<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Hive 调优 | Young&#39;s blog</title>
    <meta name="generator" content="VuePress 1.9.5">
    <link rel="icon" href="/img/favicon.ico">
    <meta name="description" content="Young丶java后端技术博客,专注后端学习与总结。擅长spring boot,JAVA基础总结,等方面的知识,关注spring,架构,elasticsearch,mysql领域.">
    <meta name="keywords" content="前端博客,个人技术博客,前端,前端开发,前端框架,web前端,前端面试题,技术文档,学习,面试,JavaScript,js,ES6,TypeScript,vue,python,css3,html5,Node,git,github,markdown">
    <meta name="baidu-site-verification" content="7F55weZDDc">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/assets/css/0.styles.53c04193.css" as="style"><link rel="preload" href="/assets/js/app.e4caa6db.js" as="script"><link rel="preload" href="/assets/js/2.d1be14c5.js" as="script"><link rel="preload" href="/assets/js/4.93e1dc89.js" as="script"><link rel="prefetch" href="/assets/js/10.20449a2b.js"><link rel="prefetch" href="/assets/js/100.f25e73b5.js"><link rel="prefetch" href="/assets/js/101.3180ba9d.js"><link rel="prefetch" href="/assets/js/102.fcd415ea.js"><link rel="prefetch" href="/assets/js/103.522869bb.js"><link rel="prefetch" href="/assets/js/104.5da1e4e4.js"><link rel="prefetch" href="/assets/js/105.e5a40fe8.js"><link rel="prefetch" href="/assets/js/106.627d6279.js"><link rel="prefetch" href="/assets/js/107.606beca1.js"><link rel="prefetch" href="/assets/js/108.100e1cb2.js"><link rel="prefetch" href="/assets/js/109.9765392e.js"><link rel="prefetch" href="/assets/js/11.da3512b5.js"><link rel="prefetch" href="/assets/js/110.b73cf0d9.js"><link rel="prefetch" href="/assets/js/111.3f77dd60.js"><link rel="prefetch" href="/assets/js/112.0c7d547d.js"><link rel="prefetch" href="/assets/js/113.1827c266.js"><link rel="prefetch" href="/assets/js/114.daf1d8a5.js"><link rel="prefetch" href="/assets/js/115.e7dca24d.js"><link rel="prefetch" href="/assets/js/116.11b303de.js"><link rel="prefetch" href="/assets/js/117.203cefba.js"><link rel="prefetch" href="/assets/js/118.61d8527b.js"><link rel="prefetch" href="/assets/js/119.1f959a37.js"><link rel="prefetch" href="/assets/js/12.11f18e06.js"><link rel="prefetch" href="/assets/js/120.c268b7aa.js"><link rel="prefetch" href="/assets/js/121.64318c96.js"><link rel="prefetch" href="/assets/js/122.cbddb70d.js"><link rel="prefetch" href="/assets/js/123.b49b84fb.js"><link rel="prefetch" href="/assets/js/124.392f030b.js"><link rel="prefetch" href="/assets/js/125.45f631c4.js"><link rel="prefetch" href="/assets/js/126.700cc575.js"><link rel="prefetch" href="/assets/js/127.d649cb2a.js"><link rel="prefetch" href="/assets/js/128.bc018411.js"><link rel="prefetch" href="/assets/js/129.d0a74611.js"><link rel="prefetch" href="/assets/js/13.1cb33dc8.js"><link rel="prefetch" href="/assets/js/130.45b1f75c.js"><link rel="prefetch" href="/assets/js/131.45ba93df.js"><link rel="prefetch" href="/assets/js/132.c58bbbd7.js"><link rel="prefetch" href="/assets/js/133.7f53922e.js"><link rel="prefetch" href="/assets/js/134.ddf0d780.js"><link rel="prefetch" href="/assets/js/135.ada3af13.js"><link rel="prefetch" href="/assets/js/136.4097c2be.js"><link rel="prefetch" href="/assets/js/137.fc910ac9.js"><link rel="prefetch" href="/assets/js/138.9628f460.js"><link rel="prefetch" href="/assets/js/139.3125ef74.js"><link rel="prefetch" href="/assets/js/14.1004ce43.js"><link rel="prefetch" href="/assets/js/140.bb53ac81.js"><link rel="prefetch" href="/assets/js/141.a002ac19.js"><link rel="prefetch" href="/assets/js/142.540d19e4.js"><link rel="prefetch" href="/assets/js/143.4cbccfca.js"><link rel="prefetch" href="/assets/js/144.8a217b6a.js"><link rel="prefetch" href="/assets/js/145.9c7bc0de.js"><link rel="prefetch" href="/assets/js/146.3dfd0773.js"><link rel="prefetch" href="/assets/js/147.bc0f0d42.js"><link rel="prefetch" href="/assets/js/148.e0cdc4d5.js"><link rel="prefetch" href="/assets/js/149.8486db6e.js"><link rel="prefetch" href="/assets/js/15.703e8784.js"><link rel="prefetch" href="/assets/js/150.5f3b7fb5.js"><link rel="prefetch" href="/assets/js/151.98a3f202.js"><link rel="prefetch" href="/assets/js/152.2940f2ba.js"><link rel="prefetch" href="/assets/js/153.75f3a085.js"><link rel="prefetch" href="/assets/js/154.fa2da83b.js"><link rel="prefetch" href="/assets/js/155.113be5c8.js"><link rel="prefetch" href="/assets/js/156.0667e7f5.js"><link rel="prefetch" href="/assets/js/157.0b3e5dfa.js"><link rel="prefetch" href="/assets/js/158.a338bdd7.js"><link rel="prefetch" href="/assets/js/159.33c9771c.js"><link rel="prefetch" href="/assets/js/16.71e3d898.js"><link rel="prefetch" href="/assets/js/160.e868c8b3.js"><link rel="prefetch" href="/assets/js/161.cf61955e.js"><link rel="prefetch" href="/assets/js/162.baee00ca.js"><link rel="prefetch" href="/assets/js/163.183cde82.js"><link rel="prefetch" href="/assets/js/164.c1eadef5.js"><link rel="prefetch" href="/assets/js/165.70ee8a24.js"><link rel="prefetch" href="/assets/js/166.8e185ff2.js"><link rel="prefetch" href="/assets/js/167.0881cf57.js"><link rel="prefetch" href="/assets/js/168.88caf424.js"><link rel="prefetch" href="/assets/js/169.e7e984ff.js"><link rel="prefetch" href="/assets/js/17.b0356f05.js"><link rel="prefetch" href="/assets/js/170.c7052d81.js"><link rel="prefetch" href="/assets/js/171.2ab773fd.js"><link rel="prefetch" href="/assets/js/172.0e39f858.js"><link rel="prefetch" href="/assets/js/173.76661218.js"><link rel="prefetch" href="/assets/js/174.0ac9f795.js"><link rel="prefetch" href="/assets/js/175.da30bba2.js"><link rel="prefetch" href="/assets/js/176.0f230688.js"><link rel="prefetch" href="/assets/js/177.040e0937.js"><link rel="prefetch" href="/assets/js/178.68852030.js"><link rel="prefetch" href="/assets/js/179.c998f0ca.js"><link rel="prefetch" href="/assets/js/18.2e77c8d1.js"><link rel="prefetch" href="/assets/js/180.4f6b395f.js"><link rel="prefetch" href="/assets/js/181.577a5325.js"><link rel="prefetch" href="/assets/js/182.6b43cbf2.js"><link rel="prefetch" href="/assets/js/183.cf9e9cca.js"><link rel="prefetch" href="/assets/js/184.f0e76def.js"><link rel="prefetch" href="/assets/js/185.2d3d8eea.js"><link rel="prefetch" href="/assets/js/186.4db71601.js"><link rel="prefetch" href="/assets/js/187.8b6a6829.js"><link rel="prefetch" href="/assets/js/188.4a0b8f41.js"><link rel="prefetch" href="/assets/js/189.0a28241b.js"><link rel="prefetch" href="/assets/js/19.51c97d4c.js"><link rel="prefetch" href="/assets/js/190.5001309c.js"><link rel="prefetch" href="/assets/js/191.42778cf1.js"><link rel="prefetch" href="/assets/js/192.fabd1cb0.js"><link rel="prefetch" href="/assets/js/193.cbc113b8.js"><link rel="prefetch" href="/assets/js/194.4cf24763.js"><link rel="prefetch" href="/assets/js/195.ea5d1afb.js"><link rel="prefetch" href="/assets/js/196.16115ce4.js"><link rel="prefetch" href="/assets/js/197.b90179d1.js"><link rel="prefetch" href="/assets/js/198.456ceb51.js"><link rel="prefetch" href="/assets/js/199.a28de97a.js"><link rel="prefetch" href="/assets/js/20.79989fc4.js"><link rel="prefetch" href="/assets/js/200.72102ac7.js"><link rel="prefetch" href="/assets/js/201.e2b3a297.js"><link rel="prefetch" href="/assets/js/202.d4283e12.js"><link rel="prefetch" href="/assets/js/203.6e5e6596.js"><link rel="prefetch" href="/assets/js/204.363863cf.js"><link rel="prefetch" href="/assets/js/205.d16c5a36.js"><link rel="prefetch" href="/assets/js/206.dc867263.js"><link rel="prefetch" href="/assets/js/207.acfeaaaa.js"><link rel="prefetch" href="/assets/js/208.22c49054.js"><link rel="prefetch" href="/assets/js/209.0f7c526b.js"><link rel="prefetch" href="/assets/js/21.1b619a3f.js"><link rel="prefetch" href="/assets/js/210.b247a678.js"><link rel="prefetch" href="/assets/js/211.fe8629a4.js"><link rel="prefetch" href="/assets/js/212.48b672e5.js"><link rel="prefetch" href="/assets/js/213.08f571a8.js"><link rel="prefetch" href="/assets/js/214.04da1824.js"><link rel="prefetch" href="/assets/js/215.f60b57f4.js"><link rel="prefetch" href="/assets/js/216.4383ceb6.js"><link rel="prefetch" href="/assets/js/217.3b1ce286.js"><link rel="prefetch" href="/assets/js/218.1534ef52.js"><link rel="prefetch" href="/assets/js/219.6901e38c.js"><link rel="prefetch" href="/assets/js/22.349d3a16.js"><link rel="prefetch" href="/assets/js/220.22e0c5ea.js"><link rel="prefetch" href="/assets/js/221.2e7a5a4f.js"><link rel="prefetch" href="/assets/js/222.76b63073.js"><link rel="prefetch" href="/assets/js/223.500a058f.js"><link rel="prefetch" href="/assets/js/224.7f7c1250.js"><link rel="prefetch" href="/assets/js/225.2f183cbe.js"><link rel="prefetch" href="/assets/js/23.712dd5ac.js"><link rel="prefetch" href="/assets/js/24.77ae5052.js"><link rel="prefetch" href="/assets/js/25.e95f81fb.js"><link rel="prefetch" href="/assets/js/26.82cdd880.js"><link rel="prefetch" href="/assets/js/27.427a5aec.js"><link rel="prefetch" href="/assets/js/28.e245952d.js"><link rel="prefetch" href="/assets/js/29.50596e31.js"><link rel="prefetch" href="/assets/js/3.4f4335cf.js"><link rel="prefetch" href="/assets/js/30.016e73a0.js"><link rel="prefetch" href="/assets/js/31.fb0b0b40.js"><link rel="prefetch" href="/assets/js/32.8e7d8efe.js"><link rel="prefetch" href="/assets/js/33.f05f242b.js"><link rel="prefetch" href="/assets/js/34.893b8c3e.js"><link rel="prefetch" href="/assets/js/35.f98d31b7.js"><link rel="prefetch" href="/assets/js/36.6a5744a0.js"><link rel="prefetch" href="/assets/js/37.67e8976d.js"><link rel="prefetch" href="/assets/js/38.2d8447e0.js"><link rel="prefetch" href="/assets/js/39.3b3fde85.js"><link rel="prefetch" href="/assets/js/40.8cde36eb.js"><link rel="prefetch" href="/assets/js/41.9df0f821.js"><link rel="prefetch" href="/assets/js/42.c9f1a26b.js"><link rel="prefetch" href="/assets/js/43.fa088c07.js"><link rel="prefetch" href="/assets/js/44.121055e3.js"><link rel="prefetch" href="/assets/js/45.7995c3a0.js"><link rel="prefetch" href="/assets/js/46.17d53a2e.js"><link rel="prefetch" href="/assets/js/47.4a374966.js"><link rel="prefetch" href="/assets/js/48.733e5b6c.js"><link rel="prefetch" href="/assets/js/49.0fb92742.js"><link rel="prefetch" href="/assets/js/5.f52855e6.js"><link rel="prefetch" href="/assets/js/50.50fc5031.js"><link rel="prefetch" href="/assets/js/51.69d8d52a.js"><link rel="prefetch" href="/assets/js/52.d84cedc3.js"><link rel="prefetch" href="/assets/js/53.a64ddaf4.js"><link rel="prefetch" href="/assets/js/54.15e09103.js"><link rel="prefetch" href="/assets/js/55.0f7e8fd5.js"><link rel="prefetch" href="/assets/js/56.6cb5bf13.js"><link rel="prefetch" href="/assets/js/57.d90d9da6.js"><link rel="prefetch" href="/assets/js/58.2c03a905.js"><link rel="prefetch" href="/assets/js/59.02cf613a.js"><link rel="prefetch" href="/assets/js/6.0ff35647.js"><link rel="prefetch" href="/assets/js/60.bb6d2b2f.js"><link rel="prefetch" href="/assets/js/61.ef2abfd3.js"><link rel="prefetch" href="/assets/js/62.b09e5f81.js"><link rel="prefetch" href="/assets/js/63.6ca85ec7.js"><link rel="prefetch" href="/assets/js/64.77eab656.js"><link rel="prefetch" href="/assets/js/65.65b00883.js"><link rel="prefetch" href="/assets/js/66.040b5d23.js"><link rel="prefetch" href="/assets/js/67.23318ab1.js"><link rel="prefetch" href="/assets/js/68.5c29433f.js"><link rel="prefetch" href="/assets/js/69.90978695.js"><link rel="prefetch" href="/assets/js/7.463451e9.js"><link rel="prefetch" href="/assets/js/70.0c585fbd.js"><link rel="prefetch" href="/assets/js/71.120e4ae5.js"><link rel="prefetch" href="/assets/js/72.53bf1e3a.js"><link rel="prefetch" href="/assets/js/73.282f5b35.js"><link rel="prefetch" href="/assets/js/74.4f1cb67d.js"><link rel="prefetch" href="/assets/js/75.f5d3ea1e.js"><link rel="prefetch" href="/assets/js/76.fb173587.js"><link rel="prefetch" href="/assets/js/77.8064b022.js"><link rel="prefetch" href="/assets/js/78.d26f8075.js"><link rel="prefetch" href="/assets/js/79.6cff2fa5.js"><link rel="prefetch" href="/assets/js/8.d5f74857.js"><link rel="prefetch" href="/assets/js/80.29d746c7.js"><link rel="prefetch" href="/assets/js/81.c0a214a2.js"><link rel="prefetch" href="/assets/js/82.f0c93ca2.js"><link rel="prefetch" href="/assets/js/83.db6f55e1.js"><link rel="prefetch" href="/assets/js/84.b0a7a28c.js"><link rel="prefetch" href="/assets/js/85.db7376d4.js"><link rel="prefetch" href="/assets/js/86.96ec3402.js"><link rel="prefetch" href="/assets/js/87.ae41a109.js"><link rel="prefetch" href="/assets/js/88.d83c21c8.js"><link rel="prefetch" href="/assets/js/89.33868490.js"><link rel="prefetch" href="/assets/js/9.2680f96d.js"><link rel="prefetch" href="/assets/js/90.ed48459a.js"><link rel="prefetch" href="/assets/js/91.e1ee23ba.js"><link rel="prefetch" href="/assets/js/92.8b354527.js"><link rel="prefetch" href="/assets/js/93.0682d2e4.js"><link rel="prefetch" href="/assets/js/94.105580aa.js"><link rel="prefetch" href="/assets/js/95.d378d658.js"><link rel="prefetch" href="/assets/js/96.a6460598.js"><link rel="prefetch" href="/assets/js/97.a4cc955f.js"><link rel="prefetch" href="/assets/js/98.9a600d4f.js"><link rel="prefetch" href="/assets/js/99.45007523.js">
    <link rel="stylesheet" href="/assets/css/0.styles.53c04193.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/img/logo.png" alt="Young's blog" class="logo"> <span class="site-name can-hide">Young's blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/Spring/" class="nav-link">Spring</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="前端" class="dropdown-title"><a href="/web/" class="link-title">前端</a> <span class="title" style="display:none;">前端</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>前端文章1</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/8143cc480faf9a11/" class="nav-link">JavaScript</a></li></ul></li><li class="dropdown-item"><h4>学习笔记</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/note/javascript/" class="nav-link">《JavaScript教程》</a></li><li class="dropdown-subitem"><a href="/note/js/" class="nav-link">《JavaScript高级程序设计》</a></li><li class="dropdown-subitem"><a href="/note/es6/" class="nav-link">《ES6 教程》</a></li><li class="dropdown-subitem"><a href="/note/vue/" class="nav-link">《Vue》</a></li><li class="dropdown-subitem"><a href="/note/react/" class="nav-link">《React》</a></li><li class="dropdown-subitem"><a href="/note/typescript-axios/" class="nav-link">《TypeScript 从零实现 axios》</a></li><li class="dropdown-subitem"><a href="/note/git/" class="nav-link">《Git》</a></li><li class="dropdown-subitem"><a href="/pages/51afd6/" class="nav-link">TypeScript</a></li><li class="dropdown-subitem"><a href="/pages/4643cd/" class="nav-link">JS设计模式总结</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="页面" class="dropdown-title"><a href="/ui/" class="link-title">页面</a> <span class="title" style="display:none;">页面</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/8309a5b876fc95e3/" class="nav-link">HTML</a></li><li class="dropdown-item"><!----> <a href="/pages/0a83b083bdf257cb/" class="nav-link">CSS</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="技术" class="dropdown-title"><a href="/technology/" class="link-title">技术</a> <span class="title" style="display:none;">技术</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/9a7ee40fc232253e/" class="nav-link">技术文档</a></li><li class="dropdown-item"><!----> <a href="/pages/4c778760be26d8b3/" class="nav-link">GitHub技巧</a></li><li class="dropdown-item"><!----> <a href="/pages/117708e0af7f0bd9/" class="nav-link">Nodejs</a></li><li class="dropdown-item"><!----> <a href="/pages/41f87d890d0a02af/" class="nav-link">博客搭建</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="更多" class="dropdown-title"><a href="/more/" class="link-title">更多</a> <span class="title" style="display:none;">更多</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/f2a556/" class="nav-link">学习</a></li><li class="dropdown-item"><!----> <a href="/pages/aea6571b7a8bae86/" class="nav-link">面试</a></li><li class="dropdown-item"><!----> <a href="/pages/2d615df9a36a98ed/" class="nav-link">心情杂货</a></li><li class="dropdown-item"><!----> <a href="/pages/baaa02/" class="nav-link">实用技巧</a></li><li class="dropdown-item"><!----> <a href="/friends/" class="nav-link">友情链接</a></li></ul></div></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><a href="/pages/beb6c0bd8a66cea6/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/andanyang/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="/img/logo.png"> <div class="blogger-info"><h3>Young</h3> <span></span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/Spring/" class="nav-link">Spring</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="前端" class="dropdown-title"><a href="/web/" class="link-title">前端</a> <span class="title" style="display:none;">前端</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>前端文章1</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/8143cc480faf9a11/" class="nav-link">JavaScript</a></li></ul></li><li class="dropdown-item"><h4>学习笔记</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/note/javascript/" class="nav-link">《JavaScript教程》</a></li><li class="dropdown-subitem"><a href="/note/js/" class="nav-link">《JavaScript高级程序设计》</a></li><li class="dropdown-subitem"><a href="/note/es6/" class="nav-link">《ES6 教程》</a></li><li class="dropdown-subitem"><a href="/note/vue/" class="nav-link">《Vue》</a></li><li class="dropdown-subitem"><a href="/note/react/" class="nav-link">《React》</a></li><li class="dropdown-subitem"><a href="/note/typescript-axios/" class="nav-link">《TypeScript 从零实现 axios》</a></li><li class="dropdown-subitem"><a href="/note/git/" class="nav-link">《Git》</a></li><li class="dropdown-subitem"><a href="/pages/51afd6/" class="nav-link">TypeScript</a></li><li class="dropdown-subitem"><a href="/pages/4643cd/" class="nav-link">JS设计模式总结</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="页面" class="dropdown-title"><a href="/ui/" class="link-title">页面</a> <span class="title" style="display:none;">页面</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/8309a5b876fc95e3/" class="nav-link">HTML</a></li><li class="dropdown-item"><!----> <a href="/pages/0a83b083bdf257cb/" class="nav-link">CSS</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="技术" class="dropdown-title"><a href="/technology/" class="link-title">技术</a> <span class="title" style="display:none;">技术</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/9a7ee40fc232253e/" class="nav-link">技术文档</a></li><li class="dropdown-item"><!----> <a href="/pages/4c778760be26d8b3/" class="nav-link">GitHub技巧</a></li><li class="dropdown-item"><!----> <a href="/pages/117708e0af7f0bd9/" class="nav-link">Nodejs</a></li><li class="dropdown-item"><!----> <a href="/pages/41f87d890d0a02af/" class="nav-link">博客搭建</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="更多" class="dropdown-title"><a href="/more/" class="link-title">更多</a> <span class="title" style="display:none;">更多</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/f2a556/" class="nav-link">学习</a></li><li class="dropdown-item"><!----> <a href="/pages/aea6571b7a8bae86/" class="nav-link">面试</a></li><li class="dropdown-item"><!----> <a href="/pages/2d615df9a36a98ed/" class="nav-link">心情杂货</a></li><li class="dropdown-item"><!----> <a href="/pages/baaa02/" class="nav-link">实用技巧</a></li><li class="dropdown-item"><!----> <a href="/friends/" class="nav-link">友情链接</a></li></ul></div></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><a href="/pages/beb6c0bd8a66cea6/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/andanyang/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Hadoop</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>kafka</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Flume</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>hive</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/bigdata/hive_Basic/" class="sidebar-link">Hive入门</a></li><li><a href="/bigdata/hive_sql/" class="sidebar-link">Hive sql</a></li><li><a href="/bigdata/hive_Partition_Bucket/" class="sidebar-link">Hive 分区表和分桶表</a></li><li><a href="/bigdata/hive_File_format_compressiont/" class="sidebar-link">Hive 件格式和压缩</a></li><li><a href="/bigdata/hive_Performance_Tune/" aria-current="page" class="active sidebar-link">Hive 调优</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/bigdata/hive_Performance_Tune/#_12-1-计算资源配置" class="sidebar-link">12.1 计算资源配置</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-1-1-yarn-资源配置" class="sidebar-link">12.1.1 Yarn 资源配置</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_1-yarn-配置说明" class="sidebar-link">1）Yarn 配置说明</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_2-yarn-配置实操" class="sidebar-link">2）Yarn 配置实操</a></li><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-1-2-mapreduce-资源配置" class="sidebar-link">12.1.2 MapReduce 资源配置</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_1-mapreduce-map-memory-mb" class="sidebar-link">1）mapreduce.map.memory.mb</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_2-mapreduce-map-cpu-vcores" class="sidebar-link">2）mapreduce.map.cpu.vcores</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_3-mapreduce-reduce-memory-mb" class="sidebar-link">3）mapreduce.reduce.memory.mb</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_4-mapreduce-reduce-cpu-vcores" class="sidebar-link">4）mapreduce.reduce.cpu.vcores</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/bigdata/hive_Performance_Tune/#_12-2-测试用表" class="sidebar-link">12.2 测试用表</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-2-1-订单表-2000w-条数据" class="sidebar-link">12.2.1 订单表(2000w 条数据)</a></li><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-2-3-商品信息表-100w-条数据" class="sidebar-link">12.2.3 商品信息表(100w 条数据)</a></li><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-2-4-省份信息表-34-条数据" class="sidebar-link">12.2.4 省份信息表(34 条数据)</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/bigdata/hive_Performance_Tune/#_12-3-explain-查看执行计划-重点" class="sidebar-link">12.3 Explain 查看执行计划（重点）</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-3-1-explain-执行计划概述" class="sidebar-link">12.3.1 Explain 执行计划概述</a></li><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-3-2-基本语法" class="sidebar-link">12.3.2 基本语法</a></li><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-3-3-案例实操" class="sidebar-link">12.3.3 案例实操</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_1-查看下面这条语句的执行计划" class="sidebar-link">1）查看下面这条语句的执行计划</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_2-执行计划如下图" class="sidebar-link">2）执行计划如下图</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/bigdata/hive_Performance_Tune/#_12-4-hql-语法优化之分组聚合优化" class="sidebar-link">12.4 HQL 语法优化之分组聚合优化</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-4-1-优化说明" class="sidebar-link">12.4.1 优化说明</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_12-4-2-优化案例" class="sidebar-link">12.4.2 优化案例</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_1-示例-sql" class="sidebar-link">1）示例 SQL</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_2-优化前" class="sidebar-link">2）优化前</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_3-优化思路" class="sidebar-link">3）优化思路</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/bigdata/hive_Performance_Tune/#_12-5-hql-语法优化之-join-优化" class="sidebar-link">12.5 HQL 语法优化之 Join 优化</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-5-1-join-算法概述" class="sidebar-link">12.5.1 Join 算法概述</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_1-common-join" class="sidebar-link">1）Common Join</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_2-map-join" class="sidebar-link">2）Map Join</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_4-sort-merge-bucket-map-join" class="sidebar-link">4）Sort Merge Bucket Map Join</a></li><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-5-2-map-join" class="sidebar-link">12.5.2 Map Join</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_12-5-2-1-优化说明" class="sidebar-link">12.5.2.1 优化说明</a></li><li class="sidebar-sub-header level5"><a href="/bigdata/hive_Performance_Tune/#_1-hint-提示" class="sidebar-link">1）Hint 提示</a></li><li class="sidebar-sub-header level5"><a href="/bigdata/hive_Performance_Tune/#_2-自动触发" class="sidebar-link">2）自动触发</a></li><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-5-2-2-优化案例" class="sidebar-link">12.5.2.2 优化案例</a></li><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-5-3-bucket-map-join" class="sidebar-link">12.5.3 Bucket Map Join</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_12-5-3-1-优化说明" class="sidebar-link">12.5.3.1 优化说明</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_12-5-3-2-优化案例" class="sidebar-link">12.5.3.2 优化案例</a></li><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-5-4-sort-merge-bucket-map-join" class="sidebar-link">12.5.4 Sort Merge Bucket Map Join</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_12-5-4-2-优化案例" class="sidebar-link">12.5.4.2 优化案例</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/bigdata/hive_Performance_Tune/#_12-6-hql-语法优化之数据倾斜" class="sidebar-link">12.6 HQL 语法优化之数据倾斜</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-6-1-数据倾斜概述" class="sidebar-link">12.6.1 数据倾斜概述</a></li><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-6-2-分组聚合导致的数据倾斜" class="sidebar-link">12.6.2 分组聚合导致的数据倾斜</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_12-6-2-1-优化说明" class="sidebar-link">12.6.2.1 优化说明</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_12-6-2-2-优化案例" class="sidebar-link">12.6.2.2 优化案例</a></li><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-6-3-join-导致的数据倾斜" class="sidebar-link">12.6.3 Join 导致的数据倾斜</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_12-6-3-1-优化说明" class="sidebar-link">12.6.3.1 优化说明</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_12-6-3-2-优化案例" class="sidebar-link">12.6.3.2 优化案例</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/bigdata/hive_Performance_Tune/#_12-7-hql-语法优化之任务并行度" class="sidebar-link">12.7 HQL 语法优化之任务并行度</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_12-7-1-优化说明" class="sidebar-link">12.7.1 优化说明</a></li><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-7-1-1-map-端并行度" class="sidebar-link">12.7.1.1 Map 端并行度</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_12-7-1-2-reduce-端并行度" class="sidebar-link">12.7.1.2 Reduce 端并行度</a></li><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-7-2-优化案例" class="sidebar-link">12.7.2 优化案例</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/bigdata/hive_Performance_Tune/#_12-8-hql-语法优化之小文件合并" class="sidebar-link">12.8 HQL 语法优化之小文件合并</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-8-1-优化说明" class="sidebar-link">12.8.1 优化说明</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_12-8-1-1-map-端输入文件合并" class="sidebar-link">12.8.1.1 Map 端输入文件合并</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_12-8-1-2-reduce-输出文件合并" class="sidebar-link">12.8.1.2 Reduce 输出文件合并</a></li><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-8-2-优化案例" class="sidebar-link">12.8.2 优化案例</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/bigdata/hive_Performance_Tune/#_12-9-其他优化" class="sidebar-link">12.9 其他优化</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-9-1-cbo-优化" class="sidebar-link">12.9.1 CBO 优化</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_12-9-1-1-优化说明" class="sidebar-link">12.9.1.1 优化说明</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_12-9-2-2-优化案例" class="sidebar-link">12.9.2.2 优化案例</a></li><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-9-2-谓词下推" class="sidebar-link">12.9.2 谓词下推</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_12-9-2-1-优化说明" class="sidebar-link">12.9.2.1 优化说明</a></li><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-9-3-矢量化查询" class="sidebar-link">12.9.3 矢量化查询</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_12-9-4-fetch-抓取" class="sidebar-link">12.9.4 Fetch 抓取</a></li><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-9-5-本地模式" class="sidebar-link">12.9.5 本地模式</a></li><li class="sidebar-sub-header level4"><a href="/bigdata/hive_Performance_Tune/#_12-9-5-1-优化说明" class="sidebar-link">12.9.5.1 优化说明</a></li><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-9-6-并行执行" class="sidebar-link">12.9.6 并行执行</a></li><li class="sidebar-sub-header level3"><a href="/bigdata/hive_Performance_Tune/#_12-9-7-严格模式" class="sidebar-link">12.9.7 严格模式</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/bigdata/hive_Performance_Tune/#_1-连接不上-mysql-数据库" class="sidebar-link">1）连接不上 MySQL 数据库</a></li><li class="sidebar-sub-header level2"><a href="/bigdata/hive_Performance_Tune/#_2-hive-默认的输入格式处理是-combinehiveinputformat-会对小文件进行合并。" class="sidebar-link">2）Hive 默认的输入格式处理是 CombineHiveInputFormat，会对小文件进行合并。</a></li><li class="sidebar-sub-header level2"><a href="/bigdata/hive_Performance_Tune/#_3-不能执行-mapreduce-程序" class="sidebar-link">3）不能执行 MapReduce 程序</a></li><li class="sidebar-sub-header level2"><a href="/bigdata/hive_Performance_Tune/#_4-启动-mysql-服务时-报-mysql-server-pid-file-could-not-be-found-异常。" class="sidebar-link">4）启动 MySQL 服务时，报 MySQL server PID file could not be found! 异常。</a></li><li class="sidebar-sub-header level2"><a href="/bigdata/hive_Performance_Tune/#_5-报-service-mysql-status-mysql-is-not-running-but-lock-file-var-lock-subsys-mysql-失败-异常。" class="sidebar-link">5）报 service mysql status MySQL is not running, but lock file (/var/lock/subsys/mysql[失败])异常。</a></li><li class="sidebar-sub-header level2"><a href="/bigdata/hive_Performance_Tune/#_6-jvm-堆内存溢出-hive-集群运行模式" class="sidebar-link">6）JVM 堆内存溢出（Hive 集群运行模式）</a></li></ul></li><li><a href="/bigdata/hive_trap/" class="sidebar-link">Hive入门 的坑</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>scala</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>spark</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/categories/?category=%E5%A4%A7%E6%95%B0%E6%8D%AE" title="分类" data-v-06225672>大数据</a></li><li data-v-06225672><a href="/categories/?category=hive" title="分类" data-v-06225672>hive</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/andanyoung" target="_blank" title="作者" class="beLink" data-v-06225672>andanyang</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2023-10-18</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABH1JREFUSA3tVl1oHFUUPmdmd2ltklqbpJDiNnXFmgbFktho7YMPNiJSSZM0+CAYSkUELVhM6YuwIPpgoOKDqOBDC0XE2CQoNtQXBUFTTcCi+Wlh1V2TQExsUzcltd3M9Tt3ZjZzZ2fT+OJTL8yeM+eee757fmeJbq//KQL8X3DUSFOcfr7cRsRtxNQMWueeVzOkaITIGqQHNg5y8+jNW9ldM7A6nTpAjuolUikAwq7CE3WcM2RRDz+XGVgN3FptU/aUSlvq9Pa3iZ1+sgAqJyyAFqkipd9dqiwHF3P65YycLWc/6sqGrvoEoIp6DOFaX5h6+dnfjkWprwqsPk0dUGq5vySwDImC10KxFHgGL1SWoc92O3eVht09qdXNH11I2SsTsJYqMWzihqGMi+A+Garf3BAuuLI5oGlULyNfyB/HYNujwktOfRrMr5t77NmevqaUopx0grnKAyvVpmwUDB4x6FPXuGvYLTDwWsejwgtgkYKPqRJg8SV6xaiZ3ZTppGneS4yfH5/66fZSDHv+QZci/+h5c5UHtpy67JUqGppM0sh0Nc1dW6/N1W5Yoqat8/TU/VnadmdeW2PLLSyh0cvxBs3KbqTmwYPpxN4do/mzE8nEpvX/UMu2Wbp74zUAK5q6WkHns7V0eWkdPbPzd3rxkTGybadYySumVzhcaJFbs5UrEkQ/+CK8gF5dnh/6ciIZ73gwQ927L1IitoxKLXYP3SjYdOrHHfTZhRRlFyrorafPk20B3HPD1y2G3qKZME5Jcf3t/HUC13/8tSd++vqFveMUTwAUxSUFI1QekR1+bIze3D9MF2aq6cPvG72CgnldWCFqyRw3lwH8ZMerjTD9ElRO7Gv44wNpC90aASqGfVlz/Rx17srQ57/UU26hkhQqUB7dBR71WmzQhHUnblGmVOEw0jhbV1n9OlXUDCIRGaNV5Jp43N516fN7JmnTHdfp7Hgy0luO4aMhtkLL8Bi3bUWYvzh5Mn1dTxrL6QmGuRhGL/TiTTxRoEdTszSaq9GR0NGA3KdkOz3hqSV3MIDhQ5IVX/Ivx3umBti2es2h4eZby7x8br1rkf7Mo90AqC8aQ3sJeNzqFRu+vSANAQe3PL7l0HGOAdwDCeZYvNKeoZp1Qfs6Aipndh86HmFRi0LAnEO47wsqM6cdfjh3jBPUzhZy7nvlUfFsamED1VQt6aISHVymXZ/B2aCtIG8AI8xfobj2d3en1wWVhOeHELKmLQ1s211s88comkv4UCwWyF787mJdYXtNfhKAXVqnKTq8QZvGAGGOfaTo5pGZ/PwbUCr5+DPr/1J92JNHr9aOl/F3iI5+O1nfybsGxoimvZ3ViWSluDITw3P37mypheDIPY0tw7+O/5ApbkYw+zpfaUVu32Pi98+defdUhEpZkRFq0aqyNh9FuL9hpYbEm6iwi0z2REd09ZmyENEbuhjDWzKvZXTqKYaBIr3tt5kuPtQBZFvEUwHt60vfCNu41XsksH9Ij1BMMz1Y0OOunHNShFIP5868g5zeXmuLwL9T4b6Q2+KejgAAAABJRU5ErkJggg==">Hive 调优<!----></h1>  <div class="theme-vdoing-content content__default"><h1 id="第-12-章-企业级调优"><a href="#第-12-章-企业级调优" class="header-anchor">#</a> 第 12 章 企业级调优</h1> <h2 id="_12-1-计算资源配置"><a href="#_12-1-计算资源配置" class="header-anchor">#</a> 12.1 计算资源配置</h2> <p>本教程的计算环境为 Hive on MR。计算资源的调整主要包括 Yarn 和 MR。</p> <h3 id="_12-1-1-yarn-资源配置"><a href="#_12-1-1-yarn-资源配置" class="header-anchor">#</a> 12.1.1 Yarn 资源配置</h3> <h4 id="_1-yarn-配置说明"><a href="#_1-yarn-配置说明" class="header-anchor">#</a> 1）Yarn 配置说明</h4> <p>需要调整的 Yarn 参数均与 CPU、内存等资源有关，核心配置参数如下</p> <p>（1）yarn.nodemanager.resource.memory-mb</p> <p>该参数的含义是，一个 NodeManager 节点分配给 Container 使用的总内存（默认8G）。该参数的配置，取决于 NodeManager 所在节点的总内存容量和该节点运行的其他服务的数量。
考虑上述因素，此处可将该参数设置为 <strong>64G(总内存的1/2 ~ 1/3)具体要看其他服务占用</strong>，如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;
    &lt;value&gt;65536&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>（2）yarn.nodemanager.resource.cpu-vcores</p> <p>该参数的含义是，一个 NodeManager 节点分配给 Container 使用的 CPU 核数**（默认每台8核）**。该参数的配置，同样取决于 NodeManager 所在节点的总 CPU 核数和该节点运行的其他服务。
考虑上述因素，此处可将该参数设置为 16（<strong>考虑具体node核心数，以及其他程序占比）。一般 cpu比内存为 1:4</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;
    &lt;value&gt;16&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>（3）yarn.scheduler.maximum-allocation-mb</p> <p>该参数的含义是，<strong>单个</strong> Container 能够使用的最大内存。推荐配置如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;property&gt;
    &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;
    &lt;value&gt;16384&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>（4）yarn.scheduler.minimum-allocation-mb</p> <p>该参数的含义是，单个 Container 能够使用的最小内存，推荐配置如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;property&gt;
    &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;
    &lt;value&gt;512&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h4 id="_2-yarn-配置实操"><a href="#_2-yarn-配置实操" class="header-anchor">#</a> 2）Yarn 配置实操</h4> <p>（1）修改$HADOOP_HOME/etc/hadoop/yarn-site.xml 文件</p> <p>（2）修改如下参数</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;
    &lt;value&gt;65536&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;
    &lt;value&gt;16&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;
    &lt;value&gt;16384&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
    &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;
    &lt;value&gt;512&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div><p>（3）分发该配置文件
（4）重启 Yarn。</p> <h3 id="_12-1-2-mapreduce-资源配置"><a href="#_12-1-2-mapreduce-资源配置" class="header-anchor">#</a> 12.1.2 MapReduce 资源配置</h3> <p>MapReduce 资源配置主要包括 Map Task 的内存和 CPU 核数，以及 Reduce Task 的内存和 CPU 核数。核心配置参数如下：</p> <h4 id="_1-mapreduce-map-memory-mb"><a href="#_1-mapreduce-map-memory-mb" class="header-anchor">#</a> 1）mapreduce.map.memory.mb</h4> <p>该参数的含义是，单个 Map Task 申请的 container 容器内存大小，<strong>其默认值为 1024</strong>。该值不能超出<code>yarn.scheduler.maximum-allocation-mb</code>和<code>yarn.scheduler.minimum-allocation-mb</code>规定的范围。</p> <p>该参数需要根据不同的计算任务单独进行配置，在 hive 中，可直接使用如下方式为每个 SQL 语句单独进行配置：（hive-site.xml）</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>set  mapreduce.map.memory.mb=2048;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h4 id="_2-mapreduce-map-cpu-vcores"><a href="#_2-mapreduce-map-cpu-vcores" class="header-anchor">#</a> 2）mapreduce.map.cpu.vcores</h4> <p>该参数的含义是，单个 Map Task 申请的 container 容器 cpu 核数，其默认值为 1。该值一般无需调整。</p> <h4 id="_3-mapreduce-reduce-memory-mb"><a href="#_3-mapreduce-reduce-memory-mb" class="header-anchor">#</a> 3）mapreduce.reduce.memory.mb</h4> <p>该参数的含义是，单个 Reduce Task 申请的 container 容器内存大小，<strong>其默认值为 1024</strong>。该值同样不能超出<code>yarn.scheduler.maximum-allocation-mb</code>和<code>yarn.scheduler.minimum-allocation-mb</code>规定的范围。</p> <p>该参数需要根据不同的计算任务单独进行配置，在 hive 中，可直接使用如下方式为每个 SQL 语句单独进行配置：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>set  mapreduce.reduce.memory.mb=2048;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h4 id="_4-mapreduce-reduce-cpu-vcores"><a href="#_4-mapreduce-reduce-cpu-vcores" class="header-anchor">#</a> 4）mapreduce.reduce.cpu.vcores</h4> <p>该参数的含义是，单个 Reduce Task 申请的 container 容器 cpu 核数，其默认值为 1。该值一般无需调整。</p> <h2 id="_12-2-测试用表"><a href="#_12-2-测试用表" class="header-anchor">#</a> 12.2 测试用表</h2> <h3 id="_12-2-1-订单表-2000w-条数据"><a href="#_12-2-1-订单表-2000w-条数据" class="header-anchor">#</a> 12.2.1 订单表(2000w 条数据)</h3> <p><strong>1）表结构</strong></p> <table><thead><tr><th><strong>id(订单 id)</strong></th> <th><strong>user_id(用户 id)</strong></th> <th><strong>product_id(商品 id)</strong></th> <th><strong>province_id(省份 id)</strong></th> <th><strong>create_time(下单时间)</strong></th> <th><strong>product_num(商品 id)</strong></th> <th><strong>total_amount(订单金额)</strong></th></tr></thead> <tbody><tr><td><strong>10000001</strong></td> <td>125442354</td> <td>15003199</td> <td>1</td> <td>2020-06-14 03:54:29</td> <td>3</td> <td>100.58</td></tr> <tr><td><strong>10000002</strong></td> <td>192758405</td> <td>17210367</td> <td>1</td> <td>2020-06-14 01:19:47</td> <td>8</td> <td>677.18</td></tr></tbody></table> <p><strong>2）建表语句</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
drop table if exists order_detail;
create table order_detail(
    id           string comment '订单id',
    user_id      string comment '用户id',
    product_id   string comment '商品id',
    province_id  string comment '省份id',
    create_time  string comment '下单时间',
    product_num  int comment '商品件数',
    total_amount decimal(16, 2) comment '下单金额'
)
partitioned by (dt string)
row format delimited fields terminated by '\t';
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><p><strong>3）数据装载</strong></p> <p>将 order_detail.txt 文件上传到 hadoop102 节点的/opt/module/hive/datas/目录，并执行以下导入语句。</p> <blockquote><p>注：文件较大，请耐心等待。</p></blockquote> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
load data local inpath '/opt/module/hive/datas/order_detail.txt' overwrite into table order_detail partition(dt='2020-06-14');
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>12.2.2 支付表(600w 条数据)</p> <p><strong>1）表结构</strong></p> <table><thead><tr><th><strong>id(支付 id)</strong></th> <th><strong>order_detail_id(订单 id)</strong></th> <th><strong>user_id(用户 id)</strong></th> <th><strong>payment_time(支付时间)</strong></th> <th><strong>total_amount(订单金额)</strong></th></tr></thead> <tbody><tr><td><strong>10000001</strong></td> <td>17403042</td> <td>131508758</td> <td>2020-06-14 13:55:44</td> <td>391.72</td></tr> <tr><td><strong>10000002</strong></td> <td>19198884</td> <td>133018075</td> <td>2020-06-14 08:46:23</td> <td>657.10</td></tr></tbody></table> <p><strong>2）建表语句</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
drop table if exists payment_detail;
create table payment_detail(
    id              string comment '支付id',
    order_detail_id string comment '订单明细id',
    user_id         string comment '用户id',
    payment_time    string comment '支付时间',
    total_amount    decimal(16, 2) comment '支付金额'
)
partitioned by (dt string)
row format delimited fields terminated by '\t';
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p><strong>3）数据装载</strong></p> <p>将 payment_detail.txt 文件上传到 hadoop102 节点的/opt/module/hive/datas/目录，并执行以下导入语句。</p> <blockquote><p>注：文件较大，请耐心等待。</p></blockquote> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
load data local inpath '/opt/module/hive/datas/payment_detail.txt' overwrite into table payment_detail partition(dt='2020-06-14');
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h3 id="_12-2-3-商品信息表-100w-条数据"><a href="#_12-2-3-商品信息表-100w-条数据" class="header-anchor">#</a> 12.2.3 商品信息表(100w 条数据)</h3> <p><strong>1）表结构</strong></p> <table><thead><tr><th><strong>id(商品 id)</strong></th> <th><strong>product_name(商品名称)</strong></th> <th><strong>price(价格)</strong></th> <th><strong>category_id(分类 id)</strong></th></tr></thead> <tbody><tr><td><strong>1000001</strong></td> <td><strong>CuisW</strong></td> <td><strong>4517.00</strong></td> <td><strong>219</strong></td></tr> <tr><td><strong>1000002</strong></td> <td><strong>TBtbp</strong></td> <td><strong>9357.00</strong></td> <td><strong>208</strong></td></tr></tbody></table> <p><strong>2）建表语句</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
drop table if exists product_info;
create table product_info(
    id           string comment '商品id',
    product_name string comment '商品名称',
    price        decimal(16, 2) comment '价格',
    category_id  string comment '分类id'
)
row format delimited fields terminated by '\t';
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p><strong>3）数据装载</strong></p> <p>将 product_info.txt 文件上传到 hadoop102 节点的/opt/module/hive/datas/目录，并执行以下导入语句</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
load data local inpath '/opt/module/hive/datas/product_info.txt' overwrite into table product_info;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h3 id="_12-2-4-省份信息表-34-条数据"><a href="#_12-2-4-省份信息表-34-条数据" class="header-anchor">#</a> 12.2.4 省份信息表(34 条数据)</h3> <p><strong>1）表结构</strong></p> <table><thead><tr><th><strong>id(省份 id)</strong></th> <th><strong>province_name(省份名称)</strong></th></tr></thead> <tbody><tr><td><strong>1</strong></td> <td><strong>北京</strong></td></tr> <tr><td><strong>2</strong></td> <td><strong>天津</strong></td></tr></tbody></table> <p><strong>2）建表语句</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
drop table if exists province_info;
create table province_info(
    id            string comment '省份id',
    province_name string comment '省份名称'
)
row format delimited fields terminated by '\t';
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>3）数据装载
将 province_info.txt 文件上传到 hadoop102 节点的/opt/module/hive/datas/目录，并执行以下导入语句。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
load data local inpath '/opt/module/hive/datas/province_info.txt' overwrite into table province_info;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h2 id="_12-3-explain-查看执行计划-重点"><a href="#_12-3-explain-查看执行计划-重点" class="header-anchor">#</a> 12.3 Explain 查看执行计划（重点）</h2> <h3 id="_12-3-1-explain-执行计划概述"><a href="#_12-3-1-explain-执行计划概述" class="header-anchor">#</a> 12.3.1 Explain 执行计划概述</h3> <p>Explain 呈现的执行计划，<strong>由一系列 Stage 组成</strong>，这一系列 Stage 具有依赖关系，<strong>每个 Stage 对应一个 MapReduce Job</strong>，或者一个文件系统操作等。
若某个 Stage 对应的一个 MapReduce Job，其 Map 端和 Reduce 端的计算逻辑分别由 Map Operator Tree 和 Reduce Operator Tree 进行描述，Operator Tree 由一系列的 Operator 组成，一个 Operator 代表在 Map 或 Reduce 阶段的一个单一的逻辑操作，例如 TableScan Operator，Select Operator，Join Operator 等。</p> <p>下图是由一个执行计划绘制而成：</p> <p><img src="/assets/img/image-20231018213022705.14557636.png" alt="Explain执行计划概述"></p> <p>常见的 Operator 及其作用如下：</p> <ul><li><p>TableScan：表扫描操作，通常 map 端第一个操作肯定是表扫描操作</p></li> <li><p>Select Operator：选取操作</p></li> <li><p>Group By Operator：分组聚合操作</p></li> <li><p>Reduce Output Operator：输出到 reduce 操作</p></li> <li><p>Filter Operator：过滤操作</p></li> <li><p>Join Operator：join 操作</p></li> <li><p>File Output Operator：文件输出操作</p></li> <li><p>Fetch Operator 客户端获取数据操作</p></li></ul> <h3 id="_12-3-2-基本语法"><a href="#_12-3-2-基本语法" class="header-anchor">#</a> 12.3.2 基本语法</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>EXPLAIN [FORMATTED | EXTENDED | DEPENDENCY] query-sql
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>注：FORMATTED、EXTENDED、DEPENDENCY 关键字为可选项，各自作用如下。</p> <ul><li><p>FORMATTED：将执行计划以 JSON 字符串的形式输出</p></li> <li><p>EXTENDED：输出执行计划中的额外信息，通常是读写的文件名等信息</p></li> <li><p>DEPENDENCY：输出执行计划读取的表及分区</p></li></ul> <h3 id="_12-3-3-案例实操"><a href="#_12-3-3-案例实操" class="header-anchor">#</a> 12.3.3 案例实操</h3> <h4 id="_1-查看下面这条语句的执行计划"><a href="#_1-查看下面这条语句的执行计划" class="header-anchor">#</a> 1）查看下面这条语句的执行计划</h4> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
explain
select
    user_id,
    count(*)
from order_detail
group by user_id;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h4 id="_2-执行计划如下图"><a href="#_2-执行计划如下图" class="header-anchor">#</a> 2）执行计划如下图</h4> <p><img src="/assets/img/image-20231018213343661.f956adf4.png" alt="执行计划"></p> <h2 id="_12-4-hql-语法优化之分组聚合优化"><a href="#_12-4-hql-语法优化之分组聚合优化" class="header-anchor">#</a> 12.4 HQL 语法优化之分组聚合优化</h2> <h3 id="_12-4-1-优化说明"><a href="#_12-4-1-优化说明" class="header-anchor">#</a> 12.4.1 优化说明</h3> <p>Hive 中未经优化的分组聚合，是通过一个 MapReduce Job 实现的。Map 端负责读取数据，并按照分组字段分区，通过 Shuffle，将数据发往 Reduce 端，各组数据在 Reduce 端完成最终的聚合运算。</p> <p><strong>Hive 对分组聚合的优化</strong>主要围绕着减少 Shuffle 数据量进行，具体做法是 map-side 聚合。所谓 map-side 聚合，就是在 map 端维护一个 hash table，利用其完成部分的聚合，然后将部分聚合的结果，按照分组字段分区，发送至 reduce 端，完成最终的聚合。map-side 聚合能有效减少 shuffle 的数据量，提高分组聚合运算的效率。</p> <p>map-side 聚合相关的参数如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--启用map-side聚合
set hive.map.aggr=true;

--用于检测源表数据是否适合进行map-side聚合。检测的方法是：先对若干条数据进行map-side聚合，若聚合后的条数和聚合前的条数比值小于该值，则认为该表适合进行map-side聚合；否则，认为该表数据不适合进行map-side聚合，后续数据便不再进行map-side聚合。
set hive.map.aggr.hash.min.reduction=0.5;

--用于检测源表是否适合map-side聚合的条数。
set hive.groupby.mapaggr.checkinterval=100000;

--map-side聚合所用的hash table，占用map task堆内存的最大比例，若超出该值，则会对hash table进行一次flush。
set hive.map.aggr.hash.force.flush.memory.threshold=0.9;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><h4 id="_12-4-2-优化案例"><a href="#_12-4-2-优化案例" class="header-anchor">#</a> 12.4.2 优化案例</h4> <h4 id="_1-示例-sql"><a href="#_1-示例-sql" class="header-anchor">#</a> 1）示例 SQL</h4> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
select
    product_id,
    count(*)
from order_detail
group by product_id;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><h4 id="_2-优化前"><a href="#_2-优化前" class="header-anchor">#</a> 2）优化前</h4> <p>未经优化的分组聚合，执行计划如下图所示：</p> <p><img src="/assets/img/image-20231018213720969.f88d1a86.png" alt="image-20231018213720969"></p> <h4 id="_3-优化思路"><a href="#_3-优化思路" class="header-anchor">#</a> 3）优化思路</h4> <p>可以考虑开启 map-side 聚合，配置以下参数：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--启用map-side聚合，默认是true
set hive.map.aggr=true;

--用于检测源表数据是否适合进行map-side聚合。检测的方法是：先对若干条数据进行map-side聚合，若聚合后的条数和聚合前的条数比值小于该值，则认为该表适合进行map-side聚合；否则，认为该表数据不适合进行map-side聚合，后续数据便不再进行map-side聚合。
set hive.map.aggr.hash.min.reduction=0.5;

--用于检测源表是否适合map-side聚合的条数。
set hive.groupby.mapaggr.checkinterval=100000;

--map-side聚合所用的hash table，占用map task堆内存的最大比例，若超出该值，则会对hash table进行一次flush。
set hive.map.aggr.hash.force.flush.memory.threshold=0.9;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p>优化后的执行计划如图所示：</p> <p><img src="/assets/img/image-20231018213809282.7fc47142.png" alt="image-20231018213809282"></p> <h2 id="_12-5-hql-语法优化之-join-优化"><a href="#_12-5-hql-语法优化之-join-优化" class="header-anchor">#</a> 12.5 HQL 语法优化之 Join 优化</h2> <h3 id="_12-5-1-join-算法概述"><a href="#_12-5-1-join-算法概述" class="header-anchor">#</a> 12.5.1 Join 算法概述</h3> <p>Hive 拥有多种 join 算法，包括 Common Join，Map Join，Bucket Map Join，Sort Merge Buckt Map Join 等，下面对每种 join 算法做简要说明：</p> <h4 id="_1-common-join"><a href="#_1-common-join" class="header-anchor">#</a> 1）Common Join</h4> <p>Common Join 是 Hive 中最稳定的 join 算法，其通过一个 MapReduce Job 完成一个 join 操作。Map 端负责读取 join 操作所需表的数据，并按照关联字段进行分区，通过 Shuffle，将其发送到 Reduce 端，相同 key 的数据在 Reduce 端完成最终的 Join 操作。如下图所示：</p> <p><img src="/assets/img/image-20231018213935354.1776d4b6.png" alt="image-20231018213935354"></p> <p>需要<strong>注意</strong>的是，sql 语句中的 join 操作和执行计划中的 Common Join 任务并非一对一的关系，一个 sql 语句中的<strong>相邻</strong>的且<strong>关联字段相同</strong>的多个 join 操作可以合并为一个 Common Join 任务。</p> <p>例如：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
select
    a.val,
    b.val,
    c.val
from a
join b on (a.key = b.key1)
join c on (c.key = b.key1)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>上述 sql 语句中两个 join 操作的关联字段均为 b 表的 key1 字段，则该语句中的两个 join 操作可由一个 Common Join 任务实现，也就是可通过一个 Map Reduce 任务实现。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
select
    a.val,
    b.val,
    c.val
from a
join b on (a.key = b.key1)
join c on (c.key = b.key2)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>上述 sql 语句中的两个 join 操作关联字段各不相同，则该语句的两个 join 操作需要各自通过一个 Common Join 任务实现，也就是通过两个 Map Reduce 任务实现。</p> <h4 id="_2-map-join"><a href="#_2-map-join" class="header-anchor">#</a> 2）Map Join</h4> <p>Map Join 算法可以通过两个只有 map 阶段的 Job 完成一个 join 操作。其适用场景为大表 join 小表。若某 join 操作满足要求，则第一个 Job 会读取小表数据，将其制作为 hash table，并上传至 Hadoop 分布式缓存（本质上是上传至 HDFS）。第二个 Job 会先从分布式缓存中读取小表数据，并缓存在 Map Task 的内存中，然后扫描大表数据，这样在 map 端即可完成关联操作。如下图所示：</p> <p><img src="/assets/img/image-20231018214156479.aa06154d.png" alt="image-20231018214156479"></p> <p>3）Bucket Map Join</p> <p>Bucket Map Join 是对 Map Join 算法的改进，其打破了 Map Join 只适用于大表 join 小表的限制，可用于大表 join 大表的场景。</p> <p>Bucket Map Join 的核心思想是：<strong>若能保证参与 join 的表均为分桶表</strong>，且关联字段为分桶字段，且其中一张表的分桶数量是另外一张表分桶数量的整数倍，就能保证参与 join 的两张表的分桶之间具有明确的关联关系，所以就可以在两表的分桶间进行 Map Join 操作了。这样一来，第二个 Job 的 Map 端就无需再缓存小表的全表数据了，而只需缓存其所需的分桶即可。其原理如图所示：</p> <p><img src="/assets/img/image-20231018214442255.d4ad3816.png" alt="image-20231018214442255"></p> <h4 id="_4-sort-merge-bucket-map-join"><a href="#_4-sort-merge-bucket-map-join" class="header-anchor">#</a> 4）Sort Merge Bucket Map Join</h4> <p>Sort Merge Bucket Map Join（简称 SMB Map Join）基于 Bucket Map Join。SMB Map Join 要求，参与 join 的表均为分桶表，且需保证分桶内的数据是有序的，且分桶字段、排序字段和关联字段为相同字段，且其中一张表的分桶数量是另外一张表分桶数量的整数倍。</p> <p>SMB Map Join 同 Bucket Join 一样，同样是利用两表各分桶之间的关联关系，在分桶之间进行 join 操作，不同的是，分桶之间的 join 操作的实现原理。Bucket Map Join，两个分桶之间的 join 实现原理为 Hash Join 算法；而 SMB Map Join，两个分桶之间的 join 实现原理为 Sort Merge Join 算法。</p> <p>Hash Join 和 Sort Merge Join 均为关系型数据库中常见的 Join 实现算法。Hash Join 的原理相对简单，就是对参与 join 的一张表构建 hash table，然后扫描另外一张表，然后进行逐行匹配。Sort Merge Join 需要在两张按照关联字段排好序的表中进行，其原理如图所示：</p> <p><img src="/assets/img/image-20231018214757169.be77d28f.png" alt="image-20231018214757169"></p> <p>Hive 中的 SMB Map Join 就是对两个分桶的数据按照上述思路进行 Join 操作。可以看出，SMB Map Join 与 Bucket Map Join 相比，在进行 Join 操作时，Map 端是无需对整个 Bucket 构建 hash table，也无需在 Map 端缓存整个 Bucket 数据的，每个 Mapper 只需按顺序逐个 key 读取两个分桶的数据进行 join 即可。</p> <h3 id="_12-5-2-map-join"><a href="#_12-5-2-map-join" class="header-anchor">#</a> 12.5.2 Map Join</h3> <h4 id="_12-5-2-1-优化说明"><a href="#_12-5-2-1-优化说明" class="header-anchor">#</a> <strong>12.5.2.1 优化说明</strong></h4> <p>Map Join 有两种触发方式，一种是用户在 SQL 语句中增加 hint 提示，另外一种是 Hive 优化器根据参与 join 表的数据量大小，自动触发。</p> <h5 id="_1-hint-提示"><a href="#_1-hint-提示" class="header-anchor">#</a> 1）Hint 提示</h5> <p>用户可通过如下方式，指定通过 map join 算法，并且 ta 将作为 map join 中的小表。这种方式已经过时，不推荐使用。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
select /*+ mapjoin(ta) */
    ta.id,
    tb.id
from table_a ta
join table_b tb
on ta.id=tb.id;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><h5 id="_2-自动触发"><a href="#_2-自动触发" class="header-anchor">#</a> 2）自动触发</h5> <p>Hive 在编译 SQL 语句阶段，起初所有的 join 操作均采用 Common Join 算法实现。</p> <p>之后在物理优化阶段，Hive 会根据每个 Common Join 任务所需表的大小判断该 Common Join 任务是否能够转换为 Map Join 任务，若满足要求，便将 Common Join 任务自动转换为 Map Join 任务。</p> <p>但有些 Common Join 任务所需的表大小，在 SQL 的编译阶段是未知的（例如对子查询进行 join 操作），所以这种 Common Join 任务是否能转换成 Map Join 任务在编译阶是无法确定的。</p> <p>针对这种情况，Hive 会在编译阶段生成一个条件任务（Conditional Task），其下会包含一个计划列表，计划列表中包含转换后的 Map Join 任务以及原有的 Common Join 任务。最终具体采用哪个计划，是在运行时决定的。大致思路如下图所示：</p> <p><img src="/assets/img/image-20231018215103225.82dc6e17.png" alt="image-20231018215103225"></p> <p>Map join 自动转换的具体判断逻辑如下图所示：</p> <p><img src="/assets/img/image-20231018215118634.048cfcff.png" alt="image-20231018215118634"></p> <p>图中涉及到的参数如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--启动Map Join自动转换
set hive.auto.convert.join=true;

--一个Common Join operator转为Map Join operator的判断条件,若该Common Join相关的表中,存在n-1张表的已知大小总和&lt;=该值,则生成一个Map Join计划,此时可能存在多种n-1张表的组合均满足该条件,则hive会为每种满足条件的组合均生成一个Map Join计划,同时还会保留原有的Common Join计划作为后备(back up)计划,实际运行时,优先执行Map Join计划，若不能执行成功，则启动Common Join后备计划。
set hive.mapjoin.smalltable.filesize=250000;

--开启无条件转Map Join
set hive.auto.convert.join.noconditionaltask=true;

--无条件转Map Join时的小表之和阈值,若一个Common Join operator相关的表中，存在n-1张表的大小总和&lt;=该值,此时hive便不会再为每种n-1张表的组合均生成Map Join计划,同时也不会保留Common Join作为后备计划。而是只生成一个最优的Map Join计划。
set hive.auto.convert.join.noconditionaltask.size=10000000;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><ul><li>hive.mapjoin.smalltable.filesize 建议使用map的1/2 ~ 2/3 内存 再除以10 （filesize  文件大小转内存大小）</li></ul> <h3 id="_12-5-2-2-优化案例"><a href="#_12-5-2-2-优化案例" class="header-anchor">#</a> 12.5.2.2 优化案例</h3> <p>1）示例 SQL</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
select
    *
from order_detail od
join product_info product on od.product_id = product.id
join province_info province on od.province_id = province.id;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>2）优化前</p> <p>上述 SQL 语句共有三张表进行两次 join 操作，且两次 join 操作的关联字段不同。故优化前的执行计划应该包含两个 Common Join operator，也就是由两个 MapReduce 任务实现。执行计划如下图所示：</p> <p><img src="/assets/img/image-20231018215322636.f46526d6.png" alt="image-20231018215322636"></p> <p>3）优化思路</p> <p>经分析，参与 join 的三张表，数据量如下</p> <table><thead><tr><th><strong>表名</strong></th> <th><strong>大小</strong></th></tr></thead> <tbody><tr><td><strong>order_detail</strong></td> <td>1176009934（约 1122M）</td></tr> <tr><td><strong>product_info</strong></td> <td>25285707（约 24M）</td></tr> <tr><td><strong>province_info</strong></td> <td>369（约 0.36K）</td></tr></tbody></table> <p><strong>注：可使用如下语句获取表/分区的大小信息</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
desc formatted table_name partition(partition_col='partition');
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>三张表中，product_info 和 province_info 数据量较小，可考虑将其作为小表，进行 Map Join 优化</p> <p>根据前文 Common Join 任务转 Map Join 任务的判断逻辑图，可得出以下优化方案：</p> <p><strong>方案一：</strong>
启用 Map Join 自动转换。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
set hive.auto.convert.join=true;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>不使用无条件转 Map Join。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>不使用无条件转Map Join。
hive (default)&gt;
set hive.auto.convert.join.noconditionaltask=false;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>调整 hive.mapjoin.smalltable.filesize 参数，使其大于等于 product_info。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
set hive.mapjoin.smalltable.filesize=25285707;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>这样可保证将两个 Common Join operator 均可转为 Map Join operator，并保留 Common Join 作为后备计划，保证计算任务的稳定。调整完的执行计划如下图：</p> <p><img src="/assets/img/image-20231018215524645.cd3f4e91.png" alt="image-20231018215524645"></p> <p><strong>方案二：</strong></p> <p>启用 Map Join 自动转换。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
set hive.auto.convert.join=true;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>使用无条件转 Map Join。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
set hive.auto.convert.join.noconditionaltask=true;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>调整 hive.auto.convert.join.noconditionaltask.size 参数，使其大于等于 product_info 和 province_info 之和。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
set hive.auto.convert.join.noconditionaltask.size=25286076;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>这样可直接将两个 Common Join operator 转为两个 Map Join operator，并且由于两个 Map Join operator 的小表大小之和小于等于 hive.auto.convert.join.noconditionaltask.size，故两个 Map Join operator 任务可合并为同一个。这个方案计算效率最高，但需要的内存也是最多的。</p> <p>调整完的执行计划如下图：</p> <p><img src="/assets/img/image-20231018215635419.55348bd6.png" alt="image-20231018215635419"></p> <p><strong>方案三：</strong></p> <p>启用 Map Join 自动转换。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
set hive.auto.convert.join=true;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>使用无条件转 Map Join。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
set hive.auto.convert.join.noconditionaltask=true;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>调整 hive.auto.convert.join.noconditionaltask.size 参数，使其等于 product_info。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
set hive.auto.convert.join.noconditionaltask.size=25285707;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>这样可直接将两个 Common Join operator 转为 Map Join operator，但不会将两个 Map Join 的任务合并。该方案计算效率比方案二低，但需要的内存也更少。</p> <p>调整完的执行计划如下图：</p> <p><img src="/assets/img/image-20231018215841189.840dddc3.png" alt="image-20231018215841189"></p> <h3 id="_12-5-3-bucket-map-join"><a href="#_12-5-3-bucket-map-join" class="header-anchor">#</a> <strong>12.5.3</strong> <strong>Bucket Map Join</strong></h3> <h4 id="_12-5-3-1-优化说明"><a href="#_12-5-3-1-优化说明" class="header-anchor">#</a> 12.5.3.1 优化说明</h4> <p>Bucket Map Join 不支持自动转换，发须通过用户在 SQL 语句中提供如下 Hint 提示，并配置如下相关参数，方可使用。</p> <p><strong>1）Hint 提示</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
select /*+ mapjoin(ta) */
    ta.id,
    tb.id
from table_a ta
join table_b tb on ta.id=tb.id;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p><strong>2）相关参数</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--关闭cbo优化，cbo会导致hint信息被忽略
set hive.cbo.enable=false;
--map join hint默认会被忽略(因为已经过时)，需将如下参数设置为false
set hive.ignore.mapjoin.hint=false;
--启用bucket map join优化功能
set hive.optimize.bucketmapjoin = true;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><h4 id="_12-5-3-2-优化案例"><a href="#_12-5-3-2-优化案例" class="header-anchor">#</a> 12.5.3.2 优化案例</h4> <p><strong>1）示例 SQL</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
select
    *
from(
    select
        *
    from order_detail
    where dt='2020-06-14'
)od
join(
    select
        *
    from payment_detail
    where dt='2020-06-14'
)pd
on od.id=pd.order_detail_id;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div><p><strong>2）优化前</strong></p> <p>上述 SQL 语句共有两张表一次 join 操作，故优化前的执行计划应包含一个 Common Join 任务，通过一个 MapReduce Job 实现。执行计划如下图所示：</p> <p><img src="/assets/img/image-20231018220037705.6af903cd.png" alt="image-20231018220037705"></p> <p><strong>3）优化思路</strong></p> <p>经分析，参与 join 的两张表，数据量如下</p> <table><thead><tr><th><strong>表名</strong></th> <th><strong>大小</strong></th></tr></thead> <tbody><tr><td><strong>order**</strong>_detail**</td> <td>1176009934（约 1122M）</td></tr> <tr><td><strong>payment**</strong>_detail**</td> <td>334198480（约 319M）</td></tr></tbody></table> <p>两张表都相对较大，若采用普通的 Map Join 算法，则 Map 端需要较多的内存来缓存数据，当然可以选择为 Map 段分配更多的内存，来保证任务运行成功。但是，Map 端的内存不可能无上限的分配，所以当参与 Join 的表数据量均过大时，就可以考虑采用 Bucket Map Join 算法。下面演示如何使用 Bucket Map Join。</p> <p>首先需要依据源表创建两个分桶表，order_detail 建议分 16 个 bucket，payment_detail 建议分 8 个 bucket,注意<strong>分桶个数</strong>的倍数关系以及<strong>分桶字段</strong>。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--订单表
hive (default)&gt;
drop table if exists order_detail_bucketed;
create table order_detail_bucketed(
    id           string comment '订单id',
    user_id      string comment '用户id',
    product_id   string comment '商品id',
    province_id  string comment '省份id',
    create_time  string comment '下单时间',
    product_num  int comment '商品件数',
    total_amount decimal(16, 2) comment '下单金额'
)
clustered by (id) into 16 buckets
row format delimited fields terminated by '\t';

--支付表
hive (default)&gt;
drop table if exists payment_detail_bucketed;
create table payment_detail_bucketed(
    id              string comment '支付id',
    order_detail_id string comment '订单明细id',
    user_id         string comment '用户id',
    payment_time    string comment '支付时间',
    total_amount    decimal(16, 2) comment '支付金额'
)
clustered by (order_detail_id) into 8 buckets
row format delimited fields terminated by '\t';
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br></div></div><p>然后向两个分桶表导入数据。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--订单表
hive (default)&gt;
insert overwrite table order_detail_bucketed
select
    id,
    user_id,
    product_id,
    province_id,
    create_time,
    product_num,
    total_amount
from order_detail
where dt='2020-06-14';

--分桶表
hive (default)&gt;
insert overwrite table payment_detail_bucketed
select
    id,
    order_detail_id,
    user_id,
    payment_time,
    total_amount
from payment_detail
where dt='2020-06-14';
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br></div></div><p>然后设置以下参数：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--关闭cbo优化，cbo会导致hint信息被忽略，需将如下参数修改为false
set hive.cbo.enable=false;
--map join hint默认会被忽略(因为已经过时)，需将如下参数修改为false
set hive.ignore.mapjoin.hint=false;
--启用bucket map join优化功能,默认不启用，需将如下参数修改为true
set hive.optimize.bucketmapjoin = true;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>最后在重写 SQL 语句，如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
select /*+ mapjoin(pd) */
    *
from order_detail_bucketed od
join payment_detail_bucketed pd on od.id = pd.order_detail_id;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>优化后的执行计划如图所示：<img src="/assets/img/image-20231018220240966.c7b712fa.png" alt="image-20231018220240966"></p> <p>需要注意的是，Bucket Map Join 的执行计划的基本信息和普通的 Map Join 无异，若想看到差异，可执行如下语句，查看执行计划的详细信息。详细执行计划中，如在 Map Join Operator 中看到 “BucketMapJoin: true”，则表明使用的 Join 算法为 Bucket Map Join。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
explain extended select /*+ mapjoin(pd) */
    *
from order_detail_bucketed od
join payment_detail_bucketed pd on od.id = pd.order_detail_id;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h3 id="_12-5-4-sort-merge-bucket-map-join"><a href="#_12-5-4-sort-merge-bucket-map-join" class="header-anchor">#</a> 12.5.4 Sort Merge Bucket Map Join</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>--启动Sort Merge Bucket Map Join优化
set hive.optimize.bucketmapjoin.sortedmerge=true;
--使用自动转换SMB Join
set hive.auto.convert.sortmerge.join=true;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h4 id="_12-5-4-2-优化案例"><a href="#_12-5-4-2-优化案例" class="header-anchor">#</a> 12.5.4.2 优化案例</h4> <p><strong>1）示例 SQL 语句</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
select
    *
from(
    select
        *
    from order_detail
    where dt='2020-06-14'
)od
join(
    select
        *
    from payment_detail
    where dt='2020-06-14'
)pd
on od.id=pd.order_detail_id;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div><p><strong>2）优化前</strong></p> <p>上述 SQL 语句共有两张表一次 join 操作，故优化前的执行计划应包含一个 Common Join 任务，通过一个 MapReduce Job 实现。</p> <p><strong>3）优化思路</strong>
经分析，参与 join 的两张表，数据量如下</p> <table><thead><tr><th><strong>表名</strong></th> <th><strong>大小</strong></th></tr></thead> <tbody><tr><td><strong>order**</strong>_detail**</td> <td>1176009934（约 1122M）</td></tr> <tr><td><strong>payment**</strong>_detail**</td> <td>334198480（约 319M）</td></tr></tbody></table> <p>张表都相对较大，除了可以考虑采用 Bucket Map Join 算法，还可以考虑 SMB Join。相较于 Bucket Map Join，SMB Map Join 对分桶大小是没有要求的。下面演示如何使用 SMB Map Join。</p> <p>首先需要依据源表创建两个的有序的分桶表，order_detail 建议分 16 个 bucket，payment_detail 建议分 8 个 bucket,注意<strong>分桶个数</strong>的倍数关系以及<strong>分桶字段和排序字段</strong>。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--订单表
hive (default)&gt;
drop table if exists order_detail_sorted_bucketed;
create table order_detail_sorted_bucketed(
    id           string comment '订单id',
    user_id      string comment '用户id',
    product_id   string comment '商品id',
    province_id  string comment '省份id',
    create_time  string comment '下单时间',
    product_num  int comment '商品件数',
    total_amount decimal(16, 2) comment '下单金额'
)
clustered by (id) sorted by(id) into 16 buckets
row format delimited fields terminated by '\t';

--支付表
hive (default)&gt;
drop table if exists payment_detail_sorted_bucketed;
create table payment_detail_sorted_bucketed(
    id              string comment '支付id',
    order_detail_id string comment '订单明细id',
    user_id         string comment '用户id',
    payment_time    string comment '支付时间',
    total_amount    decimal(16, 2) comment '支付金额'
)
clustered by (order_detail_id) sorted by(order_detail_id) into 8 buckets
row format delimited fields terminated by '\t';
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br></div></div><p>然后向两个分桶表导入数据。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--订单表
hive (default)&gt;
insert overwrite table order_detail_sorted_bucketed
select
    id,
    user_id,
    product_id,
    province_id,
    create_time,
    product_num,
    total_amount
from order_detail
where dt='2020-06-14';

--分桶表
hive (default)&gt;
insert overwrite table payment_detail_sorted_bucketed
select
    id,
    order_detail_id,
    user_id,
    payment_time,
    total_amount
from payment_detail
where dt='2020-06-14';
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br></div></div><p>然后设置以下参数：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--启动Sort Merge Bucket Map Join优化
set hive.optimize.bucketmapjoin.sortedmerge=true;
--使用自动转换SMB Join
set hive.auto.convert.sortmerge.join=true;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>最后在重写 SQL 语句，如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
select
    *
from order_detail_sorted_bucketed od
join payment_detail_sorted_bucketed pd
on od.id = pd.order_detail_id;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>优化后的执行计如图所示：</p> <p><img src="/assets/img/image-20231018220529632.a8eed827.png" alt="image-20231018220529632"></p> <h2 id="_12-6-hql-语法优化之数据倾斜"><a href="#_12-6-hql-语法优化之数据倾斜" class="header-anchor">#</a> 12.6 HQL 语法优化之数据倾斜</h2> <h3 id="_12-6-1-数据倾斜概述"><a href="#_12-6-1-数据倾斜概述" class="header-anchor">#</a> 12.6.1 数据倾斜概述</h3> <p>数据倾斜问题，通常是指参与计算的数据分布不均，即某个 key 或者某些 key 的数据量远超其他 key，导致在 shuffle 阶段，大量相同 key 的数据被发往同一个 Reduce，进而导致该 Reduce 所需的时间远超其他 Reduce，成为整个任务的瓶颈。
Hive 中的数据倾斜常出现在分组聚合和 join 操作的场景中，下面分别介绍在上述两种场景下的优化思路。</p> <h3 id="_12-6-2-分组聚合导致的数据倾斜"><a href="#_12-6-2-分组聚合导致的数据倾斜" class="header-anchor">#</a> 12.6.2 分组聚合导致的数据倾斜</h3> <h4 id="_12-6-2-1-优化说明"><a href="#_12-6-2-1-优化说明" class="header-anchor">#</a> 12.6.2.1 优化说明</h4> <p>前文提到过，Hive 中未经优化的分组聚合，是通过一个 MapReduce Job 实现的。Map 端负责读取数据，并按照分组字段分区，通过 Shuffle，将数据发往 Reduce 端，各组数据在 Reduce 端完成最终的聚合运算。</p> <p>如果 group by 分组字段的值分布不均，就可能导致大量相同的 key 进入同一 Reduce，从而导致数据倾斜问题。</p> <p>由分组聚合导致的数据倾斜问题，有以下两种解决思路：</p> <p><strong>1）Map-Side 聚合</strong></p> <p>开启 Map-Side 聚合后，数据会现在 Map 端完成部分聚合工作。这样一来即便原始数据是倾斜的，经过 Map 端的初步聚合后，发往 Reduce 的数据也就不再倾斜了。最佳状态下，Map-端聚合能完全屏蔽数据倾斜问题。</p> <p>相关参数如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--启用map-side聚合
set hive.map.aggr=true;

--用于检测源表数据是否适合进行map-side聚合。检测的方法是：先对若干条数据进行map-side聚合，若聚合后的条数和聚合前的条数比值小于该值，则认为该表适合进行map-side聚合；否则，认为该表数据不适合进行map-side聚合，后续数据便不再进行map-side聚合。
set hive.map.aggr.hash.min.reduction=0.5;

--用于检测源表是否适合map-side聚合的条数。
set hive.groupby.mapaggr.checkinterval=100000;

--map-side聚合所用的hash table，占用map task堆内存的最大比例，若超出该值，则会对hash table进行一次flush。
set hive.map.aggr.hash.force.flush.memory.threshold=0.9;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p><strong>2）Skew-GroupBy 优化</strong></p> <p>Skew-GroupBy 的原理是启动两个 MR 任务，第一个 MR 按照随机数分区，将数据分散发送到 Reduce，完成部分聚合，第二个 MR 按照分组字段分区，完成最终聚合。</p> <p>相关参数如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--启用分组聚合数据倾斜优化
set hive.groupby.skewindata=true;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h4 id="_12-6-2-2-优化案例"><a href="#_12-6-2-2-优化案例" class="header-anchor">#</a> 12.6.2.2 优化案例</h4> <p><strong>1）示例 SQL 语句</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
select
    province_id,
    count(*)
from order_detail
group by province_id;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><blockquote><p>需要注意的是，hive 中的 map-side 聚合是默认开启的，若想看到数据倾斜的现象，需要先将 hive.map.aggr 参数设置为 false</p></blockquote> <p><strong>（2）Skew-GroupBy 优化</strong></p> <p>设置如下参数</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--启用skew-groupby
set hive.groupby.skewindata=true;
--关闭map-side聚合
set hive.map.aggr=false;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>开启 Skew-GroupBy 优化后，可以很明显看到该 sql 执行在 yarn 上启动了两个 mr 任务，第一个 mr 打散数据，第二个 mr 按照打散后的数据进行分组聚合。</p> <h3 id="_12-6-3-join-导致的数据倾斜"><a href="#_12-6-3-join-导致的数据倾斜" class="header-anchor">#</a> 12.6.3 Join 导致的数据倾斜</h3> <h4 id="_12-6-3-1-优化说明"><a href="#_12-6-3-1-优化说明" class="header-anchor">#</a> 12.6.3.1 优化说明</h4> <p>前文提到过，未经优化的 join 操作，默认是使用 common join 算法，也就是通过一个 MapReduce Job 完成计算。Map 端负责读取 join 操作所需表的数据，并按照关联字段进行分区，通过 Shuffle，将其发送到 Reduce 端，相同 key 的数据在 Reduce 端完成最终的 Join 操作。</p> <p>如果关联字段的值分布不均，就可能导致大量相同的 key 进入同一 Reduce，从而导致数据倾斜问题。</p> <p>由 join 导致的数据倾斜问题，有如下三种解决方案：</p> <p><strong>1）map join</strong></p> <p>使用 map join 算法，join 操作仅在 map 端就能完成，没有 shuffle 操作，没有 reduce 阶段，自然不会产生 reduce 端的数据倾斜。该方案适用于大表 join 小表时发生数据倾斜的场景。</p> <p>相关参数如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--启动Map Join自动转换
set hive.auto.convert.join=true;

--一个Common Join operator转为Map Join operator的判断条件,若该Common Join相关的表中,存在n-1张表的大小总和&lt;=该值,则生成一个Map Join计划,此时可能存在多种n-1张表的组合均满足该条件,则hive会为每种满足条件的组合均生成一个Map Join计划,同时还会保留原有的Common Join计划作为后备(back up)计划,实际运行时,优先执行Map Join计划，若不能执行成功，则启动Common Join后备计划。
set hive.mapjoin.smalltable.filesize=250000;

--开启无条件转Map Join
set hive.auto.convert.join.noconditionaltask=true;

--无条件转Map Join时的小表之和阈值,若一个Common Join operator相关的表中，存在n-1张表的大小总和&lt;=该值,此时hive便不会再为每种n-1张表的组合均生成Map Join计划,同时也不会保留Common Join作为后备计划。而是只生成一个最优的Map Join计划。
set hive.auto.convert.join.noconditionaltask.size=10000000;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p><strong>2）skew join</strong></p> <p>skew join 的原理是，为倾斜的大 key 单独启动一个 map join 任务进行计算，其余 key 进行正常的 common join。原理图如下：</p> <p><img src="/assets/img/image-20231018223008124.68891ace.png" alt="image-20231018223008124"></p> <p>相关参数如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--启用skew join优化
set hive.optimize.skewjoin=true;
--触发skew join的阈值，若某个key的行数超过该参数值，则触发
set hive.skewjoin.key=100000;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>这种方案对参与 join 的源表大小没有要求，但是对两表中倾斜的 key 的数据量有要求，要求一张表中的倾斜 key 的数据量比较小（方便走 mapjoin）。</p> <p><strong>3）调整 SQL 语句</strong></p> <p>若参与 join 的两表均为大表，其中一张表的数据是倾斜的，此时也可通过以下方式对 SQL 语句进行相应的调整。
假设原始 SQL 语句如下：A，B 两表均为大表，且其中一张表的数据是倾斜的。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
select
    *
from A
join B
on A.id=B.id;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>其 join 过程如下：</p> <p><img src="/assets/img/image-20231018223102543.bc482023.png" alt="image-20231018223102543"></p> <p>图中 1001 为倾斜的大 key，可以看到，其被发往了同一个 Reduce 进行处理。
调整 SQL 语句如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
select
    *
from(
    select --打散操作
        concat(id,'_',cast(rand()*2 as int)) id,
        value
    from A
)ta
join(
    select --扩容操作
        concat(id,'_',0) id,
        value
    from B
    union all
    select
        concat(id,'_',1) id,
        value
    from B
)tb
on ta.id=tb.id;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br></div></div><p>调整之后的 SQL 语句执行计划如下图所示：</p> <p><img src="/assets/img/image-20231018223226338.7accde9c.png" alt="image-20231018223226338"></p> <h4 id="_12-6-3-2-优化案例"><a href="#_12-6-3-2-优化案例" class="header-anchor">#</a> 12.6.3.2 优化案例</h4> <p><strong>1）示例 SQL 语句</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
select
    *
from order_detail od
join province_info pi
on od.province_id=pi.id;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p><strong>2）优化前</strong></p> <p>order_detail 表中的 province_id 字段是存在倾斜的，若不经过优化，通过观察任务的执行过程，是能够看出数据倾斜现象的。</p> <p><img src="/assets/img/image-20231018223320448.1e5e1bdf.png" alt="image-20231018223320448"></p> <p>需要注意的是，hive 中的 map join 自动转换是默认开启的，若想看到数据倾斜的现象，需要先将 hive.auto.convert.join 参数设置为 false。</p> <p><strong>3）优化思路</strong></p> <p>上述两种优化思路均可解决该数据倾斜问题，下面分别进行说明：</p> <p><strong>（1）map join</strong></p> <p>设置如下参数</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--启用map join
set hive.auto.convert.join=true;
--关闭skew join
set hive.optimize.skewjoin=false;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>可以很明显看到开启 map join 以后，mr 任务只有 map 阶段，没有 reduce 阶段，自然也就不会有数据倾斜发生。</p> <p><img src="/assets/img/image-20231018223441743.2e0ce40b.png" alt="image-20231018223441743"></p> <p><strong>（2）skew join</strong></p> <p>设置如下参数</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--启动skew join
set hive.optimize.skewjoin=true;
--关闭map join
set hive.auto.convert.join=false;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>开启 skew join 后，使用 explain 可以很明显看到执行计划如下图所示，说明 skew join 生效，任务既有 common join，又有部分 key 走了 map join。</p> <p>并且该 sql 在 yarn 上最终启动了两个 mr 任务，而且第二个任务只有 map 没有 reduce 阶段，说明第二个任务是对倾斜的 key 进行了 map join。</p> <p><img src="/assets/img/image-20231018223556086.b5c19f93.png" alt="image-20231018223556086"></p> <p><img src="/assets/img/image-20231018223604733.67d90b2d.png" alt="image-20231018223604733"></p> <h2 id="_12-7-hql-语法优化之任务并行度"><a href="#_12-7-hql-语法优化之任务并行度" class="header-anchor">#</a> 12.7 HQL 语法优化之任务并行度</h2> <h4 id="_12-7-1-优化说明"><a href="#_12-7-1-优化说明" class="header-anchor">#</a> 12.7.1 优化说明</h4> <p>对于一个分布式的计算任务而言，设置一个合适的并行度十分重要。Hive 的计算任务由 MapReduce 完成，故并行度的调整需要分为 Map 端和 Reduce 端。</p> <h3 id="_12-7-1-1-map-端并行度"><a href="#_12-7-1-1-map-端并行度" class="header-anchor">#</a> 12.7.1.1 Map 端并行度</h3> <p>Map 端的并行度，也就是 Map 的个数。是由输入文件的切片数决定的。一般情况下，Map 端的并行度无需手动调整。
以下特殊情况可考虑调整 map 端并行度：</p> <p><strong>1）查询的表中存在大量小文件</strong></p> <p>按照 Hadoop 默认的切片策略，一个小文件会单独启动一个 map task 负责计算。若查询的表中存在大量小文件，则会启动大量 map task，造成计算资源的浪费。这种情况下，可以使用 Hive 提供的 CombineHiveInputFormat，多个小文件合并为一个切片，从而控制 map task 个数。相关参数如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><strong>2）map 端有复杂的查询逻辑</strong></p> <p>若 SQL 语句中有正则替换、json 解析等复杂耗时的查询逻辑时，map 端的计算会相对慢一些。若想加快计算速度，在计算资源充足的情况下，可考虑增大 map 端的并行度，令 map task 多一些，每个 map task 计算的数据少一些。相关参数如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--一个切片的最大值
set mapreduce.input.fileinputformat.split.maxsize=256000000;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h4 id="_12-7-1-2-reduce-端并行度"><a href="#_12-7-1-2-reduce-端并行度" class="header-anchor">#</a> 12.7.1.2 Reduce 端并行度</h4> <p>Reduce 端的并行度，也就是 Reduce 个数。相对来说，更需要关注。Reduce 端的并行度，可由用户自己指定，也可由 Hive 自行根据该 MR Job 输入的文件大小进行估算。</p> <p>Reduce 端的并行度的相关参数如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--指定Reduce端并行度，默认值为-1，表示用户未指定
set mapreduce.job.reduces;
--Reduce端并行度最大值
set hive.exec.reducers.max;
--单个Reduce Task计算的数据量，用于估算Reduce并行度
set hive.exec.reducers.bytes.per.reducer;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>Reduce 端并行度的确定逻辑如下：</p> <p>若指定参数<strong>mapreduce.job.reduces</strong>的值为一个非负整数，则 Reduce 并行度为指定值。否则，Hive 自行估算 Reduce 并行度，估算逻辑如下：</p> <p>假设 Job 输入的文件大小为<strong>totalInputBytes</strong></p> <p>参数<strong>hive.exec.reducers.bytes.per.reducer</strong>的值为 bytesPerReducer。</p> <p>参数<strong>hive.exec.reducers.max</strong>的值为 maxReducers。</p> <p>则 Reduce 端的并行度为：</p> <p><img src="/assets/img/wps1-1212123012012102102.ccd1611c.jpg" alt="img"></p> <p>根据上述描述，可以看出，Hive 自行估算 Reduce 并行度时，是以整个 MR Job 输入的文件大小作为依据的。因此，在某些情况下其估计的并行度很可能并不准确，此时就需要用户根据实际情况来指定 Reduce 并行度了。</p> <h3 id="_12-7-2-优化案例"><a href="#_12-7-2-优化案例" class="header-anchor">#</a> 12.7.2 优化案例</h3> <p><strong>1）示例 SQL 语句</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
select
    province_id,
    count(*)
from order_detail
group by province_id;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p><strong>2）优化前</strong></p> <p>上述 sql 语句，在不指定 Reduce 并行度时，Hive 自行估算并行度的逻辑如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>totalInputBytes= 1136009934
bytesPerReducer=256000000
maxReducers=1009
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>经计算，Reduce 并行度为</p> <p><img src="/assets/img/wps2-20131010118iwheqijeq.c5a1b07d.jpg" alt="img"></p> <p><strong>3）优化思路</strong></p> <p>上述 sql 语句，在默认情况下，是会进行 map-side 聚合的，也就是 Reduce 端接收的数据，实际上是 map 端完成聚合之后的结果。观察任务的执行过程，会发现，每个 map 端输出的数据只有 34 条记录，共有 5 个 map task。</p> <p><img src="/assets/img/image-20231018224209311.dff34eb5.png" alt="image-20231018224209311"></p> <p>也就是说 Reduce 端实际只会接收 170（34*5）条记录，故理论上 Reduce 端并行度设置为 1 就足够了。这种情况下，用户可通过以下参数，自行设置 Reduce 端并行度为 1。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--指定Reduce端并行度，默认值为-1，表示用户未指定
set mapreduce.job.reduces=1;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h2 id="_12-8-hql-语法优化之小文件合并"><a href="#_12-8-hql-语法优化之小文件合并" class="header-anchor">#</a> <strong>12.8 HQL 语法优化之小文件合并</strong></h2> <h3 id="_12-8-1-优化说明"><a href="#_12-8-1-优化说明" class="header-anchor">#</a> 12.8.1 优化说明</h3> <p>小文件合并优化，分为两个方面，分别是 Map 端输入的小文件合并，和 Reduce 端输出的小文件合并。</p> <h4 id="_12-8-1-1-map-端输入文件合并"><a href="#_12-8-1-1-map-端输入文件合并" class="header-anchor">#</a> 12.8.1.1 Map 端输入文件合并</h4> <p>合并 Map 端输入的小文件，是指将多个小文件划分到一个切片中，进而由一个 Map Task 去处理。目的是防止为单个小文件启动一个 Map Task，浪费计算资源。</p> <p>相关参数为：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--可将多个小文件切片，合并为一个切片，进而由一个map任务处理
set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h4 id="_12-8-1-2-reduce-输出文件合并"><a href="#_12-8-1-2-reduce-输出文件合并" class="header-anchor">#</a> 12.8.1.2 Reduce 输出文件合并</h4> <p>合并 Reduce 端输出的小文件，是指将多个小文件合并成大文件。目的是减少 HDFS 小文件数量。其原理是根据计算任务输出文件的平均大小进行判断，若符合条件，则单独启动一个额外的任务进行合并。</p> <p>相关参数为：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--开启合并map only任务输出的小文件
set hive.merge.mapfiles=true;

--开启合并map reduce任务输出的小文件
set hive.merge.mapredfiles=true;

--合并后的文件大小
set hive.merge.size.per.task=256000000;

--触发小文件合并任务的阈值，若某计算任务输出的文件平均大小低于该值，则触发合并
set hive.merge.smallfiles.avgsize=16000000;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><h3 id="_12-8-2-优化案例"><a href="#_12-8-2-优化案例" class="header-anchor">#</a> 12.8.2 优化案例</h3> <p><strong>1）示例用表</strong></p> <p>现有一个需求，计算各省份订单金额总和，下表为结果表。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
drop table if exists order_amount_by_province;
create table order_amount_by_province(
    province_id string comment '省份id',
    order_amount decimal(16,2) comment '订单金额'
)
location '/order_amount_by_province';
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p><strong>2）示例 SQL 语句</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
insert overwrite table order_amount_by_province
select
    province_id,
    sum(total_amount)
from order_detail
group by province_id;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p><strong>3）优化前</strong></p> <p>根据任务并行度一节所需内容，可分析出，默认情况下，该 sql 语句的 Reduce 端并行度为 5，故最终输出文件个数也为 5，下图为输出文件，可以看出，5 个均为小文件。</p> <p><img src="/assets/img/image-20231018224538034.0d5a5457.png" alt="image-20231018224538034"></p> <p><strong>4）优化思路</strong></p> <p>若想避免小文件的产生，可采取方案有两个。</p> <p>（1）合理设置任务的 Reduce 端并行度</p> <p>若将上述计算任务的并行度设置为 1，就能保证其输出结果只有一个文件。</p> <p>（2）启用 Hive 合并小文件优化</p> <p>设置以下参数：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--开启合并map reduce任务输出的小文件
set hive.merge.mapredfiles=true;

--合并后的文件大小
set hive.merge.size.per.task=256000000;

--触发小文件合并任务的阈值，若某计算任务输出的文件平均大小低于该值，则触发合并
set hive.merge.smallfiles.avgsize=16000000;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>再次执行上述的 insert 语句，观察结果表中的文件，只剩一个了。</p> <p><img src="/assets/img/image-20231018224640214.c3fec45b.png" alt="image-20231018224640214"></p> <h2 id="_12-9-其他优化"><a href="#_12-9-其他优化" class="header-anchor">#</a> 12.9 其他优化</h2> <h3 id="_12-9-1-cbo-优化"><a href="#_12-9-1-cbo-优化" class="header-anchor">#</a> 12.9.1 CBO 优化</h3> <h4 id="_12-9-1-1-优化说明"><a href="#_12-9-1-1-优化说明" class="header-anchor">#</a> 12.9.1.1 优化说明</h4> <p>CBO 是指 Cost based Optimizer，即基于计算成本的优化。</p> <p>在 Hive 中，计算成本模型考虑到了：数据的行数、CPU、本地 IO、HDFS IO、网络 IO 等方面。Hive 会计算同一 SQL 语句的不同执行计划的计算成本，并选出成本最低的执行计划。目前 CBO 在 hive 的 MR 引擎下主要用于 join 的优化，例如多表 join 的 join 顺序。</p> <p>相关参数为：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--是否启用cbo优化
set hive.cbo.enable=true;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h4 id="_12-9-2-2-优化案例"><a href="#_12-9-2-2-优化案例" class="header-anchor">#</a> 12.9.2.2 优化案例</h4> <p>1）示例 SQL 语句</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt;
select
    *
from order_detail od
join product_info product on od.product_id=product.id
join province_info province on od.province_id=province.id;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p><strong>2）关闭 CBO 优化</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--关闭cbo优化
set hive.cbo.enable=false;

--为了测试效果更加直观，关闭map join自动转换
set hive.auto.convert.join=false;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>根据执行计划，可以看出，三张表的 join 顺序如下：</p> <p><img src="/assets/img/image-20231018224904768.a9b22df4.png" alt="image-20231018224904768"></p> <p><strong>3）开启 CBO 优化</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--开启cbo优化
set hive.cbo.enable=true;
--为了测试效果更加直观，关闭map join自动转换
set hive.auto.convert.join=false;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>根据执行计划，可以看出，三张表的 join 顺序如下：</p> <p><img src="/assets/img/image-20231018224941114.06b89c67.png" alt="image-20231018224941114"></p> <p><strong>4）总结</strong></p> <p>根据上述案例可以看出，CBO 优化对于执行计划中 join 顺序是有影响的，其之所以会将 province_info 的 join 顺序提前，是因为 province info 的数据量较小，将其提前，会有更大的概率使得中间结果的数据量变小，从而使整个计算任务的数据量减小，也就是使计算成本变小。</p> <h3 id="_12-9-2-谓词下推"><a href="#_12-9-2-谓词下推" class="header-anchor">#</a> 12.9.2 谓词下推</h3> <h4 id="_12-9-2-1-优化说明"><a href="#_12-9-2-1-优化说明" class="header-anchor">#</a> 12.9.2.1 优化说明</h4> <p>谓词下推（predicate pushdown）是指，尽量将过滤操作前移，以减少后续计算步骤的数据量。</p> <p>相关参数为：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--是否启动谓词下推（predicate pushdown）优化
set hive.optimize.ppd = true;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>需要注意的是：</p> <p>CBO 优化也会完成一部分的谓词下推优化工作，因为在执行计划中，谓词越靠前，整个计划的计算成本就会越低。</p> <h3 id="_12-9-3-矢量化查询"><a href="#_12-9-3-矢量化查询" class="header-anchor">#</a> 12.9.3 矢量化查询</h3> <p>Hive 的矢量化查询优化，依赖于 CPU 的矢量化计算，CPU 的矢量化计算的基本原理如下图：</p> <p><img src="/assets/img/image-20231018225115330.94cf64e0.png" alt="image-20231018225115330"></p> <p>Hive 的矢量化查询，可以极大的提高一些典型查询场景（例如 scans, filters, aggregates, and joins）下的 CPU 使用效率。</p> <p>相关参数如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>set hive.vectorized.execution.enabled=true;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>若执行计划中，出现“Execution mode: vectorized”字样，即表明使用了矢量化计算。</p> <p>官网参考连接：</p> <p>https://cwiki.apache.org/confluence/display/Hive/Vectorized+Query+Execution#VectorizedQueryExecution-Limitations</p> <h4 id="_12-9-4-fetch-抓取"><a href="#_12-9-4-fetch-抓取" class="header-anchor">#</a> 12.9.4 Fetch 抓取</h4> <p>Fetch 抓取是指，Hive 中对某些情况的查询可以不必使用 MapReduce 计算。例如：select * from emp;在这种情况下，Hive 可以简单地读取 emp 对应的存储目录下的文件，然后输出查询结果到控制台。</p> <p>相关参数如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--是否在特定场景转换为fetch 任务
--设置为none表示不转换
--设置为minimal表示支持select *，分区字段过滤，Limit等
--设置为more表示支持select 任意字段,包括函数，过滤，和limit等
set hive.fetch.task.conversion=more;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h3 id="_12-9-5-本地模式"><a href="#_12-9-5-本地模式" class="header-anchor">#</a> 12.9.5 本地模式</h3> <h4 id="_12-9-5-1-优化说明"><a href="#_12-9-5-1-优化说明" class="header-anchor">#</a> 12.9.5.1 优化说明</h4> <p>大多数的 Hadoop Job 是需要 Hadoop 提供的完整的可扩展性来处理大数据集的。不过，有时 Hive 的输入数据量是非常小的。在这种情况下，为查询触发执行任务消耗的时间可能会比实际 job 的执行时间要多的多。对于大多数这种情况，<strong>Hive 可以通过本地模式在单台机器上处理所有的任务。对于小数据集，执行时间可以明显被缩短。</strong></p> <p>相关参数如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--开启自动转换为本地模式
set hive.exec.mode.local.auto=true; 

--设置local MapReduce的最大输入数据量，当输入数据量小于这个值时采用local  MapReduce的方式，默认为134217728，即128M
set hive.exec.mode.local.auto.inputbytes.max=50000000;

--设置local MapReduce的最大输入文件个数，当输入文件个数小于这个值时采用local MapReduce的方式，默认为4
set hive.exec.mode.local.auto.input.files.max=10;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><h3 id="_12-9-6-并行执行"><a href="#_12-9-6-并行执行" class="header-anchor">#</a> 12.9.6 并行执行</h3> <p>Hive 会将一个 SQL 语句转化成一个或者多个 Stage，每个 Stage 对应一个 MR Job。默认情况下，Hive 同时只会执行一个 Stage。但是某 SQL 语句可能会包含多个 Stage，但这多个 Stage 可能并非完全互相依赖，也就是说有些 Stage 是可以并行执行的。此处提到的并行执行就是指这些 Stage 的并行执行。相关参数如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>--启用并行执行优化
set hive.exec.parallel=true;  

--同一个sql允许最大并行度，默认为8
set hive.exec.parallel.thread.number=8;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h3 id="_12-9-7-严格模式"><a href="#_12-9-7-严格模式" class="header-anchor">#</a> <strong>12.9.7 严格模式</strong></h3> <p>Hive 可以通过设置某些参数防止危险操作：</p> <p><strong>1）分区表不使用分区过滤</strong></p> <p>将<code>hive.strict.checks.no.partition.filter</code>设置为 true 时，对于分区表，除非 where 语句中含有分区字段过滤条件来限制范围，否则不允许执行。换句话说，就是用户不允许扫描所有分区。进行这个限制的原因是，通常分区表都拥有非常大的数据集，而且数据增加迅速。没有进行分区限制的查询可能会消耗令人不可接受的巨大资源来处理这个表。</p> <p><strong>2）使用 order by 没有 limit 过滤</strong></p> <p>将<code>hive.strict.checks.orderby.no.limit</code>设置为 true 时，对于<strong>使用了 order by 语句的查询，要求必须使用 limit 语句</strong>。因为 order by 为了执行排序过程会将所有的结果数据分发到同一个 Reduce 中进行处理，强制要求用户增加这个 limit 语句可以防止 Reduce 额外执行很长一段时间（开启了 limit 可以在数据进入到 Reduce 之前就减少一部分数据）。</p> <p><strong>3）笛卡尔积</strong></p> <p>将<code>hive.strict.checks.cartesian.product</code>设置为 true 时，<strong>会限制笛卡尔积的查询</strong>。对关系型数据库非常了解的用户可能期望在执行 JOIN 查询的时候不使用 ON 语句而是使用 where 语句，这样关系数据库的执行优化器就可以高效地将 WHERE 语句转化成那个 ON 语句。不幸的是，Hive 并不会执行这种优化，因此，如果表足够大，那么这个查询就会出现不可控的情况。</p> <h1 id="附录-常见错误及解决方案"><a href="#附录-常见错误及解决方案" class="header-anchor">#</a> 附录：常见错误及解决方案</h1> <h2 id="_1-连接不上-mysql-数据库"><a href="#_1-连接不上-mysql-数据库" class="header-anchor">#</a> 1）连接不上 MySQL 数据库</h2> <p>（1）导错驱动包，应该把 mysql-connector-java-5.1.27-bin.jar 导入/opt/module/hive/lib 的不是这个包。错把 mysql-connector-java-5.1.27.tar.gz 导入 hive/lib 包下。</p> <p>（2）修改 user 表中的主机名称没有都修改为%，而是修改为 localhost</p> <h2 id="_2-hive-默认的输入格式处理是-combinehiveinputformat-会对小文件进行合并。"><a href="#_2-hive-默认的输入格式处理是-combinehiveinputformat-会对小文件进行合并。" class="header-anchor">#</a> 2）Hive 默认的输入格式处理是 CombineHiveInputFormat，会对小文件进行合并。</h2> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt; set hive.input.format;
hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>可以采用 HiveInputFormat 就会根据分区数输出相应的文件。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hive (default)&gt; set hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h2 id="_3-不能执行-mapreduce-程序"><a href="#_3-不能执行-mapreduce-程序" class="header-anchor">#</a> 3）不能执行 MapReduce 程序</h2> <p>可能是 Hadoop 的 Yarn 没开启。</p> <h2 id="_4-启动-mysql-服务时-报-mysql-server-pid-file-could-not-be-found-异常。"><a href="#_4-启动-mysql-服务时-报-mysql-server-pid-file-could-not-be-found-异常。" class="header-anchor">#</a> 4）启动 MySQL 服务时，报 MySQL server PID file could not be found! 异常。</h2> <p>在/var/lock/subsys/mysql 路径下创建 hadoop102.pid，并在文件中添加内容：4396</p> <h2 id="_5-报-service-mysql-status-mysql-is-not-running-but-lock-file-var-lock-subsys-mysql-失败-异常。"><a href="#_5-报-service-mysql-status-mysql-is-not-running-but-lock-file-var-lock-subsys-mysql-失败-异常。" class="header-anchor">#</a> <strong>5）报 service mysql status MySQL is not running, but lock file (/var/lock/subsys/mysql[失败])异常。</strong></h2> <p>解决方案：在/var/lib/mysql 目录下创建：-rw-rw----. 1 mysql mysql 5 12 月 22 16:41 hadoop102.pid 文件，并修改权限为 777。</p> <h2 id="_6-jvm-堆内存溢出-hive-集群运行模式"><a href="#_6-jvm-堆内存溢出-hive-集群运行模式" class="header-anchor">#</a> 6）JVM 堆内存溢出（Hive 集群运行模式）</h2> <p>描述：java.lang.OutOfMemoryError: Java heap space</p> <p>解决：在 yarn-site.xml 中加入如下代码。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;property&gt;
	&lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;
	&lt;value&gt;2048&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
  	&lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;
  	&lt;value&gt;2048&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
	&lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt;
	&lt;value&gt;2.1&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
	&lt;name&gt;mapred.child.java.opts&lt;/name&gt;
	&lt;value&gt;-Xmx1024m&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div><p>7）JVM 堆内存溢出（Hive 本地运行模式）</p> <p>描述：在启用 Hive 本地模式后，hive.log 报错 java.lang.OutOfMemoryError: Java heap space</p> <p>解决方案 1（临时）：</p> <p>在 Hive 客户端临时设置 io.sort.mb 和 mapreduce.task.io.sort.mb 两个参数的值为 10</p> <p>解决方案 2（永久生效）：
在$HIVE_HOME/conf 下添加 hive-env.sh。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 conf]$ pwd
/opt/module/hive/conf
[atguigu@hadoop102 conf]$ cp hive-env.sh.template hive-env.sh
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>然后将其中的参数 export HADOOP_HEAPSIZE=1024 的注释放开，然后重启 Hive。</p> <p><img src="/assets/img/image-20231018230009065.f4f32b89.png" alt="image-20231018230009065"></p> <p><img src="/assets/img/image-20231018230015070.1ba522e7.png" alt="image-20231018230015070"></p> <p>8）虚拟内存限制</p> <p>在 yarn-site.xml 中添加如下配置:</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;
    &lt;value&gt;false&lt;/value&gt;
 &lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h1 id="建议配置"><a href="#建议配置" class="header-anchor">#</a> 建议配置</h1> <div class="language- line-numbers-mode"><pre class="language-text"><code>set hive.exec.mode.local.auto;
set hive.exec.parallel;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>map 端 CUP 内存 默认8G 8C</p> <p>yarn 关闭虚拟内存限制检查 内存添加</p></div></div>  <div class="page-edit"><div class="edit-link"><a href="https://github.com/andanyang/vuepress-theme-vdoing/edit/master/docs/大数据/004.hive/005.hive调优.md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2024/03/11, 02:40:47</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/bigdata/hive_File_format_compressiont/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">Hive 件格式和压缩</div></a> <a href="/bigdata/hive_trap/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">Hive入门 的坑</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/bigdata/hive_File_format_compressiont/" class="prev">Hive 件格式和压缩</a></span> <span class="next"><a href="/bigdata/hive_trap/">Hive入门 的坑</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/bigdata/spark/SparkStreaming_Driver_Executer/"><div>
            spark中代码的执行位置（Driver or Executer）
            <!----></div></a> <span class="date">12-12</span></dt></dl><dl><dd>02</dd> <dt><a href="/bigdata/spark/SparkStreaming/"><div>
            大数据技术之 SparkStreaming
            <!----></div></a> <span class="date">12-12</span></dt></dl><dl><dd>03</dd> <dt><a href="/bigdata/spark/sql/"><div>
            Spark 核心编程之 RDD 累加器与广播变量
            <!----></div></a> <span class="date">12-06</span></dt></dl> <dl><dd></dd> <dt><a href="/archives/" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="mailto:1218853253@qq.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/andanyang" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="https://music.163.com/#/playlist?id=755597173" title="听音乐" target="_blank" class="iconfont icon-erji"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2019-2024
    <span>Young | <a href="https://github.com/andanyoung/young-blog/blob/master/LICENSE" target="_blank">MIT License</a> <br/> <a  href="https://beian.miit.gov.cn/" target="_blank">浙ICP备20002744号</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><div></div></div></div>
    <script src="/assets/js/app.e4caa6db.js" defer></script><script src="/assets/js/2.d1be14c5.js" defer></script><script src="/assets/js/4.93e1dc89.js" defer></script>
  </body>
</html>
