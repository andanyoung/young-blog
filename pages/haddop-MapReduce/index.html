<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>MapReduce编程框架 | Young&#39;s blog</title>
    <meta name="generator" content="VuePress 1.9.5">
    <link rel="icon" href="/img/favicon.ico">
    <meta name="description" content="Young丶java后端技术博客,专注后端学习与总结。擅长spring boot,JAVA基础总结,等方面的知识,关注spring,架构,elasticsearch,mysql领域.">
    <meta name="keywords" content="前端博客,个人技术博客,前端,前端开发,前端框架,web前端,前端面试题,技术文档,学习,面试,JavaScript,js,ES6,TypeScript,vue,python,css3,html5,Node,git,github,markdown">
    <meta name="baidu-site-verification" content="7F55weZDDc">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/assets/css/0.styles.d9c8cf8c.css" as="style"><link rel="preload" href="/assets/js/app.1c79bc59.js" as="script"><link rel="preload" href="/assets/js/2.e6b4ded9.js" as="script"><link rel="preload" href="/assets/js/10.1da3bb40.js" as="script"><link rel="prefetch" href="/assets/js/11.aac98347.js"><link rel="prefetch" href="/assets/js/12.821c3a4f.js"><link rel="prefetch" href="/assets/js/13.27cc968e.js"><link rel="prefetch" href="/assets/js/14.bbcd5517.js"><link rel="prefetch" href="/assets/js/15.cd44db53.js"><link rel="prefetch" href="/assets/js/16.8beaf223.js"><link rel="prefetch" href="/assets/js/17.e4347211.js"><link rel="prefetch" href="/assets/js/18.ca385235.js"><link rel="prefetch" href="/assets/js/19.0bd54467.js"><link rel="prefetch" href="/assets/js/20.98fdb15b.js"><link rel="prefetch" href="/assets/js/21.5ceac15d.js"><link rel="prefetch" href="/assets/js/22.7d0519ae.js"><link rel="prefetch" href="/assets/js/23.3aaec50f.js"><link rel="prefetch" href="/assets/js/24.94a4255f.js"><link rel="prefetch" href="/assets/js/25.7cb2f8e2.js"><link rel="prefetch" href="/assets/js/26.47d299f8.js"><link rel="prefetch" href="/assets/js/27.c1ad15db.js"><link rel="prefetch" href="/assets/js/28.d4106b74.js"><link rel="prefetch" href="/assets/js/29.560b92ce.js"><link rel="prefetch" href="/assets/js/3.bda6c48c.js"><link rel="prefetch" href="/assets/js/30.3fa2b87e.js"><link rel="prefetch" href="/assets/js/31.1a21f23b.js"><link rel="prefetch" href="/assets/js/32.106fc658.js"><link rel="prefetch" href="/assets/js/33.62e2d4b3.js"><link rel="prefetch" href="/assets/js/34.575d356a.js"><link rel="prefetch" href="/assets/js/35.fdd4301d.js"><link rel="prefetch" href="/assets/js/36.70ee7ac2.js"><link rel="prefetch" href="/assets/js/37.071d83a9.js"><link rel="prefetch" href="/assets/js/38.6a07c29c.js"><link rel="prefetch" href="/assets/js/39.7d107f45.js"><link rel="prefetch" href="/assets/js/4.5f318dcb.js"><link rel="prefetch" href="/assets/js/40.278a3776.js"><link rel="prefetch" href="/assets/js/41.cf861781.js"><link rel="prefetch" href="/assets/js/42.bb4dfb3f.js"><link rel="prefetch" href="/assets/js/43.b522ac3e.js"><link rel="prefetch" href="/assets/js/44.57b59c66.js"><link rel="prefetch" href="/assets/js/45.c1abc0f5.js"><link rel="prefetch" href="/assets/js/46.bd7f742c.js"><link rel="prefetch" href="/assets/js/47.749ef692.js"><link rel="prefetch" href="/assets/js/48.3824ae03.js"><link rel="prefetch" href="/assets/js/49.ed886ee0.js"><link rel="prefetch" href="/assets/js/5.cd833bc0.js"><link rel="prefetch" href="/assets/js/50.7fce343a.js"><link rel="prefetch" href="/assets/js/51.3424e1c2.js"><link rel="prefetch" href="/assets/js/52.31731e01.js"><link rel="prefetch" href="/assets/js/53.05986192.js"><link rel="prefetch" href="/assets/js/54.4b3d55d1.js"><link rel="prefetch" href="/assets/js/55.c631079c.js"><link rel="prefetch" href="/assets/js/56.9b4305a9.js"><link rel="prefetch" href="/assets/js/57.f8d6352c.js"><link rel="prefetch" href="/assets/js/58.538da1e0.js"><link rel="prefetch" href="/assets/js/59.95e41bb8.js"><link rel="prefetch" href="/assets/js/6.514a894b.js"><link rel="prefetch" href="/assets/js/60.d7e522a9.js"><link rel="prefetch" href="/assets/js/61.c2f54b31.js"><link rel="prefetch" href="/assets/js/62.f5ac6189.js"><link rel="prefetch" href="/assets/js/63.237d85c9.js"><link rel="prefetch" href="/assets/js/64.977c94ee.js"><link rel="prefetch" href="/assets/js/65.a877e700.js"><link rel="prefetch" href="/assets/js/66.60300b8b.js"><link rel="prefetch" href="/assets/js/67.a60b7915.js"><link rel="prefetch" href="/assets/js/68.fcb3d2b7.js"><link rel="prefetch" href="/assets/js/69.542cf7c2.js"><link rel="prefetch" href="/assets/js/7.d5a8367e.js"><link rel="prefetch" href="/assets/js/70.0d4b597a.js"><link rel="prefetch" href="/assets/js/71.68be559c.js"><link rel="prefetch" href="/assets/js/72.afe48fa8.js"><link rel="prefetch" href="/assets/js/73.4c5caea2.js"><link rel="prefetch" href="/assets/js/74.d0de988f.js"><link rel="prefetch" href="/assets/js/75.641bf3f0.js"><link rel="prefetch" href="/assets/js/76.4807538e.js"><link rel="prefetch" href="/assets/js/77.42fc5676.js"><link rel="prefetch" href="/assets/js/78.847da90a.js"><link rel="prefetch" href="/assets/js/79.104ae4a0.js"><link rel="prefetch" href="/assets/js/8.827d9bd8.js"><link rel="prefetch" href="/assets/js/80.e598f6ef.js"><link rel="prefetch" href="/assets/js/81.38be9d27.js"><link rel="prefetch" href="/assets/js/82.9d5cd2f5.js"><link rel="prefetch" href="/assets/js/83.0efa4887.js"><link rel="prefetch" href="/assets/js/84.ac2f99cd.js"><link rel="prefetch" href="/assets/js/85.b53ed975.js"><link rel="prefetch" href="/assets/js/86.bea88563.js"><link rel="prefetch" href="/assets/js/87.9ea10622.js"><link rel="prefetch" href="/assets/js/88.5d1627ea.js"><link rel="prefetch" href="/assets/js/89.abaf0298.js"><link rel="prefetch" href="/assets/js/9.92b947bb.js"><link rel="prefetch" href="/assets/js/90.539cce5f.js">
    <link rel="stylesheet" href="/assets/css/0.styles.d9c8cf8c.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/img/logo.png" alt="Young's blog" class="logo"> <span class="site-name can-hide">Young's blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/Spring/" class="nav-link">Spring</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="前端" class="dropdown-title"><a href="/web/" class="link-title">前端</a> <span class="title" style="display:none;">前端</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>前端文章1</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/8143cc480faf9a11/" class="nav-link">JavaScript</a></li></ul></li><li class="dropdown-item"><h4>学习笔记</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/note/javascript/" class="nav-link">《JavaScript教程》</a></li><li class="dropdown-subitem"><a href="/note/js/" class="nav-link">《JavaScript高级程序设计》</a></li><li class="dropdown-subitem"><a href="/note/es6/" class="nav-link">《ES6 教程》</a></li><li class="dropdown-subitem"><a href="/note/vue/" class="nav-link">《Vue》</a></li><li class="dropdown-subitem"><a href="/note/react/" class="nav-link">《React》</a></li><li class="dropdown-subitem"><a href="/note/typescript-axios/" class="nav-link">《TypeScript 从零实现 axios》</a></li><li class="dropdown-subitem"><a href="/note/git/" class="nav-link">《Git》</a></li><li class="dropdown-subitem"><a href="/pages/51afd6/" class="nav-link">TypeScript</a></li><li class="dropdown-subitem"><a href="/pages/4643cd/" class="nav-link">JS设计模式总结</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="页面" class="dropdown-title"><a href="/ui/" class="link-title">页面</a> <span class="title" style="display:none;">页面</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/8309a5b876fc95e3/" class="nav-link">HTML</a></li><li class="dropdown-item"><!----> <a href="/pages/0a83b083bdf257cb/" class="nav-link">CSS</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="技术" class="dropdown-title"><a href="/technology/" class="link-title">技术</a> <span class="title" style="display:none;">技术</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/9a7ee40fc232253e/" class="nav-link">技术文档</a></li><li class="dropdown-item"><!----> <a href="/pages/4c778760be26d8b3/" class="nav-link">GitHub技巧</a></li><li class="dropdown-item"><!----> <a href="/pages/117708e0af7f0bd9/" class="nav-link">Nodejs</a></li><li class="dropdown-item"><!----> <a href="/pages/41f87d890d0a02af/" class="nav-link">博客搭建</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="更多" class="dropdown-title"><a href="/more/" class="link-title">更多</a> <span class="title" style="display:none;">更多</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/f2a556/" class="nav-link">学习</a></li><li class="dropdown-item"><!----> <a href="/pages/aea6571b7a8bae86/" class="nav-link">面试</a></li><li class="dropdown-item"><!----> <a href="/pages/2d615df9a36a98ed/" class="nav-link">心情杂货</a></li><li class="dropdown-item"><!----> <a href="/pages/baaa02/" class="nav-link">实用技巧</a></li><li class="dropdown-item"><!----> <a href="/friends/" class="nav-link">友情链接</a></li></ul></div></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><a href="/pages/beb6c0bd8a66cea6/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/andanyang/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="/img/logo.png"> <div class="blogger-info"><h3>Young</h3> <span></span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/Spring/" class="nav-link">Spring</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="前端" class="dropdown-title"><a href="/web/" class="link-title">前端</a> <span class="title" style="display:none;">前端</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>前端文章1</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/8143cc480faf9a11/" class="nav-link">JavaScript</a></li></ul></li><li class="dropdown-item"><h4>学习笔记</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/note/javascript/" class="nav-link">《JavaScript教程》</a></li><li class="dropdown-subitem"><a href="/note/js/" class="nav-link">《JavaScript高级程序设计》</a></li><li class="dropdown-subitem"><a href="/note/es6/" class="nav-link">《ES6 教程》</a></li><li class="dropdown-subitem"><a href="/note/vue/" class="nav-link">《Vue》</a></li><li class="dropdown-subitem"><a href="/note/react/" class="nav-link">《React》</a></li><li class="dropdown-subitem"><a href="/note/typescript-axios/" class="nav-link">《TypeScript 从零实现 axios》</a></li><li class="dropdown-subitem"><a href="/note/git/" class="nav-link">《Git》</a></li><li class="dropdown-subitem"><a href="/pages/51afd6/" class="nav-link">TypeScript</a></li><li class="dropdown-subitem"><a href="/pages/4643cd/" class="nav-link">JS设计模式总结</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="页面" class="dropdown-title"><a href="/ui/" class="link-title">页面</a> <span class="title" style="display:none;">页面</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/8309a5b876fc95e3/" class="nav-link">HTML</a></li><li class="dropdown-item"><!----> <a href="/pages/0a83b083bdf257cb/" class="nav-link">CSS</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="技术" class="dropdown-title"><a href="/technology/" class="link-title">技术</a> <span class="title" style="display:none;">技术</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/9a7ee40fc232253e/" class="nav-link">技术文档</a></li><li class="dropdown-item"><!----> <a href="/pages/4c778760be26d8b3/" class="nav-link">GitHub技巧</a></li><li class="dropdown-item"><!----> <a href="/pages/117708e0af7f0bd9/" class="nav-link">Nodejs</a></li><li class="dropdown-item"><!----> <a href="/pages/41f87d890d0a02af/" class="nav-link">博客搭建</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="更多" class="dropdown-title"><a href="/more/" class="link-title">更多</a> <span class="title" style="display:none;">更多</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/f2a556/" class="nav-link">学习</a></li><li class="dropdown-item"><!----> <a href="/pages/aea6571b7a8bae86/" class="nav-link">面试</a></li><li class="dropdown-item"><!----> <a href="/pages/2d615df9a36a98ed/" class="nav-link">心情杂货</a></li><li class="dropdown-item"><!----> <a href="/pages/baaa02/" class="nav-link">实用技巧</a></li><li class="dropdown-item"><!----> <a href="/friends/" class="nav-link">友情链接</a></li></ul></div></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><a href="/pages/beb6c0bd8a66cea6/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/andanyang/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><a href="/pages/bigdata-generality/" class="sidebar-link">大数据技术之大数据概论</a></li><li><a href="/pages/Hadoop-Concept-explanation/" class="sidebar-link">大数据技术之 Hadoop概念讲解</a></li><li><a href="/pages/Build-Hadoop-running-environment/" class="sidebar-link">大数据之Hadoop 运行环境搭建</a></li><li><a href="/pages/Hadoop-working-mechanism/" class="sidebar-link">Hadoop之HDFS详解以及工作机制介绍</a></li><li><a href="/pages/haddop-MapReduce/" aria-current="page" class="active sidebar-link">MapReduce编程框架</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_1-1-mapreduce-定义" class="sidebar-link">1.1 MapReduce 定义</a></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_1-2-mapreduce-优缺点" class="sidebar-link">1.2 MapReduce 优缺点</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_1-2-1-优点" class="sidebar-link">1.2.1 优点</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_1-2-2-缺点" class="sidebar-link">1.2.2 缺点</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_1-3-mapreduce-核心思想" class="sidebar-link">1.3 MapReduce 核心思想</a></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_1-4-mapreduce-进程" class="sidebar-link">1.4 MapReduce 进程</a></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_1-5-官方-wordcount-源码" class="sidebar-link">1.5 官方 WordCount 源码</a></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_1-6-常用数据序列化类型" class="sidebar-link">1.6 常用数据序列化类型</a></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_1-7-mapreduce-编程规范" class="sidebar-link">1.7 MapReduce 编程规范</a></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_1-8-wordcount-案例实操" class="sidebar-link">1.8 WordCount 案例实操</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_1-8-1-本地测试" class="sidebar-link">1.8.1 本地测试</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_1-8-2-提交到集群测试" class="sidebar-link">1.8.2 提交到集群测试</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_2-1-序列化概述" class="sidebar-link">2.1 序列化概述</a></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_2-2-自定义-bean-对象实现序列化接口-writable" class="sidebar-link">2.2 自定义 bean 对象实现序列化接口（Writable）</a></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_3-1-inputformat-数据输入" class="sidebar-link">3.1 InputFormat 数据输入</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-1-1-切片与-maptask-并行度决定机制" class="sidebar-link">3.1.1 切片与 MapTask 并行度决定机制</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-1-2-job-提交流程源码和切片源码详解" class="sidebar-link">!image-202306142039322733.1.2 Job 提交流程源码和切片源码详解</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-1-3-fileinputformat-切片机制" class="sidebar-link">3.1.3 FileInputFormat 切片机制</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_1、切片机制" class="sidebar-link">1、切片机制</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_2、案例分析" class="sidebar-link">2、案例分析</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-1-4-textinputformat" class="sidebar-link">3.1.4 TextInputFormat</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_1-fileinputformat-实现类" class="sidebar-link">1）FileInputFormat 实现类</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_2-textinputformat" class="sidebar-link">2）TextInputFormat</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-1-5-combinetextinputformat-切片机制" class="sidebar-link">3.1.5 CombineTextInputFormat 切片机制</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_1-虚拟存储过程" class="sidebar-link">（1）虚拟存储过程：</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_2-切片过程" class="sidebar-link">（2）切片过程：</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-1-6-combinetextinputformat-案例实操" class="sidebar-link">3.1.6 CombineTextInputFormat 案例实操</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_3-2-mapreduce-工作流程" class="sidebar-link">3.2 MapReduce 工作流程</a></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_3-3-shuffle-机制" class="sidebar-link">3.3 Shuffle 机制</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-3-1-shuffle-机制" class="sidebar-link">3.3.1 Shuffle 机制</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-3-2-partition-分区" class="sidebar-link">3.3.2 Partition 分区</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_1、问题引出" class="sidebar-link">1、问题引出</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_2、默认partitioner分区" class="sidebar-link">2、默认Partitioner分区</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_3、自定义partitioner步骤" class="sidebar-link">3、自定义Partitioner步骤</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_4、分区总结" class="sidebar-link">4、分区总结</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_5、案例分析" class="sidebar-link">5、案例分析</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-3-3-partition-分区案例实操" class="sidebar-link">3.3.3 Partition 分区案例实操</a></li></ul></li></ul></li><li><a href="/pages/4a90c0/" class="sidebar-link">hadoo3.x 在windows10下编译</a></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/categories/?category=Hadoop" title="分类" data-v-06225672>Hadoop</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/andanyoung" target="_blank" title="作者" class="beLink" data-v-06225672>andanyang</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2023-06-05</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABGpJREFUSA3tVVtoXFUU3fvOI53UlmCaKIFmwEhsE7QK0ipFEdHEKpXaZGrp15SINsXUWvBDpBgQRKi0+KKoFeJHfZA+ED9KKoIU2gYD9UejTW4rVIzm0VSTziPzuNu1z507dibTTjL4U/DAzLn3nL3X2o91ziX6f9wMFdh6Jvbm9nNSV0msViVO6tN1Rm7NMu2OpeJ9lWBUTDxrJbYTS0hInuwciu9eLHlFxCLCZEk3MegsJmZ5K/JD6t7FkFdEvGUo1g7qJoG3MHImqRIn8/nzY1K9UPKKiJmtnUqHVE3Gbuay6vJE/N2FEmuxFjW2nUuE0yQXRRxLiTUAzs36zhZvOXJPdX850EVnnLZkB8prodQoM5JGj7Xk2mvC7JB8tG04Ef5PiXtG0UtxupRQSfTnBoCy554x18yJHI6I+G5Eru4LHmPJZEQsrvPUbMiA8G/WgMK7w7I+ez7++o2ANfbrjvaOl1tFMs+htG3IrZH9/hDX1Pr8Tc0UvH8tcX29KzAgIGcEkINyW5BF9x891hw6VYqgJHEk0huccS7vh3C6gTiODL+26huuBtbct8eZnqLML8PkxGYpuPZBqtqwkSjgc4mB5gbgig5i+y0UDK35LMxXisn9xQtK+nd26gTIHsHe/oblK/b29fUmN/8Y+9jAQrnBp56m1LcDlDp9irKTExSKduXJVWSqdBMA08pEJnEIOB3FPPMybu/oeV8zFeYN3xx576Q6RH+VmplE4ncQV5v+5rzSoyOU7PuEAg8g803PwBJ0CExno/jcMbN8tONYeOmHiuUNryvm3fRUy4tMPVLdAGkUhNWuggGrJcXPv+ouCjz0MKUHz1J2/E8IC9nqTabcxgaBYM0hPhD5Y65FsbxRQKxCQrDjDctW7PUM3HuZunFyifSAqEfuzCp48Il24luWUWZoyJCaPR82jE0+kFA643wRFVni4RYSq3ohJO2pZ7B5dO4xkDWbEpossJPLSrPjYID8rS2UHTlvyNxqIGsg674XJJ7vnh5L7PNwC4hh2sjCI96mzszOTpxLF0T7l88Yz7lAuK6OnL8gXLOnTvpzSb22YG8W7us3jSebFHeeqnXRG1vt+MoUM84LQIBmMsCTAcOauTh0T0l0neQK7m2bLMt2mGxU3HYssS0J2cdv5wljlPsrIuZLAG/2DOZIXgCYT8uMGZN+e2kSirfxZOPCsC0f24nTZzspnVn9VePS1Z5vubmAGGXG8ZFno9Hel0yfA5ZPhF7Dh972BQJ2qCpgH67lmWtBYbvk6sz02wjky2vXyz0XErP/kFB619js1BtwfOV4OPRqOQBjy3Qbk18vigUPPSD5ceHnwck7W9bhAqZdd7SuG7w4/P2F/GaJh8c7e9qgow+Q7cGBo+98WsLkuktFqiZabtXuQTu/Y5ETbR0v7tNSFnvrmu6pjdoan2KjMu8q/Hmj1EfCO2ZGfEIbIXKUlw8qaX9/b2oeSJmFksSeT/Fn0V3nSypChh4Gjh74ybO9aeZ/AN2dwciu2/MhAAAAAElFTkSuQmCC">MapReduce编程框架<!----></h1>  <div class="theme-vdoing-content content__default"><h1 id="_1-mapreduce-概述"><a href="#_1-mapreduce-概述" class="header-anchor">#</a> 1. MapReduce 概述</h1> <h2 id="_1-1-mapreduce-定义"><a href="#_1-1-mapreduce-定义" class="header-anchor">#</a> 1.1 MapReduce 定义</h2> <p>MapReduce 是一个<strong>分布式运算程序</strong>的编程框架，是用户开发“基于 Hadoop 的数据分析应用”的核心框架。</p> <p>MapReduce 核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个 Hadoop 集群上。</p> <h2 id="_1-2-mapreduce-优缺点"><a href="#_1-2-mapreduce-优缺点" class="header-anchor">#</a> 1.2 MapReduce 优缺点</h2> <h3 id="_1-2-1-优点"><a href="#_1-2-1-优点" class="header-anchor">#</a> 1.2.1 优点</h3> <p>1）MapReduce 易于编程</p> <p><strong>它简单的实现一些接口，就可以完成一个分布式程序</strong>，这个分布式程序可以分布到大量 廉价的 PC 机器上运行。也就是说你写一个分布式程序，跟写一个简单的串行程序是一模一样的。就是因为这个特点使得 MapReduce 编程变得非常流行。</p> <p>2）良好的扩展性</p> <p>当你的计算资源不能得到满足的时候，你可以通过<strong>简单的增加机器</strong>来扩展它的计算能力。</p> <p>3）高容错性</p> <p>MapReduce 设计的初衷就是使程序能够部署在廉价的 PC 机器上，这就要求它具有很高 的容错性。比如**其中一台机器挂了，它可以把上面的计算任务转移到另外一个节点上运行， 不至于这个任务运行失败，**而且这个过程不需要人工参与，而完全是由 Hadoop 内部完成的。</p> <p>4）适合 PB 级以上海量数据的离线处理</p> <p>可以实现上千台服务器集群并发工作，提供数据处理能力。</p> <h3 id="_1-2-2-缺点"><a href="#_1-2-2-缺点" class="header-anchor">#</a> 1.2.2 缺点</h3> <p>1）不擅长实时计算</p> <p>MapReduce 无法像 MySQL 一样，在毫秒或者秒级内返回结果。</p> <p>2）不擅长流式计算</p> <p>流式计算的输入数据是动态的，而 MapReduce 的<strong>输入数据集是静态</strong>的，不能动态变化。 这是因为 MapReduce 自身的设计特点决定了数据源必须是静态的。</p> <p>3）不擅长 DAG（有向无环图）计算</p> <p>多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下， MapReduce 并不是不能做，而是使用后，每个 MapReduce 作业的输出结果都会写入到磁盘， 会造成大量的磁盘 IO，导致性能非常的低下。</p> <h2 id="_1-3-mapreduce-核心思想"><a href="#_1-3-mapreduce-核心思想" class="header-anchor">#</a> 1.3 MapReduce 核心思想</h2> <p><img src="/assets/img/image-20230608222632302.fb87a7d7.png" alt="image-20230608222632302"></p> <p>（1）分布式的运算程序往往需要分成至少 2 个阶段。</p> <p>（2）第一个阶段的 MapTask 并发实例，完全并行运行，互不相干。 （3）第二个阶段的 ReduceTask 并发实例互不相干，但是他们的数据依赖于上一个阶段的所有 MapTask 并发实例的输出。</p> <p>（4）MapReduce 编程模型只能包含一个 Map 阶段和一个 Reduce 阶段，如果用户的业 务逻辑非常复杂，那就只能多个 MapReduce 程序，串行运行。</p> <p>总结：分析 WordCount   数据流走向深入理解 MapReduce 核心思想。</p> <h2 id="_1-4-mapreduce-进程"><a href="#_1-4-mapreduce-进程" class="header-anchor">#</a> 1.4 MapReduce 进程</h2> <p>一个完整的 MapReduce 程序在分布式运行时有三类实例进程：</p> <p>（1）MrAppMaster：负责整个程序的过程调度及状态协调。</p> <p>（2）MapTask：负责 Map 阶段的整个数据处理流程。</p> <p>（3）ReduceTask：负责 Reduce 阶段的整个数据处理流程。</p> <h2 id="_1-5-官方-wordcount-源码"><a href="#_1-5-官方-wordcount-源码" class="header-anchor">#</a> 1.5 官方 WordCount 源码</h2> <p>采用反编译工具反编译源码，发现 WordCount 案例有 Map 类、Reduce 类和驱动类。且 数据的类型是 Hadoop 自身封装的序列化类型。</p> <h2 id="_1-6-常用数据序列化类型"><a href="#_1-6-常用数据序列化类型" class="header-anchor">#</a> 1.6 常用数据序列化类型</h2> <table><thead><tr><th>Java基本类型</th> <th>Hadoop Writable类型</th></tr></thead> <tbody><tr><td>boolean</td> <td>BooleanWritable</td></tr> <tr><td>byte</td> <td>ByteWritable</td></tr> <tr><td>int</td> <td>IntWritable</td></tr> <tr><td>float</td> <td>FloatWritable</td></tr> <tr><td>long</td> <td>LongWritable</td></tr> <tr><td>double</td> <td>DoubleWritable</td></tr> <tr><td>String</td> <td>Text</td></tr> <tr><td>map</td> <td>MapWritable</td></tr> <tr><td>array</td> <td>ArrayWritable</td></tr></tbody></table> <h2 id="_1-7-mapreduce-编程规范"><a href="#_1-7-mapreduce-编程规范" class="header-anchor">#</a> 1.7 MapReduce 编程规范</h2> <p>用户编写的程序分成三个部分：Mapper、Reducer 和 Driver。</p> <p>1．Mapper阶段</p> <p>（1）用户自定义的Mapper要继承自己的父类</p> <p>（2）Mapper的输入数据是KV对的形式（KV的类型可自定义）</p> <p>（3）Mapper中的业务逻辑写在map()方法中</p> <p>（4）Mapper的输出数据是KV对的形式（KV的类型可自定义）</p> <p>（5）<strong>map()方法（MapTask进程）对每一个调用一次</strong></p> <p>2．Reducer阶段</p> <p>（1）用户自定义的Reducer要继承自己的父类</p> <p>（2）Reducer的输入数据类型对应Mapper的输出数据类型，也是KV （3）Reducer的业务逻辑写在reduce()方法中</p> <p>（4）<strong>ReduceTask进程对每一组相同k的组调用一次reduce()方法</strong></p> <p>3．Driver阶段</p> <p>相当于YARN集群的客户端，用于提交我们整个程序到YARN集群，提交的是封装了MapReduce程序相关运行参数的job对象</p> <h2 id="_1-8-wordcount-案例实操"><a href="#_1-8-wordcount-案例实操" class="header-anchor">#</a> 1.8 WordCount 案例实操</h2> <h3 id="_1-8-1-本地测试"><a href="#_1-8-1-本地测试" class="header-anchor">#</a> 1.8.1 本地测试</h3> <p>1）需求</p> <p>在给定的文本文件中统计输出每一个单词出现的总次数</p> <p>2）需求分析</p> <p>按照 MapReduce 编程规范，分别编写 Mapper，Reducer，Driver。</p> <p>3）环境准备</p> <p>（1）创建 maven 工程，MapReduceDemo</p> <p>（2）在 pom.xml 文件中添加如下依赖</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>  &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
            &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;
            &lt;version&gt;3.1.3&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;junit&lt;/groupId&gt;
            &lt;artifactId&gt;junit&lt;/artifactId&gt;
            &lt;version&gt;4.12&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
            &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;
            &lt;version&gt;1.7.30&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br></div></div><p>（2）在项目的 src/main/resources 目录下，新建一个文件，命名为“log4j.properties”，在 文件中填入。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>log4j.rootLogger=INFO, stdout 
log4j.appender.stdout=org.apache.log4j.ConsoleAppender 
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout 
log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n 
log4j.appender.logfile=org.apache.log4j.FileAppender 
log4j.appender.logfile.File=target/spring.log 
log4j.appender.logfile.layout=org.apache.log4j.PatternLayout 
log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>4）编写程序</p> <p>（1）编写 Mapper 类</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;
/**
 * KEYIN, map阶段输入的key的类型：LongWritable
 * VALUEIN,map阶段输入value类型：Text
 * KEYOUT,map阶段输出的Key类型：Text
 * VALUEOUT,map阶段输出的value类型：IntWritable
 */
public class WordCountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {
    private Text outK = new Text();
    private IntWritable outV = new IntWritable(1);

    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {

        // 1 获取一行
        // atguigu atguigu
        String line = value.toString();

        // 2 切割
        // atguigu
        // atguigu
        String[] words = line.split(&quot; &quot;);

        // 3 循环写出
        for (String word : words) {
            // 封装outk
            outK.set(word);

            // 写出
            context.write(outK, outV);
        }
    }
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br></div></div><p>（2）编写 Reducer 类</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

import java.io.IOException;
/**
 * KEYIN, reduce阶段输入的key的类型：Text
 * VALUEIN,reduce阶段输入value类型：IntWritable
 * KEYOUT,reduce阶段输出的Key类型：Text
 * VALUEOUT,reduce阶段输出的value类型：IntWritable
 */
public class WordCountReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
    private IntWritable outV = new IntWritable();

    @Override
    protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {

        int sum = 0;
        // atguigu, (1,1)
        // 累加
        for (IntWritable value : values) {
            sum += value.get();
        }

        outV.set(sum);

        // 写出
        context.write(key, outV);
    }
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br></div></div><p>（3）编写 Driver 驱动类</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import java.io.IOException;

/**
 * @author andanyoung
 * @version 1.0
 * @date 2023/6/8 22:55
 */

public class WordCountDriver {

    public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {

        // 1 获取job
        Configuration conf = new Configuration();
        //conf.set(&quot;fs.defaultFS&quot;, &quot;hdfs://node1:8020&quot;);
        Job job = Job.getInstance(conf);

        // 2 设置jar包路径
        job.setJarByClass(WordCountDriver.class);

        // 3 关联mapper和reducer
        job.setMapperClass(WordCountMapper.class);
        job.setReducerClass(WordCountReducer.class);

        // 4 设置map输出的kv类型
        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(IntWritable.class);

        // 5 设置最终输出的kV类型
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);

        // 6 设置输入路径和输出路径
        FileInputFormat.setInputPaths(job, new Path(&quot;F:\\hadoop-test\\wc.txt&quot;));
        FileOutputFormat.setOutputPath(job, new Path(&quot;F:\\hadoop-out11&quot;));

        // 7 提交job
        boolean result = job.waitForCompletion(true);

        System.exit(result ? 0 : 1);
    }
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br></div></div><p>5）本地测试</p> <p>（1）需要首先配置好 HADOOP_HOME 变量以及 Windows 运行依赖</p> <p>（2）在 IDEA/Eclipse 上运行程序</p> <h3 id="_1-8-2-提交到集群测试"><a href="#_1-8-2-提交到集群测试" class="header-anchor">#</a> 1.8.2 提交到集群测试</h3> <p>集群上测试</p> <p>（1）用 maven 打 jar 包，需要添加的打包插件依赖</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.6.1&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;source&gt;1.8&lt;/source&gt;
                    &lt;target&gt;1.8&lt;/target&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
            &lt;plugin&gt;
                &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;descriptorRefs&gt;
                        &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;
                    &lt;/descriptorRefs&gt;
                &lt;/configuration&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;id&gt;make-assembly&lt;/id&gt;
                        &lt;phase&gt;package&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;single&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br></div></div><p>（2）将程序打成 jar 包</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>mvn clean package
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（3）修改不带依赖的 jar 包名称为 wc.jar，并拷贝该 jar 包到 Hadoop 集群的 /opt/module/hadoop-3.1.3 路径</p> <p>（4）启动 Hadoop 集群</p> <p>（5）执行 WordCount 程序</p> <div class="language- line-numbers-mode"><pre class="language-text"><code> hadoop jar wc.jar
com.atguigu.mapreduce.wordcount.WordCountDriver /user/atguigu/input 
/user/atguigu/output
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h1 id="_2-hadoop-序列化"><a href="#_2-hadoop-序列化" class="header-anchor">#</a> 2. Hadoop 序列化</h1> <h2 id="_2-1-序列化概述"><a href="#_2-1-序列化概述" class="header-anchor">#</a> 2.1 序列化概述</h2> <p>1）什么是序列化</p> <p><strong>序列化</strong>就是把<strong>内存中的对象，转换成字节序列</strong>（或其他数据传输协议）以便于存储到磁盘（持久化）和网络传输。</p> <p><strong>反序列化</strong>就是将收到字节序列（或其他数据传输协议）或者是磁盘的持久化数据，转换成内存中的对象。</p> <p>2）为什么要序列化</p> <p>一般来说，“活的”对象只生存在内存里，关机断电就没有了。而且“活的”对象只能 由本地的进程使用，不能被发送到网络上的另外一台计算机。 然而序列化可以存储“活的” 对象，可以将“活的”对象发送到远程计算机。</p> <p><strong>3）为什么不用 Java 的序列化</strong></p> <p>Java 的序列化是一个重量级序列化框架（Serializable），一个对象被序列化后，会附带很多额外的信息（各种校验信息，Header，继承体系等），不便于在网络中高效传输。所以， Hadoop 自己开发了一套序列化机制（Writable）。</p> <p>4）Hadoop 序列化特点：</p> <ul><li>（1）紧凑 ：高效使用存储空间。</li> <li>（2）快速：读写数据的额外开销小。</li> <li>（3）互操作：支持多语言的交互</li></ul> <p>Java基本类型与Hadoop常用序列化类型</p> <table><thead><tr><th>Java基本类型</th> <th>Hadoop Writable类型</th></tr></thead> <tbody><tr><td>boolean</td> <td>BooleanWritable</td></tr> <tr><td>byte</td> <td>ByteWritable</td></tr> <tr><td>int</td> <td>IntWritable</td></tr> <tr><td>float</td> <td>FloatWritable</td></tr> <tr><td>long</td> <td>LongWritable</td></tr> <tr><td>double</td> <td>DoubleWritable</td></tr> <tr><td>String</td> <td>Text</td></tr> <tr><td>map</td> <td>MapWritable</td></tr> <tr><td>array</td> <td>ArrayWritable</td></tr></tbody></table> <h2 id="_2-2-自定义-bean-对象实现序列化接口-writable"><a href="#_2-2-自定义-bean-对象实现序列化接口-writable" class="header-anchor">#</a> 2.2 自定义 bean 对象实现序列化接口（Writable）</h2> <p>在企业开发中往往常用的基本序列化类型不能满足所有需求，比如在 Hadoop 框架内部 传递一个 bean 对象，那么该对象就需要实现序列化接口。</p> <p>具体实现 bean 对象序列化步骤如下 7 步。</p> <p>（1）必须实现 <code>Writable</code> 接口</p> <p>（2）反序列化时，需要反射调用空参构造函数，所以必须有空参构造</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>public FlowBean() {
	super();
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>（3）重写序列化方法</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>@Override
public void write(DataOutput out) throws IOException {
	out.writeLong(upFlow);
    out.writeLong(downFlow);
    out.writeLong(sumFlow);
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>（4）重写反序列化方法</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>@Override
public void readFields(DataInput in) throws IOException {
    upFlow = in.readLong();
    downFlow = in.readLong();
    sumFlow = in.readLong();
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>（5）<strong>注意反序列化的顺序和序列化的顺序完全一致</strong></p> <p>（6）要想把结果显示在文件中，需要重写 toString()，可用&quot;\t&quot;分开，方便后续用。</p> <p>（7）如果需要将自定义的 bean 放在 key 中传输，则还需要实现 Comparable 接口，因为 MapReduce 框中的 Shuffle 过程要求对 key 必须能排序。详见后面排序案例。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>@Override
public int compareTo(FlowBean o) {
    // 倒序排列，从大到小
    return this.sumFlow &gt; o.getSumFlow() ? -1 : 1;
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h1 id="_3-mapreduce-框架原理"><a href="#_3-mapreduce-框架原理" class="header-anchor">#</a> 3. MapReduce 框架原理</h1> <p><img src="/assets/img/image-20230614000658557.c9222082.png" alt="image-20230614000658557"></p> <h2 id="_3-1-inputformat-数据输入"><a href="#_3-1-inputformat-数据输入" class="header-anchor">#</a> 3.1 InputFormat 数据输入</h2> <h3 id="_3-1-1-切片与-maptask-并行度决定机制"><a href="#_3-1-1-切片与-maptask-并行度决定机制" class="header-anchor">#</a> 3.1.1 切片与 MapTask 并行度决定机制</h3> <p>1）问题引出</p> <p>MapTask 的并行度决定 Map 阶段的任务处理并发度，进而影响到整个 Job 的处理速度。</p> <p>思考：1G 的数据，启动 8 个 MapTask，可以提高集群的并发处理能力。那么 1K 的数据，也启动 8 个 MapTask，会提高集群性能吗？MapTask 并行任务是否越多越好呢？哪些因素影响了 MapTask 并行度？</p> <p>2）MapTask 并行度决定机制</p> <p>**数据块：**Block 是 HDFS 物理上把数据分成一块一块。数据块是 HDFS 存储数据单位。</p> <p>**数据切片：**数据切片只是在逻辑上对输入进行分片，并不会在磁盘上将其切分成片进行存储。数据切片是 MapReduce 程序计算输入数据的单位，一个切片会对应启动一个 MapTask。</p> <h3 id="_3-1-2-job-提交流程源码和切片源码详解"><a href="#_3-1-2-job-提交流程源码和切片源码详解" class="header-anchor">#</a> <img src="/assets/img/image-20230614203932273.f5718a8f.png" alt="image-20230614203932273">3.1.2 Job 提交流程源码和切片源码详解</h3> <p>1）Job 提交流程源码详解</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>waitForCompletion()

submit();

// 1建立连接
	connect();	
		// 1）创建提交Job的代理
		new Cluster(getConfiguration());
			// （1）判断是本地运行环境还是yarn集群运行环境
			initialize(jobTrackAddr, conf); 

// 2 提交job
submitter.submitJobInternal(Job.this, cluster)

	// 1）创建给集群提交数据的Stag路径
	Path jobStagingArea = JobSubmissionFiles.getStagingDir(cluster, conf);

	// 2）获取jobid ，并创建Job路径
	JobID jobId = submitClient.getNewJobID();

	// 3）拷贝jar包到集群
copyAndConfigureFiles(job, submitJobDir);	
	rUploader.uploadFiles(job, jobSubmitDir);

	// 4）计算切片，生成切片规划文件
writeSplits(job, submitJobDir);
		maps = writeNewSplits(job, jobSubmitDir);
		input.getSplits(job);

	// 5）向Stag路径写XML配置文件
writeConf(conf, submitJobFile);
	conf.writeXml(out);

	// 6）提交Job,返回提交状态
status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br></div></div><p><img src="/assets/img/image-20230614205242036.13e8fd91.png" alt="image-20230614205242036"></p> <p>2）FileInputFormat 切片源码解析（input.getSplits(job)）</p> <p><img src="/assets/img/image-20230614212624794.d7051f89.png" alt="image-20230614212624794"></p> <h3 id="_3-1-3-fileinputformat-切片机制"><a href="#_3-1-3-fileinputformat-切片机制" class="header-anchor">#</a> 3.1.3 FileInputFormat 切片机制</h3> <h4 id="_1、切片机制"><a href="#_1、切片机制" class="header-anchor">#</a> 1、切片机制</h4> <p>（1）简单地按照文件的内容长度进行切片</p> <p>（2）切片大小，默认等于Block大小</p> <p><strong>（3）切片时不考虑数据集整体，而是逐个针对每一个文件单独切片</strong></p> <h4 id="_2、案例分析"><a href="#_2、案例分析" class="header-anchor">#</a> 2、案例分析</h4> <p><img src="/assets/img/image-20230614212747456.d97ea604.png" alt="image-20230614212747456"></p> <p>（1）源码中计算切片大小的公式</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>Math.max(minSize, Math.min(maxSize, blockSize));
mapreduce.input.fileinputformat.split.minsize=1 默认值为1
mapreduce.input.fileinputformat.split.maxsize= Long.MAXValue 默认值Long.MAXValu
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>因此，<strong>默认情况下，切片大小=blocksize。</strong></p> <p>（2）切片大小设置</p> <p>maxsize（切片最大值）：参数如果调得比blockSize小，则会让切片变小，而且就等于配置的这个参数的值。 minsize（切片最小值）：参数调的比blockSize大，则可以让切片变得比blockSize还大。</p> <p>（3）获取切片信息API</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>// 获取切片的文件名称
String name = inputSplit.getPath().getName();
// 根据文件类型获取切片信息
FileSplit inputSplit = (FileSplit) context.getInputSplit();
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h3 id="_3-1-4-textinputformat"><a href="#_3-1-4-textinputformat" class="header-anchor">#</a> 3.1.4 TextInputFormat</h3> <h4 id="_1-fileinputformat-实现类"><a href="#_1-fileinputformat-实现类" class="header-anchor">#</a> 1）FileInputFormat 实现类</h4> <p>思考：<strong>在运行 MapReduce 程序时，输入的文件格式包括：基于行的日志文件、二进制格式文件、数据库表等。</strong> 那么，针对不同的数据类型，MapReduce 是如何读取这些数据的呢？</p> <p>FileInputFormat 常见的接口实现类包括：TextInputFormat、KeyValueTextInputFormat、NLineInputFormat、CombineTextInputFormat 和自定义 InputFormat 等</p> <h4 id="_2-textinputformat"><a href="#_2-textinputformat" class="header-anchor">#</a> 2）TextInputFormat</h4> <p>TextInputFormat 是<strong>默认的</strong> FileInputFormat 实现类。按行读取每条记录。**键是存储该行在整个文件中的起始字节偏移量， LongWritable 类型。值是这行的内容，**不包括任何行终止符（换行符和回车符），Text 类型。</p> <p>以下是一个示例，比如，一个分片包含了如下 4 条文本记录。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>Rich learning form
Intelligent learning engine
Learning more convenient
From the real demand for more close to the enterprise
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>每条记录表示为以下键/值对：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>(0,Rich learning form)
(20,Intelligent learning engine)
(49,Learning more convenient)
(74,From the real demand for more close to the enterprise)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h3 id="_3-1-5-combinetextinputformat-切片机制"><a href="#_3-1-5-combinetextinputformat-切片机制" class="header-anchor">#</a> 3.1.5 CombineTextInputFormat 切片机制</h3> <p>框架默认的 TextInputFormat 切片机制是对任务按文件规划切片，**不管文件多小，都会是一个单独的切片，**都会交给一个 MapTask，这样如果有大量小文件，就会产生大量的 <strong>MapTask</strong>(一个MapTask 消耗一个CPU ，1G内存)，处理效率极其低下。</p> <p>1）应用场景：</p> <p>CombineTextInputFormat 用于小文件过多的场景，它可以将多个小文件从逻辑上规划到 一个切片中，这样，多个小文件就可以交给一个 MapTask 处理。</p> <p>2）虚拟存储切片最大值设置</p> <p>CombineTextInputFormat.setMaxInputSplitSize(job, 4194304);// 4m</p> <p>注意：虚拟存储切片最大值设置最好根据实际的小文件大小情况来设置具体的值。</p> <p>3）切片机制</p> <p>生成切片过程包括：虚拟存储过程和切片过程二部分</p> <p>setMaxInputSplitSize值为4M</p> <p><img src="/assets/img/image-20230614224847034.989babb6.png" alt="image-20230614224847034"></p> <h4 id="_1-虚拟存储过程"><a href="#_1-虚拟存储过程" class="header-anchor">#</a> （1）虚拟存储过程：</h4> <p>将输入目录下所有文件大小，依次和设置的 setMaxInputSplitSize 值比较，如果不大于设置的最大值，逻辑上划分一个块。如果输入文件大于设置的最大值且大于两倍， 那么以最大值切割一块；<strong>当剩余数据大小超过设置的最大值且不大于最大值 2 倍，此时将文件均分成 2 个虚拟存储块（防止出现太小切片）。</strong></p> <p>例如 setMaxInputSplitSize 值为 4M，输入文件大小为 8.02M，则先逻辑上分成一个 4M。剩余的大小为 4.02M，如果按照 4M 逻辑划分，就会出现 0.02M 的小的虚拟存储 文件，所以将剩余的 4.02M 文件切分成（2.01M 和 2.01M）两个文件。</p> <h4 id="_2-切片过程"><a href="#_2-切片过程" class="header-anchor">#</a> （2）切片过程：</h4> <ul><li><p>（a）判断虚拟存储的文件大小是否大于 setMaxInputSplitSize 值，大于等于则单独形成一个切片。</p></li> <li><p>（b）如果不大于则跟下一个虚拟存储文件进行合并，共同形成一个切片。</p></li> <li><p>（c）测试举例：有 4 个小文件大小分别为 1.7M、5.1M、3.4M 以及 6.8M 这四个小 文件，则虚拟存储之后形成 6 个文件块，大小分别为：</p> <p>1.7M，（2.55M、2.55M），3.4M 以及（3.4M、3.4M）</p> <p>最终会形成 3 个切片，大小分别为： （1.7+2.55）M，（2.55+3.4）M，（3.4+3.4）M</p></li></ul> <h3 id="_3-1-6-combinetextinputformat-案例实操"><a href="#_3-1-6-combinetextinputformat-案例实操" class="header-anchor">#</a> 3.1.6 CombineTextInputFormat 案例实操</h3> <p>1）需求</p> <p>将输入的大量小文件合并成一个切片统一处理。</p> <ul><li><p>（1）输入数据 准备 4 个小文件</p> <p><img src="/assets/img/image-20230614225641606.cb3d8ec2.png" alt="image-20230614225641606"></p></li> <li><p>（2）期望</p> <p>期望一个切片处理 4 个文件</p></li></ul> <p>2）实现过程</p> <ul><li><p>（1）不做任何处理，运行 1.8 节的 WordCount 案例程序，观察切片个数为 4。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>number of splits:4
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li> <li><p>（2）在 WordcountDriver 中增加如下代码，运行程序，并观察运行的切片个数为 3。</p> <p>（a）驱动类中添加代码如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>// 如果不设置 InputFormat，它默认用的是 TextInputFormat.class
job.setInputFormatClass(CombineTextInputFormat.class);
//虚拟存储切片最大值设置 4m
CombineTextInputFormat.setMaxInputSplitSize(job, 4194304);
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>（b）运行如果为 3 个切片。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>number of splits:3
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li> <li><p>（3）在 WordcountDriver 中增加如下代码，运行程序，并观察运行的切片个数为 1。</p> <p>（a）驱动中添加代码如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>// 如果不设置 InputFormat，它默认用的是 TextInputFormat.class
job.setInputFormatClass(CombineTextInputFormat.class);
//虚拟存储切片最大值设置 20m
CombineTextInputFormat.setMaxInputSplitSize(job, 20971520);
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>（b）运行如果为 1 个切片</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>number of splits:1
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h2 id="_3-2-mapreduce-工作流程"><a href="#_3-2-mapreduce-工作流程" class="header-anchor">#</a> 3.2 MapReduce 工作流程</h2> <p><img src="/assets/img/image-20230614230134735.d5012940.png" alt="image-20230614230134735"></p></li></ul> <p><img src="/assets/img/image-20230614230202750.8793b2ed.png" alt="image-20230614230202750"></p> <p>上面的流程是整个 MapReduce 最全工作流程，但是 Shuffle 过程只是从第 7 步开始到第 16 步结束，具体 Shuffle 过程详解，如下：</p> <ul><li>（1）MapTask 收集我们的 map()方法输出的 kv 对，放到内存缓冲区中</li> <li>（2）从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件</li> <li>（3）多个溢出文件会被合并成大的溢出文件</li> <li>（4）在溢出过程及合并的过程中，都要调用 Partitioner 进行分区和针对 key 进行排序</li> <li>（5）ReduceTask 根据自己的分区号，去各个 MapTask 机器上取相应的结果分区数据</li> <li>（6）ReduceTask 会抓取到同一个分区的来自不同 MapTask 的结果文件，ReduceTask 会将这些文件再进行合并（归并排序）</li> <li>（7）合并成大文件后，Shuffle 的过程也就结束了，后面进入 ReduceTask 的逻辑运算过程（从文件中取出一个一个的键值对 Group，调用用户自定义的 reduce()方法）</li></ul> <p>注意：</p> <p>（1）Shuffle 中的缓冲区大小会影响到 MapReduce 程序的执行效率，原则上说，缓冲区越大，磁盘 io 的次数越少，执行速度就越快。</p> <p>（2）缓冲区的大小可以通过参数调整，参数：mapreduce.task.io.sort.mb 默认 100M。</p> <h2 id="_3-3-shuffle-机制"><a href="#_3-3-shuffle-机制" class="header-anchor">#</a> 3.3 Shuffle 机制</h2> <h3 id="_3-3-1-shuffle-机制"><a href="#_3-3-1-shuffle-机制" class="header-anchor">#</a> 3.3.1 Shuffle 机制</h3> <p>Map 方法之后，Reduce 方法之前的数据处理过程称之为 Shuffle。</p> <p><img src="/assets/img/image-20230614232316005.d760f77c.png" alt="image-20230614232316005"></p> <h3 id="_3-3-2-partition-分区"><a href="#_3-3-2-partition-分区" class="header-anchor">#</a> 3.3.2 Partition 分区</h3> <h4 id="_1、问题引出"><a href="#_1、问题引出" class="header-anchor">#</a> 1、问题引出</h4> <p>要求将统计结果按照条件输出到不同文件中（分区）。比如：将统计结果按照手机归属地不同省份输出到不同文件中（分区）</p> <h4 id="_2、默认partitioner分区"><a href="#_2、默认partitioner分区" class="header-anchor">#</a> 2、默认Partitioner分区</h4> <p><img src="/assets/img/image-20230614232752640.2c729faf.png" alt="image-20230614232752640"></p> <p>默 认分区是根据key的hashCode对ReduceTasks个数取模得到的。用户没法控制哪个 key存储到哪个分区。</p> <h4 id="_3、自定义partitioner步骤"><a href="#_3、自定义partitioner步骤" class="header-anchor">#</a> 3、自定义Partitioner步骤</h4> <p>（1）自定义类继承Partitioner，重写getPartition()方法</p> <p><img src="/assets/img/image-20230614232903693.9ada8df0.png" alt="image-20230614232903693">（2)在Job驱动中，设置自定义Partitioner</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>job.setPartitionerClass(CustomPartitioner.class);
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（3）自定义Partition后，要根据自定义Partitioner的逻辑设置相应数量的ReduceTask</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>job.setNumReduceTasks(5);
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h4 id="_4、分区总结"><a href="#_4、分区总结" class="header-anchor">#</a> 4、分区总结</h4> <p><img src="/assets/img/image-20230614233420614.59f2b0a6.png" alt="image-20230614233420614"></p> <h4 id="_5、案例分析"><a href="#_5、案例分析" class="header-anchor">#</a> 5、案例分析</h4> <p>例如：假设自定义分区数为5，则</p> <p>（1）job.setNumReduceTasks(1);  会正常运行，只不过会产生一个输出文件</p> <p>（2）job.setNumReduceTasks(2);  会报错</p> <p>（3）job.setNumReduceTasks(6);  大于5，程序会正常运行，会产生空文件</p> <h3 id="_3-3-3-partition-分区案例实操"><a href="#_3-3-3-partition-分区案例实操" class="header-anchor">#</a> 3.3.3 Partition 分区案例实操</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>package com.atguigu.mapreduce.partitioner;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Partitioner;
public class ProvincePartitioner extends Partitioner&lt;Text, FlowBean&gt; {
 @Override
 public int getPartition(Text text, FlowBean flowBean, int numPartitions) 
{
     //获取手机号前三位 prePhone
     String phone = text.toString();
     String prePhone = phone.substring(0, 3);
     //定义一个分区号变量 partition,根据 prePhone 设置分区号
     int partition;
     if(&quot;136&quot;.equals(prePhone)){
     	partition = 0;
     }else if(&quot;137&quot;.equals(prePhone)){
     	partition = 1;
     }else if(&quot;138&quot;.equals(prePhone)){
     	partition = 2;
     }else if(&quot;139&quot;.equals(prePhone)){
     	partition = 3;
     }else {
     	partition = 4;
     }
     //最后返回分区号 partition
     return partition;
 	}
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br></div></div><p>4）在驱动函数中增加自定义数据分区设置和 ReduceTask 设置</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>//8 指定自定义分区器
 job.setPartitionerClass(ProvincePartitioner.class);
 //9 同时指定相应数量的 ReduceTask
 job.setNumReduceTasks(5);
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div></div></div>  <div class="page-edit"><div class="edit-link"><a href="https://github.com/andanyang/vuepress-theme-vdoing/edit/master/docs/Hadoop/0005.MapReduce编程框架.md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <div class="tags"><a href="/tags/?tag=MapReduce" title="标签">#MapReduce</a></div> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2023/06/14, 15:40:04</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/pages/Hadoop-working-mechanism/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">Hadoop之HDFS详解以及工作机制介绍</div></a> <a href="/pages/4a90c0/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">hadoo3.x 在windows10下编译</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/pages/Hadoop-working-mechanism/" class="prev">Hadoop之HDFS详解以及工作机制介绍</a></span> <span class="next"><a href="/pages/4a90c0/">hadoo3.x 在windows10下编译</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/pages/4a90c0/"><div>
            hadoo3.x 在windows10下编译
            <!----></div></a> <span class="date">06-13</span></dt></dl><dl><dd>02</dd> <dt><a href="/bigdata/gainian-qubie/"><div>
            一文搞懂数据仓库、数据平台、数据中台、数据湖的概念和区别
            <!----></div></a> <span class="date">06-08</span></dt></dl><dl><dd>03</dd> <dt><a href="/pages/fcabaf/"><div>
            什么是多租户架构？
            <!----></div></a> <span class="date">06-08</span></dt></dl> <dl><dd></dd> <dt><a href="/archives/" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="mailto:1218853253@qq.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/andanyang" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="https://music.163.com/#/playlist?id=755597173" title="听音乐" target="_blank" class="iconfont icon-erji"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2019-2023
    <span>Young | <a href="https://github.com/andanyoung/young-blog/blob/master/LICENSE" target="_blank">MIT License</a> <br/> <a  href="https://beian.miit.gov.cn/" target="_blank">浙ICP备20002744号</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><div></div></div></div>
    <script src="/assets/js/app.1c79bc59.js" defer></script><script src="/assets/js/2.e6b4ded9.js" defer></script><script src="/assets/js/10.1da3bb40.js" defer></script>
  </body>
</html>
