<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>第五章MapReduce编程框架 | Young&#39;s blog</title>
    <meta name="generator" content="VuePress 1.9.5">
    <link rel="icon" href="/img/favicon.ico">
    <meta name="description" content="Young丶java后端技术博客,专注后端学习与总结。擅长spring boot,JAVA基础总结,等方面的知识,关注spring,架构,elasticsearch,mysql领域.">
    <meta name="keywords" content="前端博客,个人技术博客,前端,前端开发,前端框架,web前端,前端面试题,技术文档,学习,面试,JavaScript,js,ES6,TypeScript,vue,python,css3,html5,Node,git,github,markdown">
    <meta name="baidu-site-verification" content="7F55weZDDc">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/assets/css/0.styles.d9c8cf8c.css" as="style"><link rel="preload" href="/assets/js/app.9080ceff.js" as="script"><link rel="preload" href="/assets/js/2.47f2c7d0.js" as="script"><link rel="preload" href="/assets/js/4.e268042a.js" as="script"><link rel="prefetch" href="/assets/js/10.e570edea.js"><link rel="prefetch" href="/assets/js/100.704516fd.js"><link rel="prefetch" href="/assets/js/101.7957711a.js"><link rel="prefetch" href="/assets/js/102.4f6e7fa6.js"><link rel="prefetch" href="/assets/js/103.237e02c5.js"><link rel="prefetch" href="/assets/js/104.900051c8.js"><link rel="prefetch" href="/assets/js/11.ab42bc05.js"><link rel="prefetch" href="/assets/js/12.d9bedb1a.js"><link rel="prefetch" href="/assets/js/13.3595b48f.js"><link rel="prefetch" href="/assets/js/14.5375e1ab.js"><link rel="prefetch" href="/assets/js/15.aaaaabe7.js"><link rel="prefetch" href="/assets/js/16.09c0410d.js"><link rel="prefetch" href="/assets/js/17.73ed58ba.js"><link rel="prefetch" href="/assets/js/18.301245f4.js"><link rel="prefetch" href="/assets/js/19.ed3cd9a6.js"><link rel="prefetch" href="/assets/js/20.74a5523f.js"><link rel="prefetch" href="/assets/js/21.ec0a4bf5.js"><link rel="prefetch" href="/assets/js/22.b8cfe8bd.js"><link rel="prefetch" href="/assets/js/23.f592e4d5.js"><link rel="prefetch" href="/assets/js/24.24a36d86.js"><link rel="prefetch" href="/assets/js/25.ec3d3372.js"><link rel="prefetch" href="/assets/js/26.8e66b1a2.js"><link rel="prefetch" href="/assets/js/27.3c8bb21d.js"><link rel="prefetch" href="/assets/js/28.677ee1b2.js"><link rel="prefetch" href="/assets/js/29.4ca9d8c6.js"><link rel="prefetch" href="/assets/js/3.41e5d654.js"><link rel="prefetch" href="/assets/js/30.abf99ee2.js"><link rel="prefetch" href="/assets/js/31.29943eba.js"><link rel="prefetch" href="/assets/js/32.5104795c.js"><link rel="prefetch" href="/assets/js/33.54a3e4f5.js"><link rel="prefetch" href="/assets/js/34.6d2068fc.js"><link rel="prefetch" href="/assets/js/35.70dd5d37.js"><link rel="prefetch" href="/assets/js/36.6e016138.js"><link rel="prefetch" href="/assets/js/37.8d3947dd.js"><link rel="prefetch" href="/assets/js/38.f12d2cb6.js"><link rel="prefetch" href="/assets/js/39.fbc6ddca.js"><link rel="prefetch" href="/assets/js/40.c8ba4df3.js"><link rel="prefetch" href="/assets/js/41.20477b7d.js"><link rel="prefetch" href="/assets/js/42.8299e70d.js"><link rel="prefetch" href="/assets/js/43.80eafabf.js"><link rel="prefetch" href="/assets/js/44.07aaeeeb.js"><link rel="prefetch" href="/assets/js/45.2c0ce34f.js"><link rel="prefetch" href="/assets/js/46.26d9f6cd.js"><link rel="prefetch" href="/assets/js/47.72024be4.js"><link rel="prefetch" href="/assets/js/48.70ece35d.js"><link rel="prefetch" href="/assets/js/49.b809c4c5.js"><link rel="prefetch" href="/assets/js/5.38f48bda.js"><link rel="prefetch" href="/assets/js/50.4548569d.js"><link rel="prefetch" href="/assets/js/51.3489bbfc.js"><link rel="prefetch" href="/assets/js/52.9c1e7477.js"><link rel="prefetch" href="/assets/js/53.4ea1d8c4.js"><link rel="prefetch" href="/assets/js/54.7f9742fd.js"><link rel="prefetch" href="/assets/js/55.6ba84f15.js"><link rel="prefetch" href="/assets/js/56.02ac8847.js"><link rel="prefetch" href="/assets/js/57.f0b08f10.js"><link rel="prefetch" href="/assets/js/58.0c7673e1.js"><link rel="prefetch" href="/assets/js/59.08fa3af6.js"><link rel="prefetch" href="/assets/js/6.cff16d75.js"><link rel="prefetch" href="/assets/js/60.e3265050.js"><link rel="prefetch" href="/assets/js/61.764851a4.js"><link rel="prefetch" href="/assets/js/62.8a961ecc.js"><link rel="prefetch" href="/assets/js/63.5bdad7b0.js"><link rel="prefetch" href="/assets/js/64.2de347ae.js"><link rel="prefetch" href="/assets/js/65.949b0654.js"><link rel="prefetch" href="/assets/js/66.ef5f62b8.js"><link rel="prefetch" href="/assets/js/67.fa33a0ed.js"><link rel="prefetch" href="/assets/js/68.6cac0fac.js"><link rel="prefetch" href="/assets/js/69.4fa3e8e1.js"><link rel="prefetch" href="/assets/js/7.6df979f4.js"><link rel="prefetch" href="/assets/js/70.60fb8b34.js"><link rel="prefetch" href="/assets/js/71.b9e43875.js"><link rel="prefetch" href="/assets/js/72.99878ff7.js"><link rel="prefetch" href="/assets/js/73.bfc0cfc6.js"><link rel="prefetch" href="/assets/js/74.d57f911a.js"><link rel="prefetch" href="/assets/js/75.18d3967b.js"><link rel="prefetch" href="/assets/js/76.d3cce02d.js"><link rel="prefetch" href="/assets/js/77.aa765f49.js"><link rel="prefetch" href="/assets/js/78.21172fdd.js"><link rel="prefetch" href="/assets/js/79.4a1cfe9d.js"><link rel="prefetch" href="/assets/js/8.51ea646e.js"><link rel="prefetch" href="/assets/js/80.fbbd86bc.js"><link rel="prefetch" href="/assets/js/81.82d3fdf2.js"><link rel="prefetch" href="/assets/js/82.8cadf34b.js"><link rel="prefetch" href="/assets/js/83.6b9e4985.js"><link rel="prefetch" href="/assets/js/84.9efaa713.js"><link rel="prefetch" href="/assets/js/85.62502ef2.js"><link rel="prefetch" href="/assets/js/86.19b5ee6b.js"><link rel="prefetch" href="/assets/js/87.770184ac.js"><link rel="prefetch" href="/assets/js/88.9900f9d0.js"><link rel="prefetch" href="/assets/js/89.fc259fc3.js"><link rel="prefetch" href="/assets/js/9.d6ac0356.js"><link rel="prefetch" href="/assets/js/90.9ea483ca.js"><link rel="prefetch" href="/assets/js/91.60fffc53.js"><link rel="prefetch" href="/assets/js/92.caa0f1d8.js"><link rel="prefetch" href="/assets/js/93.56bfeda7.js"><link rel="prefetch" href="/assets/js/94.e9fccae8.js"><link rel="prefetch" href="/assets/js/95.600ae64d.js"><link rel="prefetch" href="/assets/js/96.fbd4507a.js"><link rel="prefetch" href="/assets/js/97.f7c772cf.js"><link rel="prefetch" href="/assets/js/98.eb8b1ae1.js"><link rel="prefetch" href="/assets/js/99.c1b07761.js">
    <link rel="stylesheet" href="/assets/css/0.styles.d9c8cf8c.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/img/logo.png" alt="Young's blog" class="logo"> <span class="site-name can-hide">Young's blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/Spring/" class="nav-link">Spring</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="前端" class="dropdown-title"><a href="/web/" class="link-title">前端</a> <span class="title" style="display:none;">前端</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>前端文章1</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/8143cc480faf9a11/" class="nav-link">JavaScript</a></li></ul></li><li class="dropdown-item"><h4>学习笔记</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/note/javascript/" class="nav-link">《JavaScript教程》</a></li><li class="dropdown-subitem"><a href="/note/js/" class="nav-link">《JavaScript高级程序设计》</a></li><li class="dropdown-subitem"><a href="/note/es6/" class="nav-link">《ES6 教程》</a></li><li class="dropdown-subitem"><a href="/note/vue/" class="nav-link">《Vue》</a></li><li class="dropdown-subitem"><a href="/note/react/" class="nav-link">《React》</a></li><li class="dropdown-subitem"><a href="/note/typescript-axios/" class="nav-link">《TypeScript 从零实现 axios》</a></li><li class="dropdown-subitem"><a href="/note/git/" class="nav-link">《Git》</a></li><li class="dropdown-subitem"><a href="/pages/51afd6/" class="nav-link">TypeScript</a></li><li class="dropdown-subitem"><a href="/pages/4643cd/" class="nav-link">JS设计模式总结</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="页面" class="dropdown-title"><a href="/ui/" class="link-title">页面</a> <span class="title" style="display:none;">页面</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/8309a5b876fc95e3/" class="nav-link">HTML</a></li><li class="dropdown-item"><!----> <a href="/pages/0a83b083bdf257cb/" class="nav-link">CSS</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="技术" class="dropdown-title"><a href="/technology/" class="link-title">技术</a> <span class="title" style="display:none;">技术</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/9a7ee40fc232253e/" class="nav-link">技术文档</a></li><li class="dropdown-item"><!----> <a href="/pages/4c778760be26d8b3/" class="nav-link">GitHub技巧</a></li><li class="dropdown-item"><!----> <a href="/pages/117708e0af7f0bd9/" class="nav-link">Nodejs</a></li><li class="dropdown-item"><!----> <a href="/pages/41f87d890d0a02af/" class="nav-link">博客搭建</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="更多" class="dropdown-title"><a href="/more/" class="link-title">更多</a> <span class="title" style="display:none;">更多</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/f2a556/" class="nav-link">学习</a></li><li class="dropdown-item"><!----> <a href="/pages/aea6571b7a8bae86/" class="nav-link">面试</a></li><li class="dropdown-item"><!----> <a href="/pages/2d615df9a36a98ed/" class="nav-link">心情杂货</a></li><li class="dropdown-item"><!----> <a href="/pages/baaa02/" class="nav-link">实用技巧</a></li><li class="dropdown-item"><!----> <a href="/friends/" class="nav-link">友情链接</a></li></ul></div></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><a href="/pages/beb6c0bd8a66cea6/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/andanyang/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="/img/logo.png"> <div class="blogger-info"><h3>Young</h3> <span></span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/Spring/" class="nav-link">Spring</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="前端" class="dropdown-title"><a href="/web/" class="link-title">前端</a> <span class="title" style="display:none;">前端</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>前端文章1</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/8143cc480faf9a11/" class="nav-link">JavaScript</a></li></ul></li><li class="dropdown-item"><h4>学习笔记</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/note/javascript/" class="nav-link">《JavaScript教程》</a></li><li class="dropdown-subitem"><a href="/note/js/" class="nav-link">《JavaScript高级程序设计》</a></li><li class="dropdown-subitem"><a href="/note/es6/" class="nav-link">《ES6 教程》</a></li><li class="dropdown-subitem"><a href="/note/vue/" class="nav-link">《Vue》</a></li><li class="dropdown-subitem"><a href="/note/react/" class="nav-link">《React》</a></li><li class="dropdown-subitem"><a href="/note/typescript-axios/" class="nav-link">《TypeScript 从零实现 axios》</a></li><li class="dropdown-subitem"><a href="/note/git/" class="nav-link">《Git》</a></li><li class="dropdown-subitem"><a href="/pages/51afd6/" class="nav-link">TypeScript</a></li><li class="dropdown-subitem"><a href="/pages/4643cd/" class="nav-link">JS设计模式总结</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="页面" class="dropdown-title"><a href="/ui/" class="link-title">页面</a> <span class="title" style="display:none;">页面</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/8309a5b876fc95e3/" class="nav-link">HTML</a></li><li class="dropdown-item"><!----> <a href="/pages/0a83b083bdf257cb/" class="nav-link">CSS</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="技术" class="dropdown-title"><a href="/technology/" class="link-title">技术</a> <span class="title" style="display:none;">技术</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/9a7ee40fc232253e/" class="nav-link">技术文档</a></li><li class="dropdown-item"><!----> <a href="/pages/4c778760be26d8b3/" class="nav-link">GitHub技巧</a></li><li class="dropdown-item"><!----> <a href="/pages/117708e0af7f0bd9/" class="nav-link">Nodejs</a></li><li class="dropdown-item"><!----> <a href="/pages/41f87d890d0a02af/" class="nav-link">博客搭建</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="更多" class="dropdown-title"><a href="/more/" class="link-title">更多</a> <span class="title" style="display:none;">更多</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/f2a556/" class="nav-link">学习</a></li><li class="dropdown-item"><!----> <a href="/pages/aea6571b7a8bae86/" class="nav-link">面试</a></li><li class="dropdown-item"><!----> <a href="/pages/2d615df9a36a98ed/" class="nav-link">心情杂货</a></li><li class="dropdown-item"><!----> <a href="/pages/baaa02/" class="nav-link">实用技巧</a></li><li class="dropdown-item"><!----> <a href="/friends/" class="nav-link">友情链接</a></li></ul></div></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><a href="/pages/beb6c0bd8a66cea6/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/andanyang/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><a href="/pages/bigdata-generality/" class="sidebar-link">第一章 大数据技术之大数据概论</a></li><li><a href="/pages/Hadoop-Concept-explanation/" class="sidebar-link">第二章大数据技术之 Hadoop概念讲解</a></li><li><a href="/Hadoop/Build-Hadoop-running-environment/" class="sidebar-link">第三章Hadoop 运行环境搭建</a></li><li><a href="/pages/Hadoop-working-mechanism/" class="sidebar-link">第四章Hadoop之HDFS详解以及工作机制介绍</a></li><li><a href="/pages/haddop-MapReduce/" aria-current="page" class="active sidebar-link">第五章MapReduce编程框架</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_1-1-mapreduce-定义" class="sidebar-link">1.1 MapReduce 定义</a></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_1-2-mapreduce-优缺点" class="sidebar-link">1.2 MapReduce 优缺点</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_1-2-1-优点" class="sidebar-link">1.2.1 优点</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_1-2-2-缺点" class="sidebar-link">1.2.2 缺点</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_1-3-mapreduce-核心思想" class="sidebar-link">1.3 MapReduce 核心思想</a></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_1-4-mapreduce-进程" class="sidebar-link">1.4 MapReduce 进程</a></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_1-5-官方-wordcount-源码" class="sidebar-link">1.5 官方 WordCount 源码</a></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_1-6-常用数据序列化类型" class="sidebar-link">1.6 常用数据序列化类型</a></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_1-7-mapreduce-编程规范" class="sidebar-link">1.7 MapReduce 编程规范</a></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_1-8-wordcount-案例实操" class="sidebar-link">1.8 WordCount 案例实操</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_1-8-1-本地测试" class="sidebar-link">1.8.1 本地测试</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_1-8-2-提交到集群测试" class="sidebar-link">1.8.2 提交到集群测试</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_2-1-序列化概述" class="sidebar-link">2.1 序列化概述</a></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_2-2-自定义-bean-对象实现序列化接口-writable" class="sidebar-link">2.2 自定义 bean 对象实现序列化接口（Writable）</a></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_3-1-inputformat-数据输入" class="sidebar-link">3.1 InputFormat 数据输入</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-1-1-切片与-maptask-并行度决定机制" class="sidebar-link">3.1.1 切片与 MapTask 并行度决定机制</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-1-2-job-提交流程源码和切片源码详解" class="sidebar-link">!image-202306142039322733.1.2 Job 提交流程源码和切片源码详解</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-1-3-fileinputformat-切片机制" class="sidebar-link">3.1.3 FileInputFormat 切片机制</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_1、切片机制" class="sidebar-link">1、切片机制</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_2、案例分析" class="sidebar-link">2、案例分析</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-1-4-textinputformat" class="sidebar-link">3.1.4 TextInputFormat</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_1-fileinputformat-实现类" class="sidebar-link">1）FileInputFormat 实现类</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_2-textinputformat" class="sidebar-link">2）TextInputFormat</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-1-5-combinetextinputformat-切片机制" class="sidebar-link">3.1.5 CombineTextInputFormat 切片机制</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_1-虚拟存储过程" class="sidebar-link">（1）虚拟存储过程：</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_2-切片过程" class="sidebar-link">（2）切片过程：</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-1-6-combinetextinputformat-案例实操" class="sidebar-link">3.1.6 CombineTextInputFormat 案例实操</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_3-2-mapreduce-工作流程" class="sidebar-link">3.2 MapReduce 工作流程</a></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_3-3-shuffle-机制" class="sidebar-link">3.3 Shuffle 机制</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-3-1-shuffle-机制" class="sidebar-link">3.3.1 Shuffle 机制</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-3-2-partition-分区" class="sidebar-link">3.3.2 Partition 分区</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_1、问题引出" class="sidebar-link">1、问题引出</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_2、默认partitioner分区" class="sidebar-link">2、默认Partitioner分区</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_3、自定义partitioner步骤" class="sidebar-link">3、自定义Partitioner步骤</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_4、分区总结" class="sidebar-link">4、分区总结</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#_5、案例分析" class="sidebar-link">5、案例分析</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-3-3-partition-分区案例实操" class="sidebar-link">3.3.3 Partition 分区案例实操</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-3-4-writablecomparable-排序" class="sidebar-link">3.3.4 WritableComparable 排序</a></li><li class="sidebar-sub-header level4"><a href="/pages/haddop-MapReduce/#排序分类" class="sidebar-link">排序分类</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-3-5-writablecomparable-排序案例实操-全排序" class="sidebar-link">3.3.5 WritableComparable 排序案例实操（全排序）</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-3-6-writablecomparable-排序案例实操-区内排序" class="sidebar-link">3.3.6 WritableComparable 排序案例实操（区内排序）</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-3-7-combiner-合并" class="sidebar-link">3.3.7 Combiner 合并</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_3-4-outputformat-数据输出" class="sidebar-link">3.4 OutputFormat 数据输出</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-4-1-outputformat-接口实现类" class="sidebar-link">3.4.1 OutputFormat 接口实现类</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-4-2-自定义-outputformat-案例实操" class="sidebar-link">3.4.2 自定义 OutputFormat 案例实操</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_3-5-mapreduce-内核源码解析" class="sidebar-link">3.5 MapReduce 内核源码解析</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-5-1-maptask-工作机制" class="sidebar-link">3.5.1 MapTask 工作机制</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_3-5-2-reducetask-工作机制" class="sidebar-link">3.5.2 ReduceTask 工作机制</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-5-3-reducetask-并行度决定机制" class="sidebar-link">3.5.3 ReduceTask 并行度决定机制</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_3-6-join-应用" class="sidebar-link">3.6 Join 应用</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-6-1-reduce-join" class="sidebar-link">3.6.1 Reduce Join</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-6-2-reduce-join-案例实操" class="sidebar-link">3.6.2 Reduce Join 案例实操</a></li><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-6-3-map-join" class="sidebar-link">3.6.3 Map Join</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_3-6-4-map-join-案例实操" class="sidebar-link">3.6.4 Map Join 案例实操</a></li><li class="sidebar-sub-header level2"><a href="/pages/haddop-MapReduce/#_3-7-数据清洗-etl" class="sidebar-link">3.7 数据清洗（ETL）</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/haddop-MapReduce/#_3-8-mapreduce-开发总结" class="sidebar-link">3.8 MapReduce 开发总结</a></li></ul></li></ul></li><li><a href="/pages/5cb5f8/" class="sidebar-link">第六章Hadoop 数据压缩</a></li><li><a href="/Hadoop/Yarn/" class="sidebar-link">第七章大数据技术之 Hadoop（Yarn）</a></li><li><a href="/pages/c19893/" class="sidebar-link">第八章Hadoop（生产调优手册）</a></li><li><a href="/pages/4a90c0/" class="sidebar-link">hadoo3.x 在windows10下编译</a></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/categories/?category=Hadoop" title="分类" data-v-06225672>Hadoop</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/andanyoung" target="_blank" title="作者" class="beLink" data-v-06225672>andanyang</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2023-06-05</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABH1JREFUSA3tVl1oHFUUPmdmd2ltklqbpJDiNnXFmgbFktho7YMPNiJSSZM0+CAYSkUELVhM6YuwIPpgoOKDqOBDC0XE2CQoNtQXBUFTTcCi+Wlh1V2TQExsUzcltd3M9Tt3ZjZzZ2fT+OJTL8yeM+eee757fmeJbq//KQL8X3DUSFOcfr7cRsRtxNQMWueeVzOkaITIGqQHNg5y8+jNW9ldM7A6nTpAjuolUikAwq7CE3WcM2RRDz+XGVgN3FptU/aUSlvq9Pa3iZ1+sgAqJyyAFqkipd9dqiwHF3P65YycLWc/6sqGrvoEoIp6DOFaX5h6+dnfjkWprwqsPk0dUGq5vySwDImC10KxFHgGL1SWoc92O3eVht09qdXNH11I2SsTsJYqMWzihqGMi+A+Garf3BAuuLI5oGlULyNfyB/HYNujwktOfRrMr5t77NmevqaUopx0grnKAyvVpmwUDB4x6FPXuGvYLTDwWsejwgtgkYKPqRJg8SV6xaiZ3ZTppGneS4yfH5/66fZSDHv+QZci/+h5c5UHtpy67JUqGppM0sh0Nc1dW6/N1W5Yoqat8/TU/VnadmdeW2PLLSyh0cvxBs3KbqTmwYPpxN4do/mzE8nEpvX/UMu2Wbp74zUAK5q6WkHns7V0eWkdPbPzd3rxkTGybadYySumVzhcaJFbs5UrEkQ/+CK8gF5dnh/6ciIZ73gwQ927L1IitoxKLXYP3SjYdOrHHfTZhRRlFyrorafPk20B3HPD1y2G3qKZME5Jcf3t/HUC13/8tSd++vqFveMUTwAUxSUFI1QekR1+bIze3D9MF2aq6cPvG72CgnldWCFqyRw3lwH8ZMerjTD9ElRO7Gv44wNpC90aASqGfVlz/Rx17srQ57/UU26hkhQqUB7dBR71WmzQhHUnblGmVOEw0jhbV1n9OlXUDCIRGaNV5Jp43N516fN7JmnTHdfp7Hgy0luO4aMhtkLL8Bi3bUWYvzh5Mn1dTxrL6QmGuRhGL/TiTTxRoEdTszSaq9GR0NGA3KdkOz3hqSV3MIDhQ5IVX/Ivx3umBti2es2h4eZby7x8br1rkf7Mo90AqC8aQ3sJeNzqFRu+vSANAQe3PL7l0HGOAdwDCeZYvNKeoZp1Qfs6Aipndh86HmFRi0LAnEO47wsqM6cdfjh3jBPUzhZy7nvlUfFsamED1VQt6aISHVymXZ/B2aCtIG8AI8xfobj2d3en1wWVhOeHELKmLQ1s211s88comkv4UCwWyF787mJdYXtNfhKAXVqnKTq8QZvGAGGOfaTo5pGZ/PwbUCr5+DPr/1J92JNHr9aOl/F3iI5+O1nfybsGxoimvZ3ViWSluDITw3P37mypheDIPY0tw7+O/5ApbkYw+zpfaUVu32Pi98+defdUhEpZkRFq0aqyNh9FuL9hpYbEm6iwi0z2REd09ZmyENEbuhjDWzKvZXTqKYaBIr3tt5kuPtQBZFvEUwHt60vfCNu41XsksH9Ij1BMMz1Y0OOunHNShFIP5868g5zeXmuLwL9T4b6Q2+KejgAAAABJRU5ErkJggg==">第五章MapReduce编程框架<!----></h1>  <div class="theme-vdoing-content content__default"><h1 id="_1-mapreduce-概述"><a href="#_1-mapreduce-概述" class="header-anchor">#</a> 1. MapReduce 概述</h1> <h2 id="_1-1-mapreduce-定义"><a href="#_1-1-mapreduce-定义" class="header-anchor">#</a> 1.1 MapReduce 定义</h2> <p>MapReduce 是一个<strong>分布式运算程序</strong>的编程框架，是用户开发“基于 Hadoop 的数据分析应用”的核心框架。</p> <p>MapReduce 核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个 Hadoop 集群上。</p> <h2 id="_1-2-mapreduce-优缺点"><a href="#_1-2-mapreduce-优缺点" class="header-anchor">#</a> 1.2 MapReduce 优缺点</h2> <h3 id="_1-2-1-优点"><a href="#_1-2-1-优点" class="header-anchor">#</a> 1.2.1 优点</h3> <p>1）MapReduce 易于编程</p> <p><strong>它简单的实现一些接口，就可以完成一个分布式程序</strong>，这个分布式程序可以分布到大量廉价的 PC 机器上运行。也就是说你写一个分布式程序，跟写一个简单的串行程序是一模一样的。就是因为这个特点使得 MapReduce 编程变得非常流行。</p> <p>2）良好的扩展性</p> <p>当你的计算资源不能得到满足的时候，你可以通过<strong>简单的增加机器</strong>来扩展它的计算能力。</p> <p>3）高容错性</p> <p>MapReduce 设计的初衷就是使程序能够部署在廉价的 PC 机器上，这就要求它具有很高 的容错性。比如**其中一台机器挂了，它可以把上面的计算任务转移到另外一个节点上运行， 不至于这个任务运行失败，**而且这个过程不需要人工参与，而完全是由 Hadoop 内部完成的。</p> <p>4）适合 PB 级以上海量数据的离线处理</p> <p>可以实现上千台服务器集群并发工作，提供数据处理能力。</p> <h3 id="_1-2-2-缺点"><a href="#_1-2-2-缺点" class="header-anchor">#</a> 1.2.2 缺点</h3> <p>1）不擅长实时计算</p> <p>MapReduce 无法像 MySQL 一样，在毫秒或者秒级内返回结果。</p> <p>2）不擅长流式计算</p> <p>流式计算的输入数据是动态的，而 MapReduce 的<strong>输入数据集是静态</strong>的，不能动态变化。 这是因为 MapReduce 自身的设计特点决定了数据源必须是静态的。</p> <p>3）不擅长 DAG（有向无环图）计算</p> <p>多个应用程序存在依赖关系，后一个应用程序的输入为前一个的输出。在这种情况下， MapReduce 并不是不能做，而是使用后，每个 MapReduce 作业的输出结果都会写入到磁盘， 会造成大量的磁盘 IO，导致性能非常的低下。</p> <h2 id="_1-3-mapreduce-核心思想"><a href="#_1-3-mapreduce-核心思想" class="header-anchor">#</a> 1.3 MapReduce 核心思想</h2> <p><img src="/assets/img/image-20230608222632302.fb87a7d7.png" alt="image-20230608222632302"></p> <p>（1）分布式的运算程序往往需要分成至少 2 个阶段。</p> <p>（2）第一个阶段的 MapTask 并发实例，完全并行运行，互不相干。</p> <p>（3）第二个阶段的 ReduceTask 并发实例互不相干，但是他们的数据依赖于上一个阶段的所有 MapTask 并发实例的输出。</p> <p>（4）MapReduce 编程模型只能包含一个 Map 阶段和一个 Reduce 阶段，如果用户的业 务逻辑非常复杂，那就只能多个 MapReduce 程序，串行运行。</p> <p>总结：分析 WordCount   数据流走向深入理解 MapReduce 核心思想。</p> <h2 id="_1-4-mapreduce-进程"><a href="#_1-4-mapreduce-进程" class="header-anchor">#</a> 1.4 MapReduce 进程</h2> <p>一个完整的 MapReduce 程序在分布式运行时有三类实例进程：</p> <p>（1）MrAppMaster：负责整个程序的过程调度及状态协调。</p> <p>（2）MapTask：负责 Map 阶段的整个数据处理流程。</p> <p>（3）ReduceTask：负责 Reduce 阶段的整个数据处理流程。</p> <h2 id="_1-5-官方-wordcount-源码"><a href="#_1-5-官方-wordcount-源码" class="header-anchor">#</a> 1.5 官方 WordCount 源码</h2> <p>采用反编译工具反编译源码，发现 WordCount 案例有 Map 类、Reduce 类和驱动类。且 数据的类型是 Hadoop 自身封装的序列化类型。</p> <h2 id="_1-6-常用数据序列化类型"><a href="#_1-6-常用数据序列化类型" class="header-anchor">#</a> 1.6 常用数据序列化类型</h2> <table><thead><tr><th>Java基本类型</th> <th>Hadoop Writable类型</th></tr></thead> <tbody><tr><td>boolean</td> <td>BooleanWritable</td></tr> <tr><td>byte</td> <td>ByteWritable</td></tr> <tr><td>int</td> <td>IntWritable</td></tr> <tr><td>float</td> <td>FloatWritable</td></tr> <tr><td>long</td> <td>LongWritable</td></tr> <tr><td>double</td> <td>DoubleWritable</td></tr> <tr><td>String</td> <td>Text</td></tr> <tr><td>map</td> <td>MapWritable</td></tr> <tr><td>array</td> <td>ArrayWritable</td></tr></tbody></table> <h2 id="_1-7-mapreduce-编程规范"><a href="#_1-7-mapreduce-编程规范" class="header-anchor">#</a> 1.7 MapReduce 编程规范</h2> <p>用户编写的程序分成三个部分：Mapper、Reducer 和 Driver。</p> <p>1．Mapper阶段</p> <p>（1）用户自定义的Mapper要继承自己的父类</p> <p>（2）Mapper的输入数据是KV对的形式（KV的类型可自定义）</p> <p>（3）Mapper中的业务逻辑写在map()方法中</p> <p>（4）Mapper的输出数据是KV对的形式（KV的类型可自定义）</p> <p>（5）<strong>map()方法（MapTask进程）对每一个调用一次</strong></p> <p>2．Reducer阶段</p> <p>（1）用户自定义的Reducer要继承自己的父类</p> <p>（2）Reducer的输入数据类型对应Mapper的输出数据类型，也是KV （3）Reducer的业务逻辑写在reduce()方法中</p> <p>（4）<strong>ReduceTask进程对每一组相同k的组调用一次reduce()方法</strong></p> <p>3．Driver阶段</p> <p>相当于YARN集群的客户端，用于提交我们整个程序到YARN集群，提交的是封装了MapReduce程序相关运行参数的job对象</p> <h2 id="_1-8-wordcount-案例实操"><a href="#_1-8-wordcount-案例实操" class="header-anchor">#</a> 1.8 WordCount 案例实操</h2> <h3 id="_1-8-1-本地测试"><a href="#_1-8-1-本地测试" class="header-anchor">#</a> 1.8.1 本地测试</h3> <p>1）需求</p> <p>在给定的文本文件中统计输出每一个单词出现的总次数</p> <p>2）需求分析</p> <p>按照 MapReduce 编程规范，分别编写 Mapper，Reducer，Driver。</p> <p>3）环境准备</p> <p>（1）创建 maven 工程，MapReduceDemo</p> <p>（2）在 pom.xml 文件中添加如下依赖</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>  &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
            &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;
            &lt;version&gt;3.1.3&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;junit&lt;/groupId&gt;
            &lt;artifactId&gt;junit&lt;/artifactId&gt;
            &lt;version&gt;4.12&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
            &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;
            &lt;version&gt;1.7.30&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br></div></div><p>（2）在项目的 src/main/resources 目录下，新建一个文件，命名为“log4j.properties”，在 文件中填入。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>log4j.rootLogger=INFO, stdout 
log4j.appender.stdout=org.apache.log4j.ConsoleAppender 
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout 
log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n 
log4j.appender.logfile=org.apache.log4j.FileAppender 
log4j.appender.logfile.File=target/spring.log 
log4j.appender.logfile.layout=org.apache.log4j.PatternLayout 
log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div><p>4）编写程序</p> <p>（1）编写 Mapper 类</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;
/**
 * KEYIN, map阶段输入的key的类型：LongWritable
 * VALUEIN,map阶段输入value类型：Text
 * KEYOUT,map阶段输出的Key类型：Text
 * VALUEOUT,map阶段输出的value类型：IntWritable
 */
public class WordCountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {
    private Text outK = new Text();
    private IntWritable outV = new IntWritable(1);

    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {

        // 1 获取一行
        // atguigu atguigu
        String line = value.toString();

        // 2 切割
        // atguigu
        // atguigu
        String[] words = line.split(&quot; &quot;);

        // 3 循环写出
        for (String word : words) {
            // 封装outk
            outK.set(word);

            // 写出
            context.write(outK, outV);
        }
    }
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br></div></div><p>（2）编写 Reducer 类</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

import java.io.IOException;
/**
 * KEYIN, reduce阶段输入的key的类型：Text
 * VALUEIN,reduce阶段输入value类型：IntWritable
 * KEYOUT,reduce阶段输出的Key类型：Text
 * VALUEOUT,reduce阶段输出的value类型：IntWritable
 */
public class WordCountReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
    private IntWritable outV = new IntWritable();

    @Override
    protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {

        int sum = 0;
        // atguigu, (1,1)
        // 累加
        for (IntWritable value : values) {
            sum += value.get();
        }

        outV.set(sum);

        // 写出
        context.write(key, outV);
    }
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br></div></div><p>（3）编写 Driver 驱动类</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import java.io.IOException;

/**
 * @author andanyoung
 * @version 1.0
 * @date 2023/6/8 22:55
 */

public class WordCountDriver {

    public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {

        // 1 获取job
        Configuration conf = new Configuration();
        //conf.set(&quot;fs.defaultFS&quot;, &quot;hdfs://node1:8020&quot;);
        Job job = Job.getInstance(conf);

        // 2 设置jar包路径
        job.setJarByClass(WordCountDriver.class);

        // 3 关联mapper和reducer
        job.setMapperClass(WordCountMapper.class);
        job.setReducerClass(WordCountReducer.class);

        // 4 设置map输出的kv类型
        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(IntWritable.class);

        // 5 设置最终输出的kV类型
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);

        // 6 设置输入路径和输出路径
        FileInputFormat.setInputPaths(job, new Path(&quot;F:\\hadoop-test\\wc.txt&quot;));
        FileOutputFormat.setOutputPath(job, new Path(&quot;F:\\hadoop-out11&quot;));

        // 7 提交job
        boolean result = job.waitForCompletion(true);

        System.exit(result ? 0 : 1);
    }
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br></div></div><p>5）本地测试</p> <p>（1）需要首先配置好 HADOOP_HOME 变量以及 Windows 运行依赖</p> <p>（2）在 IDEA/Eclipse 上运行程序</p> <h3 id="_1-8-2-提交到集群测试"><a href="#_1-8-2-提交到集群测试" class="header-anchor">#</a> 1.8.2 提交到集群测试</h3> <p>集群上测试</p> <p>（1）用 maven 打 jar 包，需要添加的打包插件依赖</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;version&gt;3.6.1&lt;/version&gt;
                &lt;configuration&gt;
                    &lt;source&gt;1.8&lt;/source&gt;
                    &lt;target&gt;1.8&lt;/target&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
            &lt;plugin&gt;
                &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;descriptorRefs&gt;
                        &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;
                    &lt;/descriptorRefs&gt;
                &lt;/configuration&gt;
                &lt;executions&gt;
                    &lt;execution&gt;
                        &lt;id&gt;make-assembly&lt;/id&gt;
                        &lt;phase&gt;package&lt;/phase&gt;
                        &lt;goals&gt;
                            &lt;goal&gt;single&lt;/goal&gt;
                        &lt;/goals&gt;
                    &lt;/execution&gt;
                &lt;/executions&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br></div></div><p>（2）将程序打成 jar 包</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>mvn clean package
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（3）修改不带依赖的 jar 包名称为 wc.jar，并拷贝该 jar 包到 Hadoop 集群的 /opt/module/hadoop-3.1.3 路径</p> <p>（4）启动 Hadoop 集群</p> <p>（5）执行 WordCount 程序</p> <div class="language- line-numbers-mode"><pre class="language-text"><code> hadoop jar wc.jar
com.atguigu.mapreduce.wordcount.WordCountDriver /user/atguigu/input 
/user/atguigu/output
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h1 id="_2-hadoop-序列化"><a href="#_2-hadoop-序列化" class="header-anchor">#</a> 2. Hadoop 序列化</h1> <h2 id="_2-1-序列化概述"><a href="#_2-1-序列化概述" class="header-anchor">#</a> 2.1 序列化概述</h2> <p>1）什么是序列化</p> <p><strong>序列化</strong>就是把<strong>内存中的对象，转换成字节序列</strong>（或其他数据传输协议）以便于存储到磁盘（持久化）和网络传输。</p> <p><strong>反序列化</strong>就是将收到字节序列（或其他数据传输协议）或者是磁盘的持久化数据，转换成内存中的对象。</p> <p>2）为什么要序列化</p> <p>一般来说，“活的”对象只生存在内存里，关机断电就没有了。而且“活的”对象只能 由本地的进程使用，不能被发送到网络上的另外一台计算机。 然而序列化可以存储“活的” 对象，可以将“活的”对象发送到远程计算机。</p> <p><strong>3）为什么不用 Java 的序列化</strong></p> <p>Java 的序列化是一个重量级序列化框架（Serializable），一个对象被序列化后，会附带很多额外的信息（各种校验信息，Header，继承体系等），不便于在网络中高效传输。所以， Hadoop 自己开发了一套序列化机制（Writable）。</p> <p>4）Hadoop 序列化特点：</p> <ul><li>（1）紧凑 ：高效使用存储空间。</li> <li>（2）快速：读写数据的额外开销小。</li> <li>（3）互操作：支持多语言的交互</li></ul> <p>Java基本类型与Hadoop常用序列化类型</p> <table><thead><tr><th>Java基本类型</th> <th>Hadoop Writable类型</th></tr></thead> <tbody><tr><td>boolean</td> <td>BooleanWritable</td></tr> <tr><td>byte</td> <td>ByteWritable</td></tr> <tr><td>int</td> <td>IntWritable</td></tr> <tr><td>float</td> <td>FloatWritable</td></tr> <tr><td>long</td> <td>LongWritable</td></tr> <tr><td>double</td> <td>DoubleWritable</td></tr> <tr><td>String</td> <td>Text</td></tr> <tr><td>map</td> <td>MapWritable</td></tr> <tr><td>array</td> <td>ArrayWritable</td></tr></tbody></table> <h2 id="_2-2-自定义-bean-对象实现序列化接口-writable"><a href="#_2-2-自定义-bean-对象实现序列化接口-writable" class="header-anchor">#</a> 2.2 自定义 bean 对象实现序列化接口（Writable）</h2> <p>在企业开发中往往常用的基本序列化类型不能满足所有需求，比如在 Hadoop 框架内部 传递一个 bean 对象，那么该对象就需要实现序列化接口。</p> <p>具体实现 bean 对象序列化步骤如下 7 步。</p> <p>（1）必须实现 <code>Writable</code> 接口</p> <p>（2）反序列化时，需要反射调用空参构造函数，所以必须有空参构造</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>public FlowBean() {
	super();
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>（3）重写序列化方法</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>@Override
public void write(DataOutput out) throws IOException {
	out.writeLong(upFlow);
    out.writeLong(downFlow);
    out.writeLong(sumFlow);
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>（4）重写反序列化方法</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>@Override
public void readFields(DataInput in) throws IOException {
    upFlow = in.readLong();
    downFlow = in.readLong();
    sumFlow = in.readLong();
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>（5）<strong>注意反序列化的顺序和序列化的顺序完全一致</strong></p> <p>（6）要想把结果显示在文件中，需要重写 toString()，可用&quot;\t&quot;分开，方便后续用。</p> <p>（7）如果需要将自定义的 bean 放在 key 中传输，则还需要实现 Comparable 接口，因为 MapReduce 框中的 Shuffle 过程要求对 key 必须能排序。详见后面排序案例。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>@Override
public int compareTo(FlowBean o) {
    // 倒序排列，从大到小
    return this.sumFlow &gt; o.getSumFlow() ? -1 : 1;
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><h1 id="_3-mapreduce-框架原理"><a href="#_3-mapreduce-框架原理" class="header-anchor">#</a> 3. MapReduce 框架原理</h1> <p><img src="/assets/img/image-20230614000658557.c9222082.png" alt="image-20230614000658557"></p> <h2 id="_3-1-inputformat-数据输入"><a href="#_3-1-inputformat-数据输入" class="header-anchor">#</a> 3.1 InputFormat 数据输入</h2> <h3 id="_3-1-1-切片与-maptask-并行度决定机制"><a href="#_3-1-1-切片与-maptask-并行度决定机制" class="header-anchor">#</a> 3.1.1 切片与 MapTask 并行度决定机制</h3> <p>1）问题引出</p> <p>MapTask 的并行度决定 Map 阶段的任务处理并发度，进而影响到整个 Job 的处理速度。</p> <p>思考：1G 的数据，启动 8 个 MapTask，可以提高集群的并发处理能力。那么 1K 的数据，也启动 8 个 MapTask，会提高集群性能吗？MapTask 并行任务是否越多越好呢？哪些因素影响了 MapTask 并行度？</p> <p>2）MapTask 并行度决定机制</p> <p>**数据块：**Block 是 HDFS 物理上把数据分成一块一块。数据块是 HDFS 存储数据单位。</p> <p>**数据切片：**数据切片只是在逻辑上对输入进行分片，并不会在磁盘上将其切分成片进行存储。数据切片是 MapReduce 程序计算输入数据的单位，一个切片会对应启动一个 MapTask。</p> <h3 id="_3-1-2-job-提交流程源码和切片源码详解"><a href="#_3-1-2-job-提交流程源码和切片源码详解" class="header-anchor">#</a> <img src="/assets/img/image-20230614203932273.f5718a8f.png" alt="image-20230614203932273">3.1.2 Job 提交流程源码和切片源码详解</h3> <p>1）Job 提交流程源码详解</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>waitForCompletion()

submit();

// 1建立连接
	connect();	
		// 1）创建提交Job的代理
		new Cluster(getConfiguration());
			// （1）判断是本地运行环境还是yarn集群运行环境
			initialize(jobTrackAddr, conf); 

// 2 提交job
submitter.submitJobInternal(Job.this, cluster)

	// 1）创建给集群提交数据的Stag路径
	Path jobStagingArea = JobSubmissionFiles.getStagingDir(cluster, conf);

	// 2）获取jobid ，并创建Job路径
	JobID jobId = submitClient.getNewJobID();

	// 3）拷贝jar包到集群
copyAndConfigureFiles(job, submitJobDir);	
	rUploader.uploadFiles(job, jobSubmitDir);

	// 4）计算切片，生成切片规划文件
writeSplits(job, submitJobDir);
		maps = writeNewSplits(job, jobSubmitDir);
		input.getSplits(job);

	// 5）向Stag路径写XML配置文件
writeConf(conf, submitJobFile);
	conf.writeXml(out);

	// 6）提交Job,返回提交状态
status = submitClient.submitJob(jobId, submitJobDir.toString(), job.getCredentials());
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br></div></div><p><img src="/assets/img/image-20230614205242036.13e8fd91.png" alt="image-20230614205242036"></p> <p>2）FileInputFormat 切片源码解析（input.getSplits(job)）</p> <p><img src="/assets/img/image-20230614212624794.d7051f89.png" alt="image-20230614212624794"></p> <h3 id="_3-1-3-fileinputformat-切片机制"><a href="#_3-1-3-fileinputformat-切片机制" class="header-anchor">#</a> 3.1.3 FileInputFormat 切片机制</h3> <h4 id="_1、切片机制"><a href="#_1、切片机制" class="header-anchor">#</a> 1、切片机制</h4> <p>（1）简单地按照文件的内容长度进行切片</p> <p>（2）切片大小，默认等于Block大小</p> <p><strong>（3）切片时不考虑数据集整体，而是逐个针对每一个文件单独切片</strong></p> <h4 id="_2、案例分析"><a href="#_2、案例分析" class="header-anchor">#</a> 2、案例分析</h4> <p><img src="/assets/img/image-20230614212747456.d97ea604.png" alt="image-20230614212747456"></p> <p>（1）源码中计算切片大小的公式</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>Math.max(minSize, Math.min(maxSize, blockSize));
mapreduce.input.fileinputformat.split.minsize=1 默认值为1
mapreduce.input.fileinputformat.split.maxsize= Long.MAXValue 默认值Long.MAXValu
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>因此，<strong>默认情况下，切片大小=blocksize。</strong></p> <p>（2）切片大小设置</p> <p>maxsize（切片最大值）：参数如果调得比blockSize小，则会让切片变小，而且就等于配置的这个参数的值。 minsize（切片最小值）：参数调的比blockSize大，则可以让切片变得比blockSize还大。</p> <p>（3）获取切片信息API</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>// 获取切片的文件名称
String name = inputSplit.getPath().getName();
// 根据文件类型获取切片信息
FileSplit inputSplit = (FileSplit) context.getInputSplit();
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h3 id="_3-1-4-textinputformat"><a href="#_3-1-4-textinputformat" class="header-anchor">#</a> 3.1.4 TextInputFormat</h3> <h4 id="_1-fileinputformat-实现类"><a href="#_1-fileinputformat-实现类" class="header-anchor">#</a> 1）FileInputFormat 实现类</h4> <p>思考：<strong>在运行 MapReduce 程序时，输入的文件格式包括：基于行的日志文件、二进制格式文件、数据库表等。</strong> 那么，针对不同的数据类型，MapReduce 是如何读取这些数据的呢？</p> <p>FileInputFormat 常见的接口实现类包括：TextInputFormat、KeyValueTextInputFormat、NLineInputFormat、CombineTextInputFormat 和自定义 InputFormat 等</p> <h4 id="_2-textinputformat"><a href="#_2-textinputformat" class="header-anchor">#</a> 2）TextInputFormat</h4> <p>TextInputFormat 是<strong>默认的</strong> FileInputFormat 实现类。按行读取每条记录。**键是存储该行在整个文件中的起始字节偏移量， LongWritable 类型。值是这行的内容，**不包括任何行终止符（换行符和回车符），Text 类型。</p> <p>以下是一个示例，比如，一个分片包含了如下 4 条文本记录。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>Rich learning form
Intelligent learning engine
Learning more convenient
From the real demand for more close to the enterprise
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>每条记录表示为以下键/值对：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>(0,Rich learning form)
(20,Intelligent learning engine)
(49,Learning more convenient)
(74,From the real demand for more close to the enterprise)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h3 id="_3-1-5-combinetextinputformat-切片机制"><a href="#_3-1-5-combinetextinputformat-切片机制" class="header-anchor">#</a> 3.1.5 CombineTextInputFormat 切片机制</h3> <p>框架默认的 TextInputFormat 切片机制是对任务按文件规划切片，**不管文件多小，都会是一个单独的切片，**都会交给一个 MapTask，这样如果有大量小文件，就会产生大量的 <strong>MapTask</strong>(一个MapTask 消耗一个CPU ，1G内存)，处理效率极其低下。</p> <p>1）应用场景：</p> <p>CombineTextInputFormat 用于小文件过多的场景，它可以将多个小文件从逻辑上规划到 一个切片中，这样，多个小文件就可以交给一个 MapTask 处理。</p> <p>2）虚拟存储切片最大值设置</p> <p>CombineTextInputFormat.setMaxInputSplitSize(job, 4194304);// 4m</p> <p>注意：虚拟存储切片最大值设置最好根据实际的小文件大小情况来设置具体的值。</p> <p>3）切片机制</p> <p>生成切片过程包括：虚拟存储过程和切片过程二部分</p> <p>setMaxInputSplitSize值为4M</p> <p><img src="/assets/img/image-20230614224847034.989babb6.png" alt="image-20230614224847034"></p> <h4 id="_1-虚拟存储过程"><a href="#_1-虚拟存储过程" class="header-anchor">#</a> （1）虚拟存储过程：</h4> <p>将输入目录下所有文件大小，依次和设置的 setMaxInputSplitSize 值比较，如果不大于设置的最大值，逻辑上划分一个块。如果输入文件大于设置的最大值且大于两倍， 那么以最大值切割一块；<strong>当剩余数据大小超过设置的最大值且不大于最大值 2 倍，此时将文件均分成 2 个虚拟存储块（防止出现太小切片）。</strong></p> <p>例如 setMaxInputSplitSize 值为 4M，输入文件大小为 8.02M，则先逻辑上分成一个 4M。剩余的大小为 4.02M，如果按照 4M 逻辑划分，就会出现 0.02M 的小的虚拟存储 文件，所以将剩余的 4.02M 文件切分成（2.01M 和 2.01M）两个文件。</p> <h4 id="_2-切片过程"><a href="#_2-切片过程" class="header-anchor">#</a> （2）切片过程：</h4> <ul><li><p>（a）判断虚拟存储的文件大小是否大于 setMaxInputSplitSize 值，大于等于则单独形成一个切片。</p></li> <li><p>（b）如果不大于则跟下一个虚拟存储文件进行合并，共同形成一个切片。</p></li> <li><p>（c）测试举例：有 4 个小文件大小分别为 1.7M、5.1M、3.4M 以及 6.8M 这四个小 文件，则虚拟存储之后形成 6 个文件块，大小分别为：</p> <p>1.7M，（2.55M、2.55M），3.4M 以及（3.4M、3.4M）</p> <p>最终会形成 3 个切片，大小分别为： （1.7+2.55）M，（2.55+3.4）M，（3.4+3.4）M</p></li></ul> <h3 id="_3-1-6-combinetextinputformat-案例实操"><a href="#_3-1-6-combinetextinputformat-案例实操" class="header-anchor">#</a> 3.1.6 CombineTextInputFormat 案例实操</h3> <p>1）需求</p> <p>将输入的大量小文件合并成一个切片统一处理。</p> <ul><li><p>（1）输入数据 准备 4 个小文件</p> <p><img src="/assets/img/image-20230614225641606.cb3d8ec2.png" alt="image-20230614225641606"></p></li> <li><p>（2）期望</p> <p>期望一个切片处理 4 个文件</p></li></ul> <p>2）实现过程</p> <ul><li><p>（1）不做任何处理，运行 1.8 节的 WordCount 案例程序，观察切片个数为 4。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>number of splits:4
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li> <li><p>（2）在 WordcountDriver 中增加如下代码，运行程序，并观察运行的切片个数为 3。</p> <p>（a）驱动类中添加代码如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>// 如果不设置 InputFormat，它默认用的是 TextInputFormat.class
job.setInputFormatClass(CombineTextInputFormat.class);
//虚拟存储切片最大值设置 4m
CombineTextInputFormat.setMaxInputSplitSize(job, 4194304);
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>（b）运行如果为 3 个切片。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>number of splits:3
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li> <li><p>（3）在 WordcountDriver 中增加如下代码，运行程序，并观察运行的切片个数为 1。</p> <p>（a）驱动中添加代码如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>// 如果不设置 InputFormat，它默认用的是 TextInputFormat.class
job.setInputFormatClass(CombineTextInputFormat.class);
//虚拟存储切片最大值设置 20m
CombineTextInputFormat.setMaxInputSplitSize(job, 20971520);
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>（b）运行如果为 1 个切片</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>number of splits:1
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h2 id="_3-2-mapreduce-工作流程"><a href="#_3-2-mapreduce-工作流程" class="header-anchor">#</a> 3.2 MapReduce 工作流程</h2> <p><img src="/assets/img/image-20230614230134735.d5012940.png" alt="image-20230614230134735"></p></li></ul> <p><img src="/assets/img/image-20230614230202750.8793b2ed.png" alt="image-20230614230202750"></p> <p>上面的流程是整个 MapReduce 最全工作流程，但是 Shuffle 过程只是从第 7 步开始到第 16 步结束，具体 Shuffle 过程详解，如下：</p> <ul><li>（1）MapTask 收集我们的 map()方法输出的 kv 对，放到内存缓冲区中</li> <li>（2）从内存缓冲区不断溢出本地磁盘文件，可能会溢出多个文件</li> <li>（3）多个溢出文件会被合并成大的溢出文件</li> <li>（4）在溢出过程及合并的过程中，都要调用 Partitioner 进行分区和针对 key 进行排序</li> <li>（5）ReduceTask 根据自己的分区号，去各个 MapTask 机器上取相应的结果分区数据</li> <li>（6）ReduceTask 会抓取到同一个分区的来自不同 MapTask 的结果文件，ReduceTask 会将这些文件再进行合并（归并排序）</li> <li>（7）合并成大文件后，Shuffle 的过程也就结束了，后面进入 ReduceTask 的逻辑运算过程（从文件中取出一个一个的键值对 Group，调用用户自定义的 reduce()方法）</li></ul> <p>注意：</p> <p>（1）Shuffle 中的缓冲区大小会影响到 MapReduce 程序的执行效率，原则上说，缓冲区越大，磁盘 io 的次数越少，执行速度就越快。</p> <p>（2）缓冲区的大小可以通过参数调整，参数：mapreduce.task.io.sort.mb 默认 100M。</p> <h2 id="_3-3-shuffle-机制"><a href="#_3-3-shuffle-机制" class="header-anchor">#</a> 3.3 Shuffle 机制</h2> <h3 id="_3-3-1-shuffle-机制"><a href="#_3-3-1-shuffle-机制" class="header-anchor">#</a> 3.3.1 Shuffle 机制</h3> <p>Map 方法之后，Reduce 方法之前的数据处理过程称之为 Shuffle。</p> <p><img src="/assets/img/image-20230614232316005.d760f77c.png" alt="image-20230614232316005"></p> <h3 id="_3-3-2-partition-分区"><a href="#_3-3-2-partition-分区" class="header-anchor">#</a> 3.3.2 Partition 分区</h3> <h4 id="_1、问题引出"><a href="#_1、问题引出" class="header-anchor">#</a> 1、问题引出</h4> <p>要求将统计结果按照条件输出到不同文件中（分区）。比如：将统计结果按照手机归属地不同省份输出到不同文件中（分区）</p> <h4 id="_2、默认partitioner分区"><a href="#_2、默认partitioner分区" class="header-anchor">#</a> 2、默认Partitioner分区</h4> <p><img src="/assets/img/image-20230614232752640.2c729faf.png" alt="image-20230614232752640"></p> <p>默 认分区是根据key的hashCode对ReduceTasks个数取模得到的。用户没法控制哪个 key存储到哪个分区。</p> <h4 id="_3、自定义partitioner步骤"><a href="#_3、自定义partitioner步骤" class="header-anchor">#</a> 3、自定义Partitioner步骤</h4> <p>（1）自定义类继承Partitioner，重写getPartition()方法</p> <p><img src="/assets/img/image-20230614232903693.9ada8df0.png" alt="image-20230614232903693">（2)在Job驱动中，设置自定义Partitioner</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>job.setPartitionerClass(CustomPartitioner.class);
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（3）自定义Partition后，要根据自定义Partitioner的逻辑设置相应数量的ReduceTask</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>job.setNumReduceTasks(5);
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h4 id="_4、分区总结"><a href="#_4、分区总结" class="header-anchor">#</a> 4、分区总结</h4> <p><img src="/assets/img/image-20230614233420614.59f2b0a6.png" alt="image-20230614233420614"></p> <h4 id="_5、案例分析"><a href="#_5、案例分析" class="header-anchor">#</a> 5、案例分析</h4> <p>例如：假设自定义分区数为5，则</p> <p>（1）job.setNumReduceTasks(1);  会正常运行，只不过会产生一个输出文件</p> <p>（2）job.setNumReduceTasks(2);  会报错</p> <p>（3）job.setNumReduceTasks(6);  大于5，程序会正常运行，会产生空文件</p> <h3 id="_3-3-3-partition-分区案例实操"><a href="#_3-3-3-partition-分区案例实操" class="header-anchor">#</a> 3.3.3 Partition 分区案例实操</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>package com.atguigu.mapreduce.partitioner;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Partitioner;
public class ProvincePartitioner extends Partitioner&lt;Text, FlowBean&gt; {
 @Override
 public int getPartition(Text text, FlowBean flowBean, int numPartitions) 
{
     //获取手机号前三位 prePhone
     String phone = text.toString();
     String prePhone = phone.substring(0, 3);
     //定义一个分区号变量 partition,根据 prePhone 设置分区号
     int partition;
     if(&quot;136&quot;.equals(prePhone)){
     	partition = 0;
     }else if(&quot;137&quot;.equals(prePhone)){
     	partition = 1;
     }else if(&quot;138&quot;.equals(prePhone)){
     	partition = 2;
     }else if(&quot;139&quot;.equals(prePhone)){
     	partition = 3;
     }else {
     	partition = 4;
     } 
     //最后返回分区号 partition
     return partition;
 	}
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br></div></div><p>4）在驱动函数中增加自定义数据分区设置和 ReduceTask 设置</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>//8 指定自定义分区器
 job.setPartitionerClass(ProvincePartitioner.class);
 //9 同时指定相应数量的 ReduceTask
 job.setNumReduceTasks(5);
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h3 id="_3-3-4-writablecomparable-排序"><a href="#_3-3-4-writablecomparable-排序" class="header-anchor">#</a> 3.3.4 WritableComparable 排序</h3> <p>排序是MapReduce框架中最重要的操作之一。</p> <p>MapTask和ReduceTask均会对数据按 照key进行排序。该操作属于 Hadoop的默认行为。任何应用程序中的数据均会被排序，而不管逻辑上是否需要。默认排序是按照字典顺序排序，且实现该排序的方法是快速排序。</p> <p>对于MapTask，它会将处理的结果暂时放到环形缓冲区中，当环形缓冲区使用率**达到一定阈值后，再对缓冲区中的数据进行一次快速排序，**并将这些有序数据溢写到磁盘上，而当数据处理完毕后，<strong>它会对磁盘上所有文件进行归并排序。</strong></p> <p>对于ReduceTask，它从每个MapTask上远程拷贝相应的数据文件，如果文件大小超过一定阈值，则溢写磁盘上，否则存储在内存中。如果磁盘上文件数目达到一定阈值，则进行一次归并排序以生成一个更大文件；如果内存中文件大小或者数目超过一定阈值，则进行一次合并后将数据溢写到磁盘上。当所有数据拷贝完毕后，<strong>ReduceTask统一对内存和磁盘上的所有数据进行一次归并排序。</strong></p> <h4 id="排序分类"><a href="#排序分类" class="header-anchor">#</a> 排序分类</h4> <p>（1）部分排序</p> <p>MapReduce根据输入记录的键对数据集排序。保证<strong>输出的每个文件内部有序。</strong></p> <p>（2）全排序</p> <p>**最终输出结果只有一个文件，且文件内部有序。**实现方式是只设置一个ReduceTask。但该方法在 处理大型文件时效率极低，因为一台机器处理所有文件，完全丧失了MapReduce所提供的并行架构。</p> <p>（3）辅助排序：</p> <p>（GroupingComparator分组） 在Reduce端对key进行分组。应用于：在接收的key为bean对象时，想让一个或几个字段相同（全部字段比较不相同）的key进入到同一个reduce方法时，可以采用分组排序。</p> <p>（4）二次排序</p> <p>在自定义排序过程中，如果compareTo中的判断条件为两个即为二次排序。</p> <p><strong>自定义排序 WritableComparable 原理分析</strong></p> <p>bean 对象做为 key 传输，需要实现 <strong>WritableComparable</strong> 接口重写 compareTo 方法，就可以实现排序。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>@Override
public int compareTo(FlowBean bean) {
    int result;
    // 按照总流量大小，倒序排列
    if (this.sumFlow &gt; bean.getSumFlow()) {
    	result = -1;
    }else if (this.sumFlow &lt; bean.getSumFlow()) {
    	result = 1;
    }else {
    	result = 0;
    }
    return result;
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><h3 id="_3-3-5-writablecomparable-排序案例实操-全排序"><a href="#_3-3-5-writablecomparable-排序案例实操-全排序" class="header-anchor">#</a> 3.3.5 WritableComparable 排序案例实操（全排序）</h3> <p>1）需求</p> <p>根据案例 2.3 序列化案例产生的结果再次对总流量进行倒序排序。</p> <p><img src="/assets/img/image-20230615213538542.4509c5b3.png" alt="image-20230615213538542"></p> <p>3）代码实现</p> <p>（1）FlowBean 对象在在需求 1 基础上增加了比较功能</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">WritableComparable</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">DataInput</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">DataOutput</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IOException</span></span><span class="token punctuation">;</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowBean</span> <span class="token keyword">implements</span> <span class="token class-name">WritableComparable</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">FlowBean</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span>
     <span class="token keyword">private</span> <span class="token keyword">long</span> upFlow<span class="token punctuation">;</span> <span class="token comment">//上行流量</span>
     <span class="token keyword">private</span> <span class="token keyword">long</span> downFlow<span class="token punctuation">;</span> <span class="token comment">//下行流量</span>
     <span class="token keyword">private</span> <span class="token keyword">long</span> sumFlow<span class="token punctuation">;</span> <span class="token comment">//总流量</span>
     <span class="token comment">//提供无参构造</span>
     <span class="token keyword">public</span> <span class="token class-name">FlowBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
     <span class="token punctuation">}</span>
     <span class="token comment">//生成三个属性的 getter 和 setter 方法</span>
     <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">getUpFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
     	<span class="token keyword">return</span> upFlow<span class="token punctuation">;</span>
     <span class="token punctuation">}</span>
     <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setUpFlow</span><span class="token punctuation">(</span><span class="token keyword">long</span> upFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>
     	<span class="token keyword">this</span><span class="token punctuation">.</span>upFlow <span class="token operator">=</span> upFlow<span class="token punctuation">;</span>
     <span class="token punctuation">}</span>
     <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">getDownFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
     	<span class="token keyword">return</span> downFlow<span class="token punctuation">;</span>
     <span class="token punctuation">}</span>
     <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setDownFlow</span><span class="token punctuation">(</span><span class="token keyword">long</span> downFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>
     	<span class="token keyword">this</span><span class="token punctuation">.</span>downFlow <span class="token operator">=</span> downFlow<span class="token punctuation">;</span>
     <span class="token punctuation">}</span>
     <span class="token keyword">public</span> <span class="token keyword">long</span> <span class="token function">getSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
     	<span class="token keyword">return</span> sumFlow<span class="token punctuation">;</span>
     <span class="token punctuation">}</span>
     <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setSumFlow</span><span class="token punctuation">(</span><span class="token keyword">long</span> sumFlow<span class="token punctuation">)</span> <span class="token punctuation">{</span>
     	<span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">=</span> sumFlow<span class="token punctuation">;</span>
     <span class="token punctuation">}</span>
     <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">setSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
     	<span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">=</span> <span class="token keyword">this</span><span class="token punctuation">.</span>upFlow <span class="token operator">+</span> <span class="token keyword">this</span><span class="token punctuation">.</span>downFlow<span class="token punctuation">;</span>
     <span class="token punctuation">}</span>
     <span class="token comment">//实现序列化和反序列化方法,注意顺序一定要一致</span>
     <span class="token annotation punctuation">@Override</span>
     <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">write</span><span class="token punctuation">(</span><span class="token class-name">DataOutput</span> out<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span> <span class="token punctuation">{</span>
         out<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>upFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>
         out<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>downFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>
         out<span class="token punctuation">.</span><span class="token function">writeLong</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow<span class="token punctuation">)</span><span class="token punctuation">;</span>
     <span class="token punctuation">}</span>
     <span class="token annotation punctuation">@Override</span>
     <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">readFields</span><span class="token punctuation">(</span><span class="token class-name">DataInput</span> in<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span> <span class="token punctuation">{</span>
         <span class="token keyword">this</span><span class="token punctuation">.</span>upFlow <span class="token operator">=</span> in<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token keyword">this</span><span class="token punctuation">.</span>downFlow <span class="token operator">=</span> in<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">=</span> in<span class="token punctuation">.</span><span class="token function">readLong</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
     <span class="token punctuation">}</span>
     <span class="token comment">//重写 ToString,最后要输出 FlowBean</span>
     <span class="token annotation punctuation">@Override</span>
     <span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
     	<span class="token keyword">return</span> upFlow <span class="token operator">+</span> <span class="token string">&quot;\t&quot;</span> <span class="token operator">+</span> downFlow <span class="token operator">+</span> <span class="token string">&quot;\t&quot;</span> <span class="token operator">+</span> sumFlow<span class="token punctuation">;</span>
     <span class="token punctuation">}</span>
     <span class="token annotation punctuation">@Override</span>
     <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">compareTo</span><span class="token punctuation">(</span><span class="token class-name">FlowBean</span> o<span class="token punctuation">)</span> <span class="token punctuation">{</span>
         <span class="token comment">//按照总流量比较,倒序排列</span>
         <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">&gt;</span> o<span class="token punctuation">.</span>sumFlow<span class="token punctuation">)</span><span class="token punctuation">{</span>
         	<span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">;</span>
         <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token keyword">this</span><span class="token punctuation">.</span>sumFlow <span class="token operator">&lt;</span> o<span class="token punctuation">.</span>sumFlow<span class="token punctuation">)</span><span class="token punctuation">{</span>
         	<span class="token keyword">return</span> <span class="token number">1</span><span class="token punctuation">;</span>
         <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>
         	<span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
         <span class="token punctuation">}</span>
     <span class="token punctuation">}</span>
 <span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br></div></div><p>（2）编写 Mapper 类</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">LongWritable</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">FlowBean</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">&gt;</span></span> 
<span class="token punctuation">{</span>
     <span class="token keyword">private</span> <span class="token class-name">FlowBean</span> outK <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FlowBean</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
     <span class="token keyword">private</span> <span class="token class-name">Text</span> outV <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
     <span class="token annotation punctuation">@Override</span>
     <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">LongWritable</span> key<span class="token punctuation">,</span> <span class="token class-name">Text</span> value<span class="token punctuation">,</span> <span class="token class-name">Context</span> context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>
         <span class="token comment">//1 获取一行数据</span>
         <span class="token class-name">String</span> line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token comment">//2 按照&quot;\t&quot;,切割数据</span>
         <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> split <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">&quot;\t&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token comment">//3 封装 outK outV</span>
         outK<span class="token punctuation">.</span><span class="token function">setUpFlow</span><span class="token punctuation">(</span><span class="token class-name">Long</span><span class="token punctuation">.</span><span class="token function">parseLong</span><span class="token punctuation">(</span>split<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
         outK<span class="token punctuation">.</span><span class="token function">setDownFlow</span><span class="token punctuation">(</span><span class="token class-name">Long</span><span class="token punctuation">.</span><span class="token function">parseLong</span><span class="token punctuation">(</span>split<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
         outK<span class="token punctuation">.</span><span class="token function">setSumFlow</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
         outV<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>split<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token comment">//4 写出 outK outV</span>
         context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>outK<span class="token punctuation">,</span>outV<span class="token punctuation">)</span><span class="token punctuation">;</span>
     <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br></div></div><p>（3）编写 Reducer 类</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>writablecompable</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">Text</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">Reducer</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IOException</span></span><span class="token punctuation">;</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlowReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">FlowBean</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">FlowBean</span><span class="token punctuation">&gt;</span></span> 
<span class="token punctuation">{</span>
     <span class="token annotation punctuation">@Override</span>
     <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span><span class="token class-name">FlowBean</span> key<span class="token punctuation">,</span> <span class="token class-name">Iterable</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Text</span><span class="token punctuation">&gt;</span></span> values<span class="token punctuation">,</span> <span class="token class-name">Context</span> context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>
         <span class="token comment">//遍历 values 集合,循环写出,避免总流量相同的情况</span>
         <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">Text</span> value <span class="token operator">:</span> values<span class="token punctuation">)</span> <span class="token punctuation">{</span>
             <span class="token comment">//调换 KV 位置,反向写出</span>
             context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>value<span class="token punctuation">,</span>key<span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token punctuation">}</span>
     <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><p>（4）编写 Driver 类</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>public class FlowDriver {
    public static void main(String[] args) throws IOException, 
    ClassNotFoundException, InterruptedException {
    
         //1 获取 job 对象
         Configuration conf = new Configuration();
         Job job = Job.getInstance(conf);
         
         //2 关联本 Driver 类
         job.setJarByClass(FlowDriver.class);
         
         //3 关联 Mapper 和 Reducer
         job.setMapperClass(FlowMapper.class);
         job.setReducerClass(FlowReducer.class);
         
         //4 设置 Map 端输出数据的 KV 类型
         job.setMapOutputKeyClass(FlowBean.class);
         job.setMapOutputValueClass(Text.class);
         
         //5 设置程序最终输出的 KV 类型
         job.setOutputKeyClass(Text.class);
         job.setOutputValueClass(FlowBean.class);
         
         //6 设置输入输出路径
         FileInputFormat.setInputPaths(job, new Path(&quot;D:\\inputflow2&quot;));
         FileOutputFormat.setOutputPath(job, new Path(&quot;D:\\comparout&quot;));
         
         //7 提交 Job
         boolean b = job.waitForCompletion(true);
         System.exit(b ? 0 : 1);
     }
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br></div></div><h3 id="_3-3-6-writablecomparable-排序案例实操-区内排序"><a href="#_3-3-6-writablecomparable-排序案例实操-区内排序" class="header-anchor">#</a> 3.3.6 WritableComparable 排序案例实操（区内排序）</h3> <p>1）需求</p> <p>要求每个省份手机号输出的文件中按照总流量内部排序。</p> <p>2）需求分析</p> <p>基于前一个需求，增加自定义分区类，分区按照省份手机号设置。</p> <p><img src="/assets/img/image-20230615215911259.27c6d39f.png" alt="image-20230615215911259"></p> <p>3）案例实操</p> <ul><li>（1）增加自定义分区类</li></ul> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">Text</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">Partitioner</span></span><span class="token punctuation">;</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">ProvincePartitioner2</span> <span class="token keyword">extends</span> <span class="token class-name">Partitioner</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">FlowBean</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span>
     <span class="token annotation punctuation">@Override</span>
     <span class="token keyword">public</span> <span class="token keyword">int</span> <span class="token function">getPartition</span><span class="token punctuation">(</span><span class="token class-name">FlowBean</span> flowBean<span class="token punctuation">,</span> <span class="token class-name">Text</span> text<span class="token punctuation">,</span> <span class="token keyword">int</span> numPartitions<span class="token punctuation">)</span> 
    <span class="token punctuation">{</span>
         <span class="token comment">//获取手机号前三位</span>
         <span class="token class-name">String</span> phone <span class="token operator">=</span> text<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token class-name">String</span> prePhone <span class="token operator">=</span> phone<span class="token punctuation">.</span><span class="token function">substring</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
         
         <span class="token comment">//定义一个分区号变量 partition,根据 prePhone 设置分区号</span>
         <span class="token keyword">int</span> partition<span class="token punctuation">;</span>
         <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token string">&quot;136&quot;</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>prePhone<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
         	partition <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
         <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token string">&quot;137&quot;</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>prePhone<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
         	partition <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>
         <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token string">&quot;138&quot;</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>prePhone<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
         	partition <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">;</span>
         <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token string">&quot;139&quot;</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span>prePhone<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
         	partition <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">;</span>
         <span class="token punctuation">}</span><span class="token keyword">else</span> <span class="token punctuation">{</span>
         	partition <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">;</span>
         <span class="token punctuation">}</span>
         <span class="token comment">//最后返回分区号 partition</span>
         <span class="token keyword">return</span> partition<span class="token punctuation">;</span>
     <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br></div></div><p>（2）在驱动类中添加分区类</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>// 设置自定义分区器
job.setPartitionerClass(ProvincePartitioner2.class);
// 设置对应的 ReduceTask 的个数
job.setNumReduceTasks(5);
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h3 id="_3-3-7-combiner-合并"><a href="#_3-3-7-combiner-合并" class="header-anchor">#</a> 3.3.7 Combiner 合并</h3> <p>（1）Combiner是MR程序中Mapper和Reducer之外的一种组件。</p> <p>（2）Combiner组件的父类就是Reducer。</p> <p>（3）Combiner和Reducer的区别在于运行的位置 Combiner是在每一个MapTask所在的节点运行;</p> <p>（4）Combiner的意义就是对每一个MapTask的输出进行局部汇总，以减小网络传输量。</p> <p>（5）Combiner能够应用的前提是不能影响最终的业务逻辑，而且，Combiner的输出kv 应该跟Reducer的输入kv类型要对应起来。</p> <p><img src="/assets/img/image-20230615221257999.cc1fafc8.png" alt="image-20230615221257999"></p> <p>（6）自定义 Combiner 实现步骤</p> <ul><li><p>（a）自定义一个 Combiner 继承 Reducer，重写 Reduce 方法</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordCountCombiner</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">IntWritable</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">IntWritable</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span>
 <span class="token keyword">private</span> <span class="token class-name">IntWritable</span> outV <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token annotation punctuation">@Override</span>
 <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span><span class="token class-name">Text</span> key<span class="token punctuation">,</span> <span class="token class-name">Iterable</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">IntWritable</span><span class="token punctuation">&gt;</span></span> values<span class="token punctuation">,</span> <span class="token class-name">Context</span> context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>
     <span class="token keyword">int</span> sum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
     <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">IntWritable</span> value <span class="token operator">:</span> values<span class="token punctuation">)</span> <span class="token punctuation">{</span>
     	sum <span class="token operator">+=</span> value<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
     <span class="token punctuation">}</span>

     outV<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span>sum<span class="token punctuation">)</span><span class="token punctuation">;</span>
     context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span>outV<span class="token punctuation">)</span><span class="token punctuation">;</span>
 <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div></li> <li><p>（b）在 Job 驱动类中设置：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>job.setCombinerClass(WordCountCombiner.class);
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li></ul> <h2 id="_3-4-outputformat-数据输出"><a href="#_3-4-outputformat-数据输出" class="header-anchor">#</a> 3.4 OutputFormat 数据输出</h2> <h3 id="_3-4-1-outputformat-接口实现类"><a href="#_3-4-1-outputformat-接口实现类" class="header-anchor">#</a> 3.4.1 OutputFormat 接口实现类</h3> <p>OutputFormat是MapReduce输出的基类，所有实现MapReduce输出都实现了 OutputFormat 接口。下面我们介绍几种常见的OutputFormat实现类。</p> <p>1．OutputFormat实现类</p> <p><img src="/assets/img/image-20230615222357367.78d9ccf8.png" alt="image-20230615222357367"></p> <p>2．默认输出格式TextOutputFormat</p> <p>3．自定义OutputFormat</p> <p>​	3.1 应用场景：</p> <p>​		例如：输出数据到MySQL/HBase/Elasticsearch等存储框架中。</p> <p>​	 3.2 自定义OutputFormat步骤</p> <p>​		➢ 自定义一个类继承FileOutputFormat。</p> <p>​		➢ 改写RecordWriter，具体改写输出数据的方法write()。</p> <h3 id="_3-4-2-自定义-outputformat-案例实操"><a href="#_3-4-2-自定义-outputformat-案例实操" class="header-anchor">#</a> 3.4.2 自定义 OutputFormat 案例实操</h3> <p>1）需求</p> <p>​	过滤输入的 log 日志，包含 atguigu 的网站输出到 e:/atguigu.log，不包含 atguigu 的网站输出到 e:/other.log。</p> <p><img src="/assets/img/image-20230615222556151.e4f7e2a7.png" alt="image-20230615222556151"></p> <p>3）案例实操</p> <ul><li>（1）编写 LogMapper 类</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;
import java.io.IOException;
public class LogMapper extends Mapper&lt;LongWritable, Text,Text, NullWritable&gt; {
     @Override
     protected void map(LongWritable key, Text value, Context context)  throws IOException, InterruptedException {
         //不做任何处理,直接写出一行 log 数据
         context.write(value,NullWritable.get());
     }
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><ul><li><p>（2）编写 LogReducer 类</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">NullWritable</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">Text</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">Reducer</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IOException</span></span><span class="token punctuation">;</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">LogReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">NullWritable</span><span class="token punctuation">,</span><span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">NullWritable</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{</span>
 <span class="token annotation punctuation">@Override</span>
     <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span><span class="token class-name">Text</span> key<span class="token punctuation">,</span> <span class="token class-name">Iterable</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">NullWritable</span><span class="token punctuation">&gt;</span></span> values<span class="token punctuation">,</span> <span class="token class-name">Context</span> 
    context<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{</span>
    
         <span class="token comment">// 防止有相同的数据,迭代写出</span>
         <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">NullWritable</span> value <span class="token operator">:</span> values<span class="token punctuation">)</span> <span class="token punctuation">{</span>
         	context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span>key<span class="token punctuation">,</span><span class="token class-name">NullWritable</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
         <span class="token punctuation">}</span>
     <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div></li> <li><p>（3）自定义一个 LogOutputFormat 类</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.RecordWriter;
import org.apache.hadoop.mapreduce.TaskAttemptContext;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import java.io.IOException;
public class LogOutputFormat extends FileOutputFormat&lt;Text, NullWritable&gt; 
{
     @Override
     public RecordWriter&lt;Text, NullWritable&gt; 
    getRecordWriter(TaskAttemptContext job) throws IOException, InterruptedException {
         //创建一个自定义的 RecordWriter 返回
         LogRecordWriter logRecordWriter = new LogRecordWriter(job);
         return logRecordWriter;
     }
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br></div></div></li> <li><p>（4）编写 LogRecordWriter 类</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import org.apache.hadoop.fs.FSDataOutputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IOUtils;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.RecordWriter;
import org.apache.hadoop.mapreduce.TaskAttemptContext;

import java.io.IOException;

public class LogRecordWriter extends RecordWriter&lt;Text, NullWritable&gt; {

    private  FSDataOutputStream atguiguOut;
    private  FSDataOutputStream otherOut;

    public LogRecordWriter(TaskAttemptContext job) {
        // 创建两条流
        try {
            FileSystem fs = FileSystem.get(job.getConfiguration());

            atguiguOut = fs.create(new Path(&quot;D:\\hadoop\\atguigu.log&quot;));

            otherOut = fs.create(new Path(&quot;D:\\hadoop\\other.log&quot;));
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    @Override
    public void write(Text key, NullWritable value) throws IOException, InterruptedException {
        String log = key.toString();

        // 具体写
        if (log.contains(&quot;atguigu&quot;)){
            atguiguOut.writeBytes(log+&quot;\n&quot;);
        }else {
            otherOut.writeBytes(log+&quot;\n&quot;);
        }
    }

    @Override
    public void close(TaskAttemptContext context) throws IOException, InterruptedException {
        // 关流
        IOUtils.closeStream(atguiguOut);
        IOUtils.closeStream(otherOut);
    }
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br></div></div><p>（5）编写 LogDriver 类</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import java.io.IOException;

public class LogDriver {

    public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {

        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf);

        job.setJarByClass(LogDriver.class);
        job.setMapperClass(LogMapper.class);
        job.setReducerClass(LogReducer.class);

        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(NullWritable.class);

        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(NullWritable.class);

        //设置自定义的outputformat
        job.setOutputFormatClass(LogOutputFormat.class);

        FileInputFormat.setInputPaths(job, new Path(&quot;D:\\input\\inputoutputformat&quot;));
        //虽然我们自定义了outputformat，但是因为我们的outputformat继承自fileoutputformat
        //而fileoutputformat要输出一个_SUCCESS文件，所以在这还得指定一个输出目录
        FileOutputFormat.setOutputPath(job, new Path(&quot;D:\\hadoop\\output1111&quot;));

        boolean b = job.waitForCompletion(true);
        System.exit(b ? 0 : 1);

    }
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br></div></div><h2 id="_3-5-mapreduce-内核源码解析"><a href="#_3-5-mapreduce-内核源码解析" class="header-anchor">#</a> 3.5 MapReduce 内核源码解析</h2> <h3 id="_3-5-1-maptask-工作机制"><a href="#_3-5-1-maptask-工作机制" class="header-anchor">#</a> 3.5.1 MapTask 工作机制</h3> <p><img src="/assets/img/image-20230615224158805.1bfa72b7.png" alt="image-20230615224158805"></p></li> <li><p>（1）Read 阶段：MapTask 通过 InputFormat 获得的 RecordReader，从输入 InputSplit 中 解析出一个个 key/value。</p></li> <li><p>（2）Map 阶段：该节点主要是将解析出的 key/value 交给用户编写 map()函数处理，并产生一系列新的 key/value。</p></li> <li><p>（3）Collect 收集阶段：在用户编写 map()函数中，当数据处理完成后，一般会调OutputCollector.collect()输出结果。在该函数内部，它会将生成的 key/value 分区（调用 Partitioner），并写入一个环形内存缓冲区中。</p></li> <li><p>（4）Spill 阶段：即“溢写”，当环形缓冲区满后，MapReduce 会将数据写到本地磁盘上， 生成一个临时文件。需要注意的是，将数据写入本地磁盘之前，先要对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。</p> <p>溢写阶段详情：</p> <ul><li><p>步骤 1：
利用快速排序算法对缓存区内的数据进行排序，排序方式是，先按照分区编号 Partition 进行排序，然后按照 key 进行排序。这样，经过排序后，数据以分区为单位聚集在一起，且同一分区内所有数据按照 key 有序。</p></li> <li><p>步骤 2：
按照分区编号由小到大依次将每个分区中的数据写入任务工作目录下的临时文件 output/spillN.out（N 表示当前溢写次数）中。如果用户设置了 Combiner，则写入文件之 前，对每个分区中的数据进行一次聚集操作。</p></li> <li><p>步骤 3：
将分区数据的元信息写到内存索引数据结构 SpillRecord 中，其中每个分区的元信息包括在临时文件中的偏移量、压缩前数据大小和压缩后数据大小。如果当前内存索引大小超过 1MB，则将内存索引写到文件 output/spillN.out.index 中。</p></li></ul></li> <li><p>（5）Merge 阶段：当所有数据处理完成后，MapTask 对所有临时文件进行一次合并， 以确保最终只会生成一个数据文件。</p> <p>当所有数据处理完后，MapTask 会将所有临时文件合并成一个大文件，并保存到文件 output/file.out 中，同时生成相应的索引文件 output/file.out.index。</p> <p>在进行文件合并过程中，MapTask 以分区为单位进行合并。对于某个分区，它将采用多轮递归合并的方式。每轮合并 mapreduce.task.io.sort.factor（默认 10）个文件，并将产生的文件重新加入待合并列表中，对文件排序后，重复以上过程，直到最终得到一个大文件。</p> <p>让每个 MapTask 最终只生成一个数据文件，可避免同时打开大量文件和同时读取大量小文件产生的随机读取带来的开销。</p> <h2 id="_3-5-2-reducetask-工作机制"><a href="#_3-5-2-reducetask-工作机制" class="header-anchor">#</a> 3.5.2 ReduceTask 工作机制</h2> <p><img src="/assets/img/image-20230615230302680.8ff3787b.png" alt="image-20230615230302680"></p></li> <li><p>（1）Copy 阶段：ReduceTask 从各个 MapTask 上远程拷贝一片数据，并针对某一片数据，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。</p></li> <li><p>（2）Sort 阶段：在远程拷贝数据的同时，ReduceTask 启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或磁盘上文件过多。按照 MapReduce 语义，用户编写 reduce()函数输入数据是按 key 进行聚集的一组数据。为了将 key 相同的数据聚在一 起，Hadoop 采用了基于排序的策略。由于各个 MapTask 已经实现对自己的处理结果进行了 局部排序，<strong>因此，ReduceTask 只需对所有数据进行一次归并排序即可。</strong></p></li> <li><p>（3）Reduce 阶段：reduce()函数将计算结果写到 HDFS 上。</p></li></ul> <h3 id="_3-5-3-reducetask-并行度决定机制"><a href="#_3-5-3-reducetask-并行度决定机制" class="header-anchor">#</a> 3.5.3 ReduceTask 并行度决定机制</h3> <p>**回顾：**MapTask 并行度由切片个数决定，切片个数由输入文件和切片规则决定。</p> <p>**思考：**ReduceTask 并行度由谁决定？</p> <p>1）设置 ReduceTask 并行度（个数）</p> <p>ReduceTask 的并行度同样影响整个 Job 的执行并发度和执行效率，但与 MapTask 的并 发数由切片数决定不同，ReduceTask 数量的决定是可以直接手动设置：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>// 默认值是 1，手动设置为 4
job.setNumReduceTasks(4);
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>2）实验：测试 ReduceTask 多少合适</p> <p>（1）实验环境：1 个 Master 节点，16 个 Slave 节点：CPU:8GHZ，内存: 2</p> <p>（2）实验结论</p> <p><img src="/assets/img/image-20230615230550050.eb175ce9.png" alt="image-20230615230550050"></p> <p>3）注意事项</p> <ul><li>（1）ReduceTask=0，表示没有Reduce阶段，输出文件个数和Map个数一致。</li> <li>（2）ReduceTask默认值就是1，所以输出文件个数为一个。</li> <li>（3）如果数据分布不均匀，就有可能在Reduce阶段产生数据倾斜</li> <li>（4）ReduceTask数量并不是任意设置，还要考虑业务逻辑需求，有些情况下，需要计算全局汇总结果，就只能有1个ReduceTask。</li> <li>（5）具体多少个ReduceTask，需要根据集群性能而定。</li> <li>（6）如果分区数不是1，但是ReduceTask为1，是否执行分区过程。答案是：不执行分区 程。因为在MapTask的源码中，执行分区的前提是先判断ReduceNum个数是否大于1。不大于1 肯定不执行。</li></ul> <h2 id="_3-6-join-应用"><a href="#_3-6-join-应用" class="header-anchor">#</a> 3.6 Join 应用</h2> <h3 id="_3-6-1-reduce-join"><a href="#_3-6-1-reduce-join" class="header-anchor">#</a> 3.6.1 Reduce Join</h3> <p>Map 端的主要工作：为来自不同表或文件的 key/value 对，<strong>打标签以区别不同来源的记录</strong>。然后用<strong>连接字段作为 key</strong>，其余部分和新加的标志作为 value，最后进行输出。</p> <p>Reduce 端的主要工作：在 Reduce 端<strong>以连接字段作为 key 的分组已经完成</strong>，我们只需要在每一个分组当中将那些来源于不同文件的记录（在 Map 阶段已经打标志）分开，最后进行合并就 ok 了。</p> <h3 id="_3-6-2-reduce-join-案例实操"><a href="#_3-6-2-reduce-join-案例实操" class="header-anchor">#</a> 3.6.2 Reduce Join 案例实操</h3> <p>1）需求</p> <p>表4-4 订单数据表t_order</p> <table><thead><tr><th>id</th> <th>pid</th> <th>amount</th></tr></thead> <tbody><tr><td>1001</td> <td>01</td> <td>1</td></tr> <tr><td>1002</td> <td>02</td> <td>2</td></tr> <tr><td>1003</td> <td>03</td> <td>3</td></tr> <tr><td>1004</td> <td>01</td> <td>4</td></tr> <tr><td>1005</td> <td>02</td> <td>5</td></tr> <tr><td>1006</td> <td>03</td> <td>6</td></tr></tbody></table> <p>表4-5 商品信息表t_product</p> <table><thead><tr><th>pid</th> <th>pname</th></tr></thead> <tbody><tr><td>01</td> <td>小米</td></tr> <tr><td>02</td> <td>华为</td></tr> <tr><td>03</td> <td>格力</td></tr></tbody></table> <p>将商品信息表中数据根据商品 pid 合并到订单数据表中。</p> <p>表4-6 最终数据形式</p> <table><thead><tr><th>id</th> <th>pname</th> <th>amount</th></tr></thead> <tbody><tr><td>1001</td> <td>小米</td> <td>1</td></tr> <tr><td>1004</td> <td>小米</td> <td>4</td></tr> <tr><td>1002</td> <td>华为</td> <td>2</td></tr> <tr><td>1005</td> <td>华为</td> <td>5</td></tr> <tr><td>1003</td> <td>格力</td> <td>3</td></tr> <tr><td>1006</td> <td>格力</td> <td>6</td></tr></tbody></table> <p>2）需求分析</p> <p>通过将关联条件作为Map输出的key，将两表满足Join条件的数据并携带数据所来源的文件信息，发往同一个ReduceTask，在Reduce中进行数据的串联。</p> <p><img src="/assets/img/image-20230615232128226.ca4da7bf.png" alt="image-20230615232128226"></p> <p>3）代码实现</p> <p>​	（1）创建商品和订单合并后的 TableBean 类</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import org.apache.hadoop.io.Writable;

import java.io.DataInput;
import java.io.DataOutput;
import java.io.IOException;

public class TableBean implements Writable {

    private String id; // 订单id
    private String pid; // 商品id
    private int amount; // 商品数量
    private String pname;// 商品名称
    private String flag; // 标记是什么表 order pd

    // 空参构造
    public TableBean() {
    }

    public String getId() {
        return id;
    }

    public void setId(String id) {
        this.id = id;
    }

    public String getPid() {
        return pid;
    }

    public void setPid(String pid) {
        this.pid = pid;
    }

    public int getAmount() {
        return amount;
    }

    public void setAmount(int amount) {
        this.amount = amount;
    }

    public String getPname() {
        return pname;
    }

    public void setPname(String pname) {
        this.pname = pname;
    }

    public String getFlag() {
        return flag;
    }

    public void setFlag(String flag) {
        this.flag = flag;
    }

    @Override
    public void write(DataOutput out) throws IOException {
        out.writeUTF(id);
        out.writeUTF(pid);
        out.writeInt(amount);
        out.writeUTF(pname);
        out.writeUTF(flag);
    }

    @Override
    public void readFields(DataInput in) throws IOException {

        this.id = in.readUTF();
        this.pid = in.readUTF();
        this.amount = in.readInt();
        this.pname = in.readUTF();
        this.flag = in.readUTF();
    }

    @Override
    public String toString() {
        // id	pname	amount
        return  id + &quot;\t&quot; +  pname + &quot;\t&quot; + amount ;
    }
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br><span class="line-number">83</span><br></div></div><p>（2）编写 TableMapper 类</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.InputSplit;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.lib.input.FileSplit;

import java.io.IOException;

public class TableMapper extends Mapper&lt;LongWritable, Text, Text, TableBean&gt; {

    private String fileName;
    private Text outK  = new Text();
    private TableBean outV = new TableBean();

    @Override
    protected void setup(Context context) throws IOException, InterruptedException {
        // 初始化  order  pd
        FileSplit split = (FileSplit) context.getInputSplit();

        fileName = split.getPath().getName();
    }

    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        // 1 获取一行
        String line = value.toString();

        // 2 判断是哪个文件的
        if (fileName.contains(&quot;order&quot;)){// 处理的是订单表

            String[] split = line.split(&quot;\t&quot;);

            // 封装k  v
            outK.set(split[1]);
            outV.setId(split[0]);
            outV.setPid(split[1]);
            outV.setAmount(Integer.parseInt(split[2]));
            outV.setPname(&quot;&quot;);
            outV.setFlag(&quot;order&quot;);

        }else {// 处理的是商品表
            String[] split = line.split(&quot;\t&quot;);

            outK.set(split[0]);
            outV.setId(&quot;&quot;);
            outV.setPid(split[0]);
            outV.setAmount(0);
            outV.setPname(split[1]);
            outV.setFlag(&quot;pd&quot;);
        }

        // 写出
        context.write(outK, outV);
    }
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br></div></div><p>（3）编写 TableReducer 类</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import org.apache.commons.beanutils.BeanUtils;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

import java.io.IOException;
import java.lang.reflect.InvocationTargetException;
import java.util.ArrayList;

public class TableReducer extends Reducer&lt;Text, TableBean,TableBean, NullWritable&gt; {

    @Override
    protected void reduce(Text key, Iterable&lt;TableBean&gt; values, Context context) throws IOException, InterruptedException {
//        01 	1001	1   order
//        01 	1004	4   order
//        01	小米   	     pd
        // 准备初始化集合
        ArrayList&lt;TableBean&gt; orderBeans = new ArrayList&lt;&gt;();
        TableBean pdBean = new TableBean();

        // 循环遍历
        for (TableBean value : values) {

            if (&quot;order&quot;.equals(value.getFlag())){// 订单表

                TableBean tmptableBean = new TableBean();

                try {
                    BeanUtils.copyProperties(tmptableBean,value);
                } catch (IllegalAccessException e) {
                    e.printStackTrace();
                } catch (InvocationTargetException e) {
                    e.printStackTrace();
                }

                orderBeans.add(tmptableBean);
            }else {// 商品表

                try {
                    BeanUtils.copyProperties(pdBean,value);
                } catch (IllegalAccessException e) {
                    e.printStackTrace();
                } catch (InvocationTargetException e) {
                    e.printStackTrace();
                }
            }
        }

        // 循环遍历orderBeans，赋值 pdname
        for (TableBean orderBean : orderBeans) {

            orderBean.setPname(pdBean.getPname());

            context.write(orderBean,NullWritable.get());
        }
    }
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br></div></div><p>（4）编写 TableDriver 类</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import java.io.IOException;

public class TableDriver {

    public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {
        Job job = Job.getInstance(new Configuration());

        job.setJarByClass(TableDriver.class);
        job.setMapperClass(TableMapper.class);
        job.setReducerClass(TableReducer.class);

        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(TableBean.class);

        job.setOutputKeyClass(TableBean.class);
        job.setOutputValueClass(NullWritable.class);

        FileInputFormat.setInputPaths(job, new Path(&quot;D:\\input\\inputtable&quot;));
        FileOutputFormat.setOutputPath(job, new Path(&quot;D:\\hadoop\\output2&quot;));

        boolean b = job.waitForCompletion(true);
        System.exit(b ? 0 : 1);
    }
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br></div></div><p>4）测试运行程序查看结果</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>1004 小米 4
1001 小米 1
1005 华为 5
1002 华为 2
1006 格力 6
1003 格力 3
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>5）总结</p> <p>缺点：这种方式中，合并的操作是在 Reduce 阶段完成，Reduce 端的处理压力太大，Map 节点的运算负载则很低，资源利用率不高，<strong>且在 Reduce 阶段极易产生数据倾斜。</strong></p> <p>解决方案：Map 端实现数据合并。</p> <h3 id="_3-6-3-map-join"><a href="#_3-6-3-map-join" class="header-anchor">#</a> 3.6.3 Map Join</h3> <p>1）使用场景</p> <p>Map Join 适用于一张表十分小、一张表很大的场景。</p> <p>2）优点</p> <p>思考：在 Reduce 端处理过多的表，非常容易产生数据倾斜。怎么办？ 在 Map 端缓存多张表，提前处理业务逻辑，这样增加 Map 端业务，减少 Reduce 端数据的压力，尽可能的减少数据倾斜。</p> <p>3）具体办法：采用 DistributedCache</p> <p>（1）在 Mapper 的 setup 阶段，将文件读取到缓存集合中。</p> <p>（2）在 Driver 驱动类中加载缓存。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>//缓存普通文件到 Task 运行节点。
job.addCacheFile(new URI(&quot;file:///e:/cache/pd.txt&quot;));
//如果是集群运行,需要设置 HDFS 路径
job.addCacheFile(new URI(&quot;hdfs://hadoop102:8020/cache/pd.txt&quot;));
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h2 id="_3-6-4-map-join-案例实操"><a href="#_3-6-4-map-join-案例实操" class="header-anchor">#</a> 3.6.4 Map Join 案例实操</h2> <p><img src="/assets/img/image-20230615234248374.4401867b.png" alt="image-20230615234248374"></p> <p>3）实现代码</p> <p>（1）先在 MapJoinDriver 驱动类中添加缓存文件</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import java.io.IOException;
import java.net.URI;
import java.net.URISyntaxException;

public class MapJoinDriver {
    public static void main(String[] args) throws IOException, URISyntaxException, ClassNotFoundException, InterruptedException {

        // 1 获取job信息
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf);
        // 2 设置加载jar包路径
        job.setJarByClass(MapJoinDriver.class);
        // 3 关联mapper
        job.setMapperClass(MapJoinMapper.class);
        // 4 设置Map输出KV类型
        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(NullWritable.class);
        // 5 设置最终输出KV类型
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(NullWritable.class);

        // 加载缓存数据
        job.addCacheFile(new URI(&quot;file:///D:/input/tablecache/pd.txt&quot;));
        // Map端Join的逻辑不需要Reduce阶段，设置reduceTask数量为0
        job.setNumReduceTasks(0);

        // 6 设置输入输出路径
        FileInputFormat.setInputPaths(job, new Path(&quot;D:\\input\\inputtable2&quot;));
        FileOutputFormat.setOutputPath(job, new Path(&quot;D:\\hadoop\\output8888&quot;));
        // 7 提交
        boolean b = job.waitForCompletion(true);
        System.exit(b ? 0 : 1);
    }
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br></div></div><p>（2）在 MapJoinMapper 类中的 setup 方法中读取缓存文件</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import org.apache.commons.lang.StringUtils;
import org.apache.hadoop.fs.FSDataInputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IOUtils;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStreamReader;
import java.net.URI;
import java.util.HashMap;

public class MapJoinMapper extends Mapper&lt;LongWritable, Text, Text, NullWritable&gt; {
    private HashMap&lt;String, String&gt; pdMap = new HashMap&lt;&gt;();
    private Text outK = new Text();

    @Override
    protected void setup(Context context) throws IOException, InterruptedException {
        // 获取缓存的文件，并把文件内容封装到集合 pd.txt
        URI[] cacheFiles = context.getCacheFiles();

        FileSystem fs = FileSystem.get(context.getConfiguration());
        FSDataInputStream fis = fs.open(new Path(cacheFiles[0]));

        // 从流中读取数据
        BufferedReader reader = new BufferedReader(new InputStreamReader(fis, &quot;UTF-8&quot;));

        String line;
        while (StringUtils.isNotEmpty(line = reader.readLine())) {
            // 切割
            String[] fields = line.split(&quot;\t&quot;);

            // 赋值
            pdMap.put(fields[0], fields[1]);
        }

        // 关流
        IOUtils.closeStream(reader);
    }

    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {

        // 处理 order.txt
        String line = value.toString();

        String[] fields = line.split(&quot;\t&quot;);

        // 获取pid
        String pname = pdMap.get(fields[1]);

        // 获取订单id 和订单数量
        // 封装
        outK.set(fields[0] + &quot;\t&quot; + pname + &quot;\t&quot; + fields[2]);

        context.write(outK, NullWritable.get());
    }
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br></div></div><h2 id="_3-7-数据清洗-etl"><a href="#_3-7-数据清洗-etl" class="header-anchor">#</a> 3.7 数据清洗（ETL）</h2> <p>“ETL，是英文 Extract-Transform-Load 的缩写，用来描述将数据从来源端经过抽取 （Extract）、转换（Transform）、加载（Load）至目的端的过程。ETL 一词较常用在数据仓库，但其对象并不限于数据仓库在运行核心业务 MapReduce 程序之前，往往要先对数据进行清洗，清理掉不符合用户 要求的数据。<strong>清理的过程往往只需要运行 Mapper 程序，不需要运行 Reduce 程序。</strong></p> <p>1）需求</p> <p>去除日志中字段个数小于等于 11 的日志。</p> <p>2）需求分析</p> <p>需要在 Map 阶段对输入的数据根据规则进行过滤清洗。</p> <p>3）实现代码</p> <p>（1）编写 WebLogMapper 类</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;

public class WebLogMapper extends Mapper&lt;LongWritable, Text, Text, NullWritable&gt; {

    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {

        // 1 获取一行
        String line = value.toString();

        // 2 ETL
        boolean result = parseLog(line, context);

        if (!result){
            return;
        }

        // 3 写出
        context.write(value, NullWritable.get());
    }

    private boolean parseLog(String line, Context context) {
        // 切割
        // 1.206.126.5 - - [19/Sep/2013:05:41:41 +0000] &quot;-&quot; 400 0 &quot;-&quot; &quot;-&quot;
        String[] fields = line.split(&quot; &quot;);

        // 2 判断一下日志的长度是否大于11
        if (fields.length &gt; 11){
            return true;
        }else {
            return false;
        }
    }
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br></div></div><p>（2）编写 WebLogDriver 类</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>import com.atguigu.mapreduce.outputformat.LogDriver;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WebLogDriver {

    public static void main(String[] args) throws Exception {

        // 输入输出路径需要根据自己电脑上实际的输入输出路径设置
        args = new String[]{&quot;D:/input/inputlog&quot;, &quot;D:/hadoop/output11111&quot;};

        // 1 获取job信息
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf);

        // 2 加载jar包
        job.setJarByClass(LogDriver.class);

        // 3 关联map
        job.setMapperClass(WebLogMapper.class);

        // 4 设置最终输出类型
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(NullWritable.class);

        // 设置reducetask个数为0
        job.setNumReduceTasks(0);

        // 5 设置输入和输出路径
        FileInputFormat.setInputPaths(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));

        // 6 提交
        boolean b = job.waitForCompletion(true);
        System.exit(b ? 0 : 1);
    }
}
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br></div></div><h3 id="_3-8-mapreduce-开发总结"><a href="#_3-8-mapreduce-开发总结" class="header-anchor">#</a> 3.8 MapReduce 开发总结</h3> <p>1）<strong>输入数据接口：InputFormat</strong></p> <ul><li>（1）默认使用的实现类是：TextInputFormat</li> <li>（2）TextInputFormat 的功能逻辑是：一次读一行文本，然后将该行的起始偏移量作为 key，行内容作为 value 返回。</li> <li>（3）CombineTextInputFormat 可以把多个小文件合并成一个切片处理，提高处理效率。</li></ul> <p><strong>2）逻辑处理接口：Mapper</strong></p> <p>用户根据业务需求实现其中三个方法：map() setup() cleanup ()</p> <p><strong>3）Partitioner 分区</strong></p> <ul><li>（1）有默认实现 HashPartitioner，逻辑是根据 key 的哈希值和 numReduces 来返回一个分区号；key.hashCode()&amp;Integer.MAXVALUE % numReduces</li> <li>（2）如果业务上有特别的需求，可以自定义分区。</li></ul> <p><strong>4）Comparable 排序</strong></p> <ul><li>（1）当我们用自定义的对象作为 key 来输出时，就必须要实现 WritableComparable 接 口，重写其中的 compareTo()方法。</li> <li>（2）部分排序：对最终输出的每一个文件进行内部排序。</li> <li>（3）全排序：对所有数据进行排序，通常只有一个 Reduce。</li> <li>（4）二次排序：排序的条件有两个。</li></ul> <p><strong>5）Combiner</strong></p> <p>合并 Combiner 合并可以提高程序执行效率，减少 IO 传输。但是使用时必须不能影响原有的业务处理结果。</p> <p><strong>6）逻辑处理接口：</strong></p> <p>Reducer 用户根据业务需求实现其中三个方法：reduce() setup() cleanup ()</p> <p><strong>7）输出数据接口：OutputFormat</strong></p> <ul><li>（1）默认实现类是 TextOutputFormat，功能逻辑是：将每一个 KV 对，向目标文本文件 输出一行。</li> <li>（2）用户还可以自定义 OutputFormat。</li></ul></div></div>  <div class="page-edit"><div class="edit-link"><a href="https://github.com/andanyang/vuepress-theme-vdoing/edit/master/docs/Hadoop/0005.MapReduce编程框架.md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <div class="tags"><a href="/tags/?tag=MapReduce" title="标签">#MapReduce</a></div> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2023/07/07, 00:58:17</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/pages/Hadoop-working-mechanism/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">第四章Hadoop之HDFS详解以及工作机制介绍</div></a> <a href="/pages/5cb5f8/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">第六章Hadoop 数据压缩</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/pages/Hadoop-working-mechanism/" class="prev">第四章Hadoop之HDFS详解以及工作机制介绍</a></span> <span class="next"><a href="/pages/5cb5f8/">第六章Hadoop 数据压缩</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/pages/bi_report/"><div>
            BI和报表的区别，终于有人说清楚了！
            <!----></div></a> <span class="date">06-29</span></dt></dl><dl><dd>02</dd> <dt><a href="/pages/0b4a5d/"><div>
            MyBatis的插件开发
            <!----></div></a> <span class="date">06-29</span></dt></dl><dl><dd>03</dd> <dt><a href="/pages/c19893/"><div>
            第八章Hadoop（生产调优手册）
            <!----></div></a> <span class="date">06-28</span></dt></dl> <dl><dd></dd> <dt><a href="/archives/" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="mailto:1218853253@qq.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/andanyang" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="https://music.163.com/#/playlist?id=755597173" title="听音乐" target="_blank" class="iconfont icon-erji"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2019-2023
    <span>Young | <a href="https://github.com/andanyoung/young-blog/blob/master/LICENSE" target="_blank">MIT License</a> <br/> <a  href="https://beian.miit.gov.cn/" target="_blank">浙ICP备20002744号</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><div></div></div></div>
    <script src="/assets/js/app.9080ceff.js" defer></script><script src="/assets/js/2.47f2c7d0.js" defer></script><script src="/assets/js/4.e268042a.js" defer></script>
  </body>
</html>
