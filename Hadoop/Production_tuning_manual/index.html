<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>第八章Hadoop（生产调优手册） | Young&#39;s blog</title>
    <meta name="generator" content="VuePress 1.9.5">
    <link rel="icon" href="/img/favicon.ico">
    <meta name="description" content="Young丶java后端技术博客,专注后端学习与总结。擅长spring boot,JAVA基础总结,等方面的知识,关注spring,架构,elasticsearch,mysql领域.">
    <meta name="keywords" content="前端博客,个人技术博客,前端,前端开发,前端框架,web前端,前端面试题,技术文档,学习,面试,JavaScript,js,ES6,TypeScript,vue,python,css3,html5,Node,git,github,markdown">
    <meta name="baidu-site-verification" content="7F55weZDDc">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/assets/css/0.styles.53c04193.css" as="style"><link rel="preload" href="/assets/js/app.e4caa6db.js" as="script"><link rel="preload" href="/assets/js/2.d1be14c5.js" as="script"><link rel="preload" href="/assets/js/3.4f4335cf.js" as="script"><link rel="prefetch" href="/assets/js/10.20449a2b.js"><link rel="prefetch" href="/assets/js/100.f25e73b5.js"><link rel="prefetch" href="/assets/js/101.3180ba9d.js"><link rel="prefetch" href="/assets/js/102.fcd415ea.js"><link rel="prefetch" href="/assets/js/103.522869bb.js"><link rel="prefetch" href="/assets/js/104.5da1e4e4.js"><link rel="prefetch" href="/assets/js/105.e5a40fe8.js"><link rel="prefetch" href="/assets/js/106.627d6279.js"><link rel="prefetch" href="/assets/js/107.606beca1.js"><link rel="prefetch" href="/assets/js/108.100e1cb2.js"><link rel="prefetch" href="/assets/js/109.9765392e.js"><link rel="prefetch" href="/assets/js/11.da3512b5.js"><link rel="prefetch" href="/assets/js/110.b73cf0d9.js"><link rel="prefetch" href="/assets/js/111.3f77dd60.js"><link rel="prefetch" href="/assets/js/112.0c7d547d.js"><link rel="prefetch" href="/assets/js/113.1827c266.js"><link rel="prefetch" href="/assets/js/114.daf1d8a5.js"><link rel="prefetch" href="/assets/js/115.e7dca24d.js"><link rel="prefetch" href="/assets/js/116.11b303de.js"><link rel="prefetch" href="/assets/js/117.203cefba.js"><link rel="prefetch" href="/assets/js/118.61d8527b.js"><link rel="prefetch" href="/assets/js/119.1f959a37.js"><link rel="prefetch" href="/assets/js/12.11f18e06.js"><link rel="prefetch" href="/assets/js/120.c268b7aa.js"><link rel="prefetch" href="/assets/js/121.64318c96.js"><link rel="prefetch" href="/assets/js/122.cbddb70d.js"><link rel="prefetch" href="/assets/js/123.b49b84fb.js"><link rel="prefetch" href="/assets/js/124.392f030b.js"><link rel="prefetch" href="/assets/js/125.45f631c4.js"><link rel="prefetch" href="/assets/js/126.700cc575.js"><link rel="prefetch" href="/assets/js/127.d649cb2a.js"><link rel="prefetch" href="/assets/js/128.bc018411.js"><link rel="prefetch" href="/assets/js/129.d0a74611.js"><link rel="prefetch" href="/assets/js/13.1cb33dc8.js"><link rel="prefetch" href="/assets/js/130.45b1f75c.js"><link rel="prefetch" href="/assets/js/131.45ba93df.js"><link rel="prefetch" href="/assets/js/132.c58bbbd7.js"><link rel="prefetch" href="/assets/js/133.7f53922e.js"><link rel="prefetch" href="/assets/js/134.ddf0d780.js"><link rel="prefetch" href="/assets/js/135.ada3af13.js"><link rel="prefetch" href="/assets/js/136.4097c2be.js"><link rel="prefetch" href="/assets/js/137.fc910ac9.js"><link rel="prefetch" href="/assets/js/138.9628f460.js"><link rel="prefetch" href="/assets/js/139.3125ef74.js"><link rel="prefetch" href="/assets/js/14.1004ce43.js"><link rel="prefetch" href="/assets/js/140.bb53ac81.js"><link rel="prefetch" href="/assets/js/141.a002ac19.js"><link rel="prefetch" href="/assets/js/142.540d19e4.js"><link rel="prefetch" href="/assets/js/143.4cbccfca.js"><link rel="prefetch" href="/assets/js/144.8a217b6a.js"><link rel="prefetch" href="/assets/js/145.9c7bc0de.js"><link rel="prefetch" href="/assets/js/146.3dfd0773.js"><link rel="prefetch" href="/assets/js/147.bc0f0d42.js"><link rel="prefetch" href="/assets/js/148.e0cdc4d5.js"><link rel="prefetch" href="/assets/js/149.8486db6e.js"><link rel="prefetch" href="/assets/js/15.703e8784.js"><link rel="prefetch" href="/assets/js/150.5f3b7fb5.js"><link rel="prefetch" href="/assets/js/151.98a3f202.js"><link rel="prefetch" href="/assets/js/152.2940f2ba.js"><link rel="prefetch" href="/assets/js/153.75f3a085.js"><link rel="prefetch" href="/assets/js/154.fa2da83b.js"><link rel="prefetch" href="/assets/js/155.113be5c8.js"><link rel="prefetch" href="/assets/js/156.0667e7f5.js"><link rel="prefetch" href="/assets/js/157.0b3e5dfa.js"><link rel="prefetch" href="/assets/js/158.a338bdd7.js"><link rel="prefetch" href="/assets/js/159.33c9771c.js"><link rel="prefetch" href="/assets/js/16.71e3d898.js"><link rel="prefetch" href="/assets/js/160.e868c8b3.js"><link rel="prefetch" href="/assets/js/161.cf61955e.js"><link rel="prefetch" href="/assets/js/162.baee00ca.js"><link rel="prefetch" href="/assets/js/163.183cde82.js"><link rel="prefetch" href="/assets/js/164.c1eadef5.js"><link rel="prefetch" href="/assets/js/165.70ee8a24.js"><link rel="prefetch" href="/assets/js/166.8e185ff2.js"><link rel="prefetch" href="/assets/js/167.0881cf57.js"><link rel="prefetch" href="/assets/js/168.88caf424.js"><link rel="prefetch" href="/assets/js/169.e7e984ff.js"><link rel="prefetch" href="/assets/js/17.b0356f05.js"><link rel="prefetch" href="/assets/js/170.c7052d81.js"><link rel="prefetch" href="/assets/js/171.2ab773fd.js"><link rel="prefetch" href="/assets/js/172.0e39f858.js"><link rel="prefetch" href="/assets/js/173.76661218.js"><link rel="prefetch" href="/assets/js/174.0ac9f795.js"><link rel="prefetch" href="/assets/js/175.da30bba2.js"><link rel="prefetch" href="/assets/js/176.0f230688.js"><link rel="prefetch" href="/assets/js/177.040e0937.js"><link rel="prefetch" href="/assets/js/178.68852030.js"><link rel="prefetch" href="/assets/js/179.c998f0ca.js"><link rel="prefetch" href="/assets/js/18.2e77c8d1.js"><link rel="prefetch" href="/assets/js/180.4f6b395f.js"><link rel="prefetch" href="/assets/js/181.577a5325.js"><link rel="prefetch" href="/assets/js/182.6b43cbf2.js"><link rel="prefetch" href="/assets/js/183.cf9e9cca.js"><link rel="prefetch" href="/assets/js/184.f0e76def.js"><link rel="prefetch" href="/assets/js/185.2d3d8eea.js"><link rel="prefetch" href="/assets/js/186.4db71601.js"><link rel="prefetch" href="/assets/js/187.8b6a6829.js"><link rel="prefetch" href="/assets/js/188.4a0b8f41.js"><link rel="prefetch" href="/assets/js/189.0a28241b.js"><link rel="prefetch" href="/assets/js/19.51c97d4c.js"><link rel="prefetch" href="/assets/js/190.5001309c.js"><link rel="prefetch" href="/assets/js/191.42778cf1.js"><link rel="prefetch" href="/assets/js/192.fabd1cb0.js"><link rel="prefetch" href="/assets/js/193.cbc113b8.js"><link rel="prefetch" href="/assets/js/194.4cf24763.js"><link rel="prefetch" href="/assets/js/195.ea5d1afb.js"><link rel="prefetch" href="/assets/js/196.16115ce4.js"><link rel="prefetch" href="/assets/js/197.b90179d1.js"><link rel="prefetch" href="/assets/js/198.456ceb51.js"><link rel="prefetch" href="/assets/js/199.a28de97a.js"><link rel="prefetch" href="/assets/js/20.79989fc4.js"><link rel="prefetch" href="/assets/js/200.72102ac7.js"><link rel="prefetch" href="/assets/js/201.e2b3a297.js"><link rel="prefetch" href="/assets/js/202.d4283e12.js"><link rel="prefetch" href="/assets/js/203.6e5e6596.js"><link rel="prefetch" href="/assets/js/204.363863cf.js"><link rel="prefetch" href="/assets/js/205.d16c5a36.js"><link rel="prefetch" href="/assets/js/206.dc867263.js"><link rel="prefetch" href="/assets/js/207.acfeaaaa.js"><link rel="prefetch" href="/assets/js/208.22c49054.js"><link rel="prefetch" href="/assets/js/209.0f7c526b.js"><link rel="prefetch" href="/assets/js/21.1b619a3f.js"><link rel="prefetch" href="/assets/js/210.b247a678.js"><link rel="prefetch" href="/assets/js/211.fe8629a4.js"><link rel="prefetch" href="/assets/js/212.48b672e5.js"><link rel="prefetch" href="/assets/js/213.08f571a8.js"><link rel="prefetch" href="/assets/js/214.04da1824.js"><link rel="prefetch" href="/assets/js/215.f60b57f4.js"><link rel="prefetch" href="/assets/js/216.4383ceb6.js"><link rel="prefetch" href="/assets/js/217.3b1ce286.js"><link rel="prefetch" href="/assets/js/218.1534ef52.js"><link rel="prefetch" href="/assets/js/219.6901e38c.js"><link rel="prefetch" href="/assets/js/22.349d3a16.js"><link rel="prefetch" href="/assets/js/220.22e0c5ea.js"><link rel="prefetch" href="/assets/js/221.2e7a5a4f.js"><link rel="prefetch" href="/assets/js/222.76b63073.js"><link rel="prefetch" href="/assets/js/223.500a058f.js"><link rel="prefetch" href="/assets/js/224.7f7c1250.js"><link rel="prefetch" href="/assets/js/225.2f183cbe.js"><link rel="prefetch" href="/assets/js/23.712dd5ac.js"><link rel="prefetch" href="/assets/js/24.77ae5052.js"><link rel="prefetch" href="/assets/js/25.e95f81fb.js"><link rel="prefetch" href="/assets/js/26.82cdd880.js"><link rel="prefetch" href="/assets/js/27.427a5aec.js"><link rel="prefetch" href="/assets/js/28.e245952d.js"><link rel="prefetch" href="/assets/js/29.50596e31.js"><link rel="prefetch" href="/assets/js/30.016e73a0.js"><link rel="prefetch" href="/assets/js/31.fb0b0b40.js"><link rel="prefetch" href="/assets/js/32.8e7d8efe.js"><link rel="prefetch" href="/assets/js/33.f05f242b.js"><link rel="prefetch" href="/assets/js/34.893b8c3e.js"><link rel="prefetch" href="/assets/js/35.f98d31b7.js"><link rel="prefetch" href="/assets/js/36.6a5744a0.js"><link rel="prefetch" href="/assets/js/37.67e8976d.js"><link rel="prefetch" href="/assets/js/38.2d8447e0.js"><link rel="prefetch" href="/assets/js/39.3b3fde85.js"><link rel="prefetch" href="/assets/js/4.93e1dc89.js"><link rel="prefetch" href="/assets/js/40.8cde36eb.js"><link rel="prefetch" href="/assets/js/41.9df0f821.js"><link rel="prefetch" href="/assets/js/42.c9f1a26b.js"><link rel="prefetch" href="/assets/js/43.fa088c07.js"><link rel="prefetch" href="/assets/js/44.121055e3.js"><link rel="prefetch" href="/assets/js/45.7995c3a0.js"><link rel="prefetch" href="/assets/js/46.17d53a2e.js"><link rel="prefetch" href="/assets/js/47.4a374966.js"><link rel="prefetch" href="/assets/js/48.733e5b6c.js"><link rel="prefetch" href="/assets/js/49.0fb92742.js"><link rel="prefetch" href="/assets/js/5.f52855e6.js"><link rel="prefetch" href="/assets/js/50.50fc5031.js"><link rel="prefetch" href="/assets/js/51.69d8d52a.js"><link rel="prefetch" href="/assets/js/52.d84cedc3.js"><link rel="prefetch" href="/assets/js/53.a64ddaf4.js"><link rel="prefetch" href="/assets/js/54.15e09103.js"><link rel="prefetch" href="/assets/js/55.0f7e8fd5.js"><link rel="prefetch" href="/assets/js/56.6cb5bf13.js"><link rel="prefetch" href="/assets/js/57.d90d9da6.js"><link rel="prefetch" href="/assets/js/58.2c03a905.js"><link rel="prefetch" href="/assets/js/59.02cf613a.js"><link rel="prefetch" href="/assets/js/6.0ff35647.js"><link rel="prefetch" href="/assets/js/60.bb6d2b2f.js"><link rel="prefetch" href="/assets/js/61.ef2abfd3.js"><link rel="prefetch" href="/assets/js/62.b09e5f81.js"><link rel="prefetch" href="/assets/js/63.6ca85ec7.js"><link rel="prefetch" href="/assets/js/64.77eab656.js"><link rel="prefetch" href="/assets/js/65.65b00883.js"><link rel="prefetch" href="/assets/js/66.040b5d23.js"><link rel="prefetch" href="/assets/js/67.23318ab1.js"><link rel="prefetch" href="/assets/js/68.5c29433f.js"><link rel="prefetch" href="/assets/js/69.90978695.js"><link rel="prefetch" href="/assets/js/7.463451e9.js"><link rel="prefetch" href="/assets/js/70.0c585fbd.js"><link rel="prefetch" href="/assets/js/71.120e4ae5.js"><link rel="prefetch" href="/assets/js/72.53bf1e3a.js"><link rel="prefetch" href="/assets/js/73.282f5b35.js"><link rel="prefetch" href="/assets/js/74.4f1cb67d.js"><link rel="prefetch" href="/assets/js/75.f5d3ea1e.js"><link rel="prefetch" href="/assets/js/76.fb173587.js"><link rel="prefetch" href="/assets/js/77.8064b022.js"><link rel="prefetch" href="/assets/js/78.d26f8075.js"><link rel="prefetch" href="/assets/js/79.6cff2fa5.js"><link rel="prefetch" href="/assets/js/8.d5f74857.js"><link rel="prefetch" href="/assets/js/80.29d746c7.js"><link rel="prefetch" href="/assets/js/81.c0a214a2.js"><link rel="prefetch" href="/assets/js/82.f0c93ca2.js"><link rel="prefetch" href="/assets/js/83.db6f55e1.js"><link rel="prefetch" href="/assets/js/84.b0a7a28c.js"><link rel="prefetch" href="/assets/js/85.db7376d4.js"><link rel="prefetch" href="/assets/js/86.96ec3402.js"><link rel="prefetch" href="/assets/js/87.ae41a109.js"><link rel="prefetch" href="/assets/js/88.d83c21c8.js"><link rel="prefetch" href="/assets/js/89.33868490.js"><link rel="prefetch" href="/assets/js/9.2680f96d.js"><link rel="prefetch" href="/assets/js/90.ed48459a.js"><link rel="prefetch" href="/assets/js/91.e1ee23ba.js"><link rel="prefetch" href="/assets/js/92.8b354527.js"><link rel="prefetch" href="/assets/js/93.0682d2e4.js"><link rel="prefetch" href="/assets/js/94.105580aa.js"><link rel="prefetch" href="/assets/js/95.d378d658.js"><link rel="prefetch" href="/assets/js/96.a6460598.js"><link rel="prefetch" href="/assets/js/97.a4cc955f.js"><link rel="prefetch" href="/assets/js/98.9a600d4f.js"><link rel="prefetch" href="/assets/js/99.45007523.js">
    <link rel="stylesheet" href="/assets/css/0.styles.53c04193.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/img/logo.png" alt="Young's blog" class="logo"> <span class="site-name can-hide">Young's blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/Spring/" class="nav-link">Spring</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="前端" class="dropdown-title"><a href="/web/" class="link-title">前端</a> <span class="title" style="display:none;">前端</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>前端文章1</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/8143cc480faf9a11/" class="nav-link">JavaScript</a></li></ul></li><li class="dropdown-item"><h4>学习笔记</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/note/javascript/" class="nav-link">《JavaScript教程》</a></li><li class="dropdown-subitem"><a href="/note/js/" class="nav-link">《JavaScript高级程序设计》</a></li><li class="dropdown-subitem"><a href="/note/es6/" class="nav-link">《ES6 教程》</a></li><li class="dropdown-subitem"><a href="/note/vue/" class="nav-link">《Vue》</a></li><li class="dropdown-subitem"><a href="/note/react/" class="nav-link">《React》</a></li><li class="dropdown-subitem"><a href="/note/typescript-axios/" class="nav-link">《TypeScript 从零实现 axios》</a></li><li class="dropdown-subitem"><a href="/note/git/" class="nav-link">《Git》</a></li><li class="dropdown-subitem"><a href="/pages/51afd6/" class="nav-link">TypeScript</a></li><li class="dropdown-subitem"><a href="/pages/4643cd/" class="nav-link">JS设计模式总结</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="页面" class="dropdown-title"><a href="/ui/" class="link-title">页面</a> <span class="title" style="display:none;">页面</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/8309a5b876fc95e3/" class="nav-link">HTML</a></li><li class="dropdown-item"><!----> <a href="/pages/0a83b083bdf257cb/" class="nav-link">CSS</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="技术" class="dropdown-title"><a href="/technology/" class="link-title">技术</a> <span class="title" style="display:none;">技术</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/9a7ee40fc232253e/" class="nav-link">技术文档</a></li><li class="dropdown-item"><!----> <a href="/pages/4c778760be26d8b3/" class="nav-link">GitHub技巧</a></li><li class="dropdown-item"><!----> <a href="/pages/117708e0af7f0bd9/" class="nav-link">Nodejs</a></li><li class="dropdown-item"><!----> <a href="/pages/41f87d890d0a02af/" class="nav-link">博客搭建</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="更多" class="dropdown-title"><a href="/more/" class="link-title">更多</a> <span class="title" style="display:none;">更多</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/f2a556/" class="nav-link">学习</a></li><li class="dropdown-item"><!----> <a href="/pages/aea6571b7a8bae86/" class="nav-link">面试</a></li><li class="dropdown-item"><!----> <a href="/pages/2d615df9a36a98ed/" class="nav-link">心情杂货</a></li><li class="dropdown-item"><!----> <a href="/pages/baaa02/" class="nav-link">实用技巧</a></li><li class="dropdown-item"><!----> <a href="/friends/" class="nav-link">友情链接</a></li></ul></div></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><a href="/pages/beb6c0bd8a66cea6/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/andanyang/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="/img/logo.png"> <div class="blogger-info"><h3>Young</h3> <span></span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/Spring/" class="nav-link">Spring</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="前端" class="dropdown-title"><a href="/web/" class="link-title">前端</a> <span class="title" style="display:none;">前端</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>前端文章1</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/8143cc480faf9a11/" class="nav-link">JavaScript</a></li></ul></li><li class="dropdown-item"><h4>学习笔记</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/note/javascript/" class="nav-link">《JavaScript教程》</a></li><li class="dropdown-subitem"><a href="/note/js/" class="nav-link">《JavaScript高级程序设计》</a></li><li class="dropdown-subitem"><a href="/note/es6/" class="nav-link">《ES6 教程》</a></li><li class="dropdown-subitem"><a href="/note/vue/" class="nav-link">《Vue》</a></li><li class="dropdown-subitem"><a href="/note/react/" class="nav-link">《React》</a></li><li class="dropdown-subitem"><a href="/note/typescript-axios/" class="nav-link">《TypeScript 从零实现 axios》</a></li><li class="dropdown-subitem"><a href="/note/git/" class="nav-link">《Git》</a></li><li class="dropdown-subitem"><a href="/pages/51afd6/" class="nav-link">TypeScript</a></li><li class="dropdown-subitem"><a href="/pages/4643cd/" class="nav-link">JS设计模式总结</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="页面" class="dropdown-title"><a href="/ui/" class="link-title">页面</a> <span class="title" style="display:none;">页面</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/8309a5b876fc95e3/" class="nav-link">HTML</a></li><li class="dropdown-item"><!----> <a href="/pages/0a83b083bdf257cb/" class="nav-link">CSS</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="技术" class="dropdown-title"><a href="/technology/" class="link-title">技术</a> <span class="title" style="display:none;">技术</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/9a7ee40fc232253e/" class="nav-link">技术文档</a></li><li class="dropdown-item"><!----> <a href="/pages/4c778760be26d8b3/" class="nav-link">GitHub技巧</a></li><li class="dropdown-item"><!----> <a href="/pages/117708e0af7f0bd9/" class="nav-link">Nodejs</a></li><li class="dropdown-item"><!----> <a href="/pages/41f87d890d0a02af/" class="nav-link">博客搭建</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="更多" class="dropdown-title"><a href="/more/" class="link-title">更多</a> <span class="title" style="display:none;">更多</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/f2a556/" class="nav-link">学习</a></li><li class="dropdown-item"><!----> <a href="/pages/aea6571b7a8bae86/" class="nav-link">面试</a></li><li class="dropdown-item"><!----> <a href="/pages/2d615df9a36a98ed/" class="nav-link">心情杂货</a></li><li class="dropdown-item"><!----> <a href="/pages/baaa02/" class="nav-link">实用技巧</a></li><li class="dropdown-item"><!----> <a href="/friends/" class="nav-link">友情链接</a></li></ul></div></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><a href="/pages/beb6c0bd8a66cea6/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/andanyang/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Hadoop</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/Hadoop/bigdata_generality/" class="sidebar-link">第一章 大数据技术之大数据概论</a></li><li><a href="/Hadoop/Hadoop-Concept-explanation/" class="sidebar-link">第二章大数据技术之 Hadoop概念讲解</a></li><li><a href="/Hadoop/Build-Hadoop-running-environment/" class="sidebar-link">第三章Hadoop 运行环境搭建</a></li><li><a href="/Hadoop/Hadoop-working-mechanism/" class="sidebar-link">第四章Hadoop之HDFS详解以及工作机制介绍</a></li><li><a href="/Hadoop/haddop-MapReduce/" class="sidebar-link">第五章MapReduce编程框架</a></li><li><a href="/Hadoop/data_compression/" class="sidebar-link">第六章Hadoop 数据压缩</a></li><li><a href="/Hadoop/Yarn/" class="sidebar-link">第七章大数据技术之 Hadoop（Yarn）</a></li><li><a href="/Hadoop/Production_tuning_manual/" aria-current="page" class="active sidebar-link">第八章Hadoop（生产调优手册）</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_1-1-namenode-内存生产配置" class="sidebar-link">1.1 NameNode 内存生产配置</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_1-2-namenode-心跳并发配置" class="sidebar-link">1.2 NameNode 心跳并发配置</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_1-3-开启回收站配置" class="sidebar-link">1.3 开启回收站配置</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_2-1-测试-hdfs-写性能" class="sidebar-link">2.1 测试 HDFS 写性能</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_2-2-测试-hdfs-读性能" class="sidebar-link">2.2 测试 HDFS 读性能</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_3-1-namenode-多目录配置" class="sidebar-link">3.1 NameNode 多目录配置</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_3-2-datanode-多目录配置" class="sidebar-link">3.2 DataNode 多目录配置</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_3-3-集群数据均衡之磁盘间数据均衡" class="sidebar-link">3.3 集群数据均衡之磁盘间数据均衡</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_4-1-添加白名单" class="sidebar-link">4.1 添加白名单</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_4-2-服役新服务器" class="sidebar-link">4.2 服役新服务器</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_4-3-服务器间数据均衡" class="sidebar-link">4.3 服务器间数据均衡</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_4-4-黑名单退役服务器" class="sidebar-link">4.4 黑名单退役服务器</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_5-1-纠删码" class="sidebar-link">5.1 纠删码</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/Hadoop/Production_tuning_manual/#_5-1-1-纠删码原理" class="sidebar-link">5.1.1 纠删码原理</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Production_tuning_manual/#_5-1-2-纠删码案例实操" class="sidebar-link">5.1.2 纠删码案例实操</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_5-2-异构存储-冷热数据分离" class="sidebar-link">5.2 异构存储（冷热数据分离）</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/Hadoop/Production_tuning_manual/#_5-2-1-异构存储-shell-操作" class="sidebar-link">5.2.1 异构存储 Shell 操作</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Production_tuning_manual/#_5-2-2-测试环境准备" class="sidebar-link">5.2.2 测试环境准备</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Production_tuning_manual/#_5-2-3-hot-存储策略案例" class="sidebar-link">5.2.3 HOT 存储策略案例</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Production_tuning_manual/#_5-2-4-warm-存储策略测试" class="sidebar-link">5.2.4 WARM 存储策略测试</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Production_tuning_manual/#_5-2-5-cold-策略测试" class="sidebar-link">5.2.5 COLD 策略测试</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Production_tuning_manual/#_5-2-6-one-ssd-策略测试" class="sidebar-link">5.2.6 ONE_SSD 策略测试</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Production_tuning_manual/#_5-2-7-all-ssd-策略测试" class="sidebar-link">5.2.7 ALL_SSD 策略测试</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Production_tuning_manual/#_5-2-8-lazy-persist-策略测试" class="sidebar-link">5.2.8 LAZY_PERSIST 策略测试</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_6-1-namenode-故障处理" class="sidebar-link">6.1 NameNode 故障处理</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/Hadoop/Production_tuning_manual/#_6-2-集群安全模式-磁盘修复" class="sidebar-link">6.2 集群安全模式&amp;磁盘修复</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_6-3-慢磁盘监控" class="sidebar-link">6.3 慢磁盘监控</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_6-4-小文件归档" class="sidebar-link">6.4 小文件归档</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_7-1-apache-和-apache-集群间数据拷贝" class="sidebar-link">7.1 Apache 和 Apache 集群间数据拷贝</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_7-2-apache-和-cdh-集群间数据拷贝" class="sidebar-link">7.2 Apache 和 CDH 集群间数据拷贝</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_8-1-mapreduce-跑的慢的原因" class="sidebar-link">8.1 MapReduce 跑的慢的原因</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_8-2-mapreduce-常用调优参数" class="sidebar-link">8.2 MapReduce 常用调优参数</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_8-3-mapreduce-数据倾斜问题" class="sidebar-link">8.3 MapReduce 数据倾斜问题</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_9-1-常用的调优参数" class="sidebar-link">9.1 常用的调优参数</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_9-2-容量调度器使用" class="sidebar-link">9.2 容量调度器使用</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_9-3-公平调度器使用" class="sidebar-link">9.3 公平调度器使用</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#第-10-章-hadoop-综合调优" class="sidebar-link">第 10 章 Hadoop 综合调优</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_10-1-hadoop-小文件优化方法" class="sidebar-link">10.1 Hadoop 小文件优化方法</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/Hadoop/Production_tuning_manual/#_10-1-1-hadoop-小文件弊端" class="sidebar-link">10.1.1 Hadoop 小文件弊端</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Production_tuning_manual/#_10-1-2-hadoop-小文件解决方案" class="sidebar-link">10.1.2 Hadoop 小文件解决方案</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Production_tuning_manual/#_10-2-测试-mapreduce-计算性能" class="sidebar-link">10.2 测试 MapReduce 计算性能</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/Hadoop/Production_tuning_manual/#_10-3-企业开发场景案例" class="sidebar-link">10.3 企业开发场景案例</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Production_tuning_manual/#_10-3-1-需求" class="sidebar-link">10.3.1 需求</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Production_tuning_manual/#_10-3-2-hdfs-参数调优" class="sidebar-link">10.3.2 HDFS 参数调优</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Production_tuning_manual/#_10-3-4-yarn-参数调优" class="sidebar-link">10.3.4 Yarn 参数调优</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Production_tuning_manual/#_10-3-5-执行程序" class="sidebar-link">10.3.5 执行程序</a></li></ul></li></ul></li><li><a href="/Hadoop/HA/" class="sidebar-link">Hadoop HA 高可用</a></li><li><a href="/Hadoop/Hadoop_SIGNLE/" class="sidebar-link">Hadoop单节点伪分布式安装</a></li><li><a href="/Hadoop/windows10_build/" class="sidebar-link">hadoop 3.x 在windows10下编译</a></li><li><a href="/Hadoop/DataNode_RUN_FAIL/" class="sidebar-link">hadoop 踩坑记 DataNode 启动失败(ClusterID不一致)：Initialization failed for Block pool</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>kafka</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Flume</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>hive</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>scala</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>spark</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/categories/?category=%E5%A4%A7%E6%95%B0%E6%8D%AE" title="分类" data-v-06225672>大数据</a></li><li data-v-06225672><a href="/categories/?category=Hadoop" title="分类" data-v-06225672>Hadoop</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/andanyoung" target="_blank" title="作者" class="beLink" data-v-06225672>andanyang</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2022-06-28</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABGpJREFUSA3tVVtoXFUU3fvOI53UlmCaKIFmwEhsE7QK0ipFEdHEKpXaZGrp15SINsXUWvBDpBgQRKi0+KKoFeJHfZA+ED9KKoIU2gYD9UejTW4rVIzm0VSTziPzuNu1z507dibTTjL4U/DAzLn3nL3X2o91ziX6f9wMFdh6Jvbm9nNSV0msViVO6tN1Rm7NMu2OpeJ9lWBUTDxrJbYTS0hInuwciu9eLHlFxCLCZEk3MegsJmZ5K/JD6t7FkFdEvGUo1g7qJoG3MHImqRIn8/nzY1K9UPKKiJmtnUqHVE3Gbuay6vJE/N2FEmuxFjW2nUuE0yQXRRxLiTUAzs36zhZvOXJPdX850EVnnLZkB8prodQoM5JGj7Xk2mvC7JB8tG04Ef5PiXtG0UtxupRQSfTnBoCy554x18yJHI6I+G5Eru4LHmPJZEQsrvPUbMiA8G/WgMK7w7I+ez7++o2ANfbrjvaOl1tFMs+htG3IrZH9/hDX1Pr8Tc0UvH8tcX29KzAgIGcEkINyW5BF9x891hw6VYqgJHEk0huccS7vh3C6gTiODL+26huuBtbct8eZnqLML8PkxGYpuPZBqtqwkSjgc4mB5gbgig5i+y0UDK35LMxXisn9xQtK+nd26gTIHsHe/oblK/b29fUmN/8Y+9jAQrnBp56m1LcDlDp9irKTExSKduXJVWSqdBMA08pEJnEIOB3FPPMybu/oeV8zFeYN3xx576Q6RH+VmplE4ncQV5v+5rzSoyOU7PuEAg8g803PwBJ0CExno/jcMbN8tONYeOmHiuUNryvm3fRUy4tMPVLdAGkUhNWuggGrJcXPv+ouCjz0MKUHz1J2/E8IC9nqTabcxgaBYM0hPhD5Y65FsbxRQKxCQrDjDctW7PUM3HuZunFyifSAqEfuzCp48Il24luWUWZoyJCaPR82jE0+kFA643wRFVni4RYSq3ohJO2pZ7B5dO4xkDWbEpossJPLSrPjYID8rS2UHTlvyNxqIGsg674XJJ7vnh5L7PNwC4hh2sjCI96mzszOTpxLF0T7l88Yz7lAuK6OnL8gXLOnTvpzSb22YG8W7us3jSebFHeeqnXRG1vt+MoUM84LQIBmMsCTAcOauTh0T0l0neQK7m2bLMt2mGxU3HYssS0J2cdv5wljlPsrIuZLAG/2DOZIXgCYT8uMGZN+e2kSirfxZOPCsC0f24nTZzspnVn9VePS1Z5vubmAGGXG8ZFno9Hel0yfA5ZPhF7Dh972BQJ2qCpgH67lmWtBYbvk6sz02wjky2vXyz0XErP/kFB619js1BtwfOV4OPRqOQBjy3Qbk18vigUPPSD5ceHnwck7W9bhAqZdd7SuG7w4/P2F/GaJh8c7e9qgow+Q7cGBo+98WsLkuktFqiZabtXuQTu/Y5ETbR0v7tNSFnvrmu6pjdoan2KjMu8q/Hmj1EfCO2ZGfEIbIXKUlw8qaX9/b2oeSJmFksSeT/Fn0V3nSypChh4Gjh74ybO9aeZ/AN2dwciu2/MhAAAAAElFTkSuQmCC">第八章Hadoop（生产调优手册）<!----></h1>  <div class="theme-vdoing-content content__default"><p><a href="https://kdocs.cn/l/csdAQMPkdDK6" target="_blank" rel="noopener noreferrer"><img src="/assets/img/image-20230901165335730.84b53394.png" alt="第八章Hadoop（生产调优手册）"><span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h1 id="第-1-章-hdfs-核心参数"><a href="#第-1-章-hdfs-核心参数" class="header-anchor">#</a> 第 1 章 HDFS—核心参数</h1> <h2 id="_1-1-namenode-内存生产配置"><a href="#_1-1-namenode-内存生产配置" class="header-anchor">#</a> 1.1 NameNode 内存生产配置</h2> <ul><li>1）NameNode 内存计算</li></ul> <p>每个文件块大概占用 150byte，一台服务器 128G 内存为例，能存储多少文件块呢？</p> <p>128 _ 1024 _ 1024 * 1024 / 150Byte ≈ 9.1 亿</p> <p>G MB KB Byte</p> <ul><li>2）Hadoop2.x 系列，配置 NameNode 内存</li></ul> <p>NameNode 内存默认 2000m，如果服务器内存 4G，NameNode 内存可以配置 3g。在 hadoop-env.sh 文件中配置如下。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>HADOOP_NAMENODE_OPTS=-Xmx3072m
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><ul><li>3）Hadoop3.x 系列，配置 NameNode 内存
<ul><li>（1）hadoop-env.sh 中描述 Hadoop 的内存是动态分配的</li></ul></li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code># The maximum amount of heap to use (Java -Xmx).  If no unit
# is provided, it will be converted to MB.  Daemons will
# prefer any Xmx setting in their respective _OPT variable.
# There is no default; the JVM will autoscale based upon machine
# memory size.
# export HADOOP_HEAPSIZE_MAX=

# The minimum amount of heap to use (Java -Xms).  If no unit
# is provided, it will be converted to MB.  Daemons will
# prefer any Xms setting in their respective _OPT variable.
# There is no default; the JVM will autoscale based upon machine
# memory size.
# export HADOOP_HEAPSIZE_MIN=
HADOOP_NAMENODE_OPTS=-Xmx102400m
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div><p>（2）查看 NameNode 占用内存</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ jps
3088 NodeManager
2611 NameNode
3271 JobHistoryServer
2744 DataNode
3579 Jps
[atguigu@hadoop102 ~]$ jmap -heap 2611
Heap Configuration:
   MaxHeapSize              = 1031798784 (984.0MB)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>（3）查看 DataNode 占用内存</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ jmap -heap 2744
Heap Configuration:
   MaxHeapSize              = 1031798784 (984.0MB)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>查看发现 hadoop102 上的 NameNode 和 DataNode 占用内存都是自动分配的，且相等。不是很合理。</p> <p><strong>经验参考：</strong></p> <p><a href="https://docs.cloudera.com/documentation/enterprise/6/release-notes/topics/rg_hardware_requirements.html#concept_fzz_dq4_gbb%5D" target="_blank" rel="noopener noreferrer">https://docs.cloudera.com/documentation/enterprise/6/release-notes/topics/rg_hardware_requirements.html#concept_fzz_dq4_gbb<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p><img src="/assets/img/wps3.9abaab15.jpg" alt="img"> <img src="/assets/img/wps4.0a8ab47b.jpg" alt="img"></p> <p>具体修改：hadoop-env.sh</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>export HDFS_NAMENODE_OPTS=&quot;-Dhadoop.security.logger=INFO,RFAS -Xmx1024m&quot;
export HDFS_DATANODE_OPTS=&quot;-Dhadoop.security.logger=ERROR,RFAS -Xmx1024m&quot;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h2 id="_1-2-namenode-心跳并发配置"><a href="#_1-2-namenode-心跳并发配置" class="header-anchor">#</a> <strong>1.2</strong> <strong>NameNode 心跳并发配置</strong></h2> <p><img src="/assets/img/image-20230629001658507.41f04211.png" alt="image-20230629001658507"></p> <p>1）hdfs-site.xml</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>The number of Namenode RPC server threads that listen to requests from clients. If dfs.namenode.servicerpc-address is not configured then Namenode RPC server threads listen to requests from all nodes.
NameNode有一个工作线程池，用来处理不同DataNode的并发心跳以及客户端并发的元数据操作。
对于大集群或者有大量客户端的集群来说，通常需要增大该参数。默认值是10。
&lt;property&gt;
    &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt;
    &lt;value&gt;21&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>企业经验：dfs.namenode.handler.count=<img src="data:image/jpeg;base64,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" alt="img">，比如集群规模（DataNode 台数)为 3 台时，此参数设置为 21。可通过简单的 python 代码计算该值，代码如下。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ sudo yum install -y python
[atguigu@hadoop102 ~]$ python
Python 2.7.5 (default, Apr 11 2018, 07:36:10)
[GCC 4.8.5 20150623 (Red Hat 4.8.5-28)] on linux2
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt; import math
&gt;&gt;&gt; print int(20*math.log(3))
21
&gt;&gt;&gt; quit()
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><h2 id="_1-3-开启回收站配置"><a href="#_1-3-开启回收站配置" class="header-anchor">#</a> <strong>1.3</strong> <strong>开启回收站配置</strong></h2> <p>开启回收站功能，可以将删除的文件在不超时的情况下，恢复原数据，起到防止误删除、备份等作用。</p> <p>1）回收站工作机制</p> <p><img src="/assets/img/image-20230629001844220.bb7decb7.png" alt="image-20230629001844220"></p> <p>2）开启回收站功能参数说明</p> <p>（1）默认值 fs.trash.interval = 0，0 表示禁用回收站；其他值表示设置文件的存活时间。</p> <p>（2）默认值 fs.trash.checkpoint.interval = 0，检查回收站的间隔时间。如果该值为 0，则该值设置和 fs.trash.interval 的参数值相等。</p> <p>（3）要求 fs.trash.checkpoint.interval &lt;= fs.trash.interval。</p> <p>3）启用回收站</p> <p>修改 core-site.xml，配置垃圾回收时间为 1 分钟。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;property&gt;
    &lt;name&gt;fs.trash.interval&lt;/name&gt;
    &lt;value&gt;1&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>4）查看回收站</p> <p>回收站目录在 HDFS 集群中的路径：/user/atguigu/.Trash/….</p> <p><mark>5）注意：通过网页上直接删除的文件也不会走回收站。</mark></p> <p>6）通过程序删除的文件不会经过回收站，需要调用 moveToTrash()才进入回收站</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>Trash trash = New Trash(conf);
trash.moveToTrash(path);
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>7）只有在命令行利用<code>hadoop fs -rm</code>命令删除的文件才会走回收站。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -rm -r /user/atguigu/input
2021-07-14 16:13:42,643 INFO fs.TrashPolicyDefault: Moved: 'hdfs://hadoop102:9820/user/atguigu/input' to trash at: hdfs://hadoop102:9820/user/atguigu/.Trash/Current/user/atguigu/input
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>8）恢复回收站数据</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -mv
/user/atguigu/.Trash/Current/user/atguigu/input    /user/atguigu/input
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h1 id="第-2-章-hdfs-集群压测"><a href="#第-2-章-hdfs-集群压测" class="header-anchor">#</a> 第 2 章 HDFS—集群压测</h1> <p>在企业中非常关心每天从 Java 后台拉取过来的数据，需要多久能上传到集群？消费者关心多久能从 HDFS 上拉取需要的数据？</p> <p>为了搞清楚 HDFS 的读写性能，生产环境上非常需要对集群进行压测。</p> <p><img src="/assets/img/image-20230629002725626.1d4dc5fa.png" alt="image-20230629002725626"></p> <p>HDFS 的读写性能主要受<strong>网络和磁盘</strong>影响比较大。为了方便测试，将 hadoop102、hadoop103、hadoop104 虚拟机网络都设置为 100mbps。</p> <p><img src="/assets/img/image-20230629002750512.88d04983.png" alt="image-20230629002750512"></p> <p>100Mbps 单位是 bit；10M/s 单位是 byte ; 1byte=8bit，100Mbps/8=12.5M/s。</p> <p>测试网速：来到 hadoop102 的/opt/module 目录，创建一个</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 software]$ python -m SimpleHTTPServer
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h2 id="_2-1-测试-hdfs-写性能"><a href="#_2-1-测试-hdfs-写性能" class="header-anchor">#</a> <strong>2.1</strong> 测试 HDFS 写性能</h2> <p>0）写测试底层原理</p> <p><img src="/assets/img/image-20230629002845923.1df46307.png" alt="image-20230629002845923"></p> <p>1）测试内容：向 HDFS 集群写 10 个 128M 的文件</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 mapreduce]$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.3-tests.jar TestDFSIO -write -nrFiles 10 -fileSize 128MB

2021-02-09 10:43:16,853 INFO fs.TestDFSIO: ----- TestDFSIO ----- : write
2021-02-09 10:43:16,854 INFO fs.TestDFSIO:             Date &amp; time: Tue Feb 09 10:43:16 CST 2021
2021-02-09 10:43:16,854 INFO fs.TestDFSIO:         Number of files: 10
2021-02-09 10:43:16,854 INFO fs.TestDFSIO:  Total MBytes processed: 1280
2021-02-09 10:43:16,854 INFO fs.TestDFSIO:       Throughput mb/sec: 1.61
2021-02-09 10:43:16,854 INFO fs.TestDFSIO:  Average IO rate mb/sec: 1.9
2021-02-09 10:43:16,854 INFO fs.TestDFSIO:   IO rate std deviation: 0.76
2021-02-09 10:43:16,854 INFO fs.TestDFSIO:      Test exec time sec: 133.05
2021-02-09 10:43:16,854 INFO fs.TestDFSIO:
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p><mark>注意：nrFiles n 为生成 mapTask 的数量，生产环境一般可通过 hadoop103:8088 查看 CPU 核数，设置为（CPU 核数 - 1)</mark></p> <ul><li><p>Number of files：生成 mapTask 数量，一般是集群中（CPU 核数-1），我们测试虚拟机就按照实际的物理内存-1 分配即可</p></li> <li><p>Total MBytes processed：单个 map 处理的文件大小</p></li> <li><p>Throughput mb/sec:单个 mapTak 的吞吐量；</p> <ul><li>计算方式：处理的总文件大小/每一个 mapTask 写数据的时间累加</li> <li>集群整体吞吐量：生成 mapTask 数量*单个 mapTak 的吞吐量</li></ul></li> <li><p>Average IO rate mb/sec: 平均 mapTak 的吞吐量</p> <ul><li>计算方式：每个 mapTask 处理文件大小/每一个 mapTask 写数据的时间全部相加除以 task 数量</li></ul></li> <li><p>IO rate std deviation:方差、反映各个 mapTask 处理的差值，越小越均衡</p></li></ul> <p>2）注意：如果测试过程中，出现异常</p> <p>（1）可以在 yarn-site.xml 中设置虚拟内存检测为 false</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;!--是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是true --&gt;
&lt;property&gt;
     &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;
     &lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>（2）分发配置并重启 Yarn 集群</p> <p>3）测试结果分析</p> <p>（1）由于副本 1 就在本地，所以该副本不参与测试</p> <p><img src="/assets/img/image-20230629003226189.0b00f4f1.png" alt="image-20230629003226189"></p> <p>一共参与测试的文件：10 个文件 * 2 个副本 = 20 个</p> <p>压测后的速度：1.61</p> <p>实测速度：1.61M/s * 20 个文件 ≈ 32M/s</p> <p>三台服务器的带宽：12.5 + 12.5 + 12.5 ≈ 30m/s</p> <p>所有网络资源都已经用满。</p> <p><strong>如果实测速度远远小于网络，并且实测速度不能满足工作需求，可以考虑采用固态硬盘或者增加磁盘个数。</strong></p> <p>（2）如果客户端不在集群节点，那就三个副本都参与计算</p> <p><img src="/assets/img/image-20230629003320851.2ecfd7b7.png" alt="image-20230629003320851"></p> <h2 id="_2-2-测试-hdfs-读性能"><a href="#_2-2-测试-hdfs-读性能" class="header-anchor">#</a> <strong>2.2</strong> 测试 HDFS 读性能</h2> <p>1）测试内容：读取 HDFS 集群 10 个 128M 的文件</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 mapreduce]$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.3-tests.jar TestDFSIO -read -nrFiles 10 -fileSize 128MB

2021-02-09 11:34:15,847 INFO fs.TestDFSIO: ----- TestDFSIO ----- : read
2021-02-09 11:34:15,847 INFO fs.TestDFSIO:             Date &amp; time: Tue Feb 09 11:34:15 CST 2021
2021-02-09 11:34:15,847 INFO fs.TestDFSIO:         Number of files: 10
2021-02-09 11:34:15,847 INFO fs.TestDFSIO:  Total MBytes processed: 1280
2021-02-09 11:34:15,848 INFO fs.TestDFSIO:       Throughput mb/sec: 200.28
2021-02-09 11:34:15,848 INFO fs.TestDFSIO:  Average IO rate mb/sec: 266.74
2021-02-09 11:34:15,848 INFO fs.TestDFSIO:   IO rate std deviation: 143.12
2021-02-09 11:34:15,848 INFO fs.TestDFSIO:      Test exec time sec: 20.83
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><p>2）删除测试生成数据</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 mapreduce]$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.3-tests.jar TestDFSIO -clean
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>3）测试结果分析：为什么读取文件速度大于网络带宽？由于目前只有三台服务器，且有三个副本，数据读取就近原则，相当于都是读取的本地磁盘数据，没有走网络。</p> <p><img src="/assets/img/image-20230629003411139.74af7749.png" alt="image-20230629003411139"></p> <h1 id="第-3-章-hdfs-多目录"><a href="#第-3-章-hdfs-多目录" class="header-anchor">#</a> 第 3 章 HDFS—多目录</h1> <h2 id="_3-1-namenode-多目录配置"><a href="#_3-1-namenode-多目录配置" class="header-anchor">#</a> 3.1 NameNode 多目录配置</h2> <p>1）NameNode 的本地目录可以配置成多个，<strong>且每个目录存放内容相同</strong>，增加了可靠性</p> <p><img src="/assets/img/image-20230629003534834.95d4497a.png" alt="image-20230629003534834"></p> <p>2）具体配置如下</p> <p>（1）在 hdfs-site.xml 文件中添加如下内容</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;property&gt;
     &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
     &lt;value&gt;file://${hadoop.tmp.dir}/dfs/name1,file://${hadoop.tmp.dir}/dfs/name2&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p><strong>注意：因为每台服务器节点的磁盘情况不同，所以这个配置配完之后，可以选择不分发</strong></p> <p>（2）停止集群，删除三台节点的 data 和 logs 中所有数据。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ rm -rf data/ logs/
[atguigu@hadoop103 hadoop-3.1.3]$ rm -rf data/ logs/
[atguigu@hadoop104 hadoop-3.1.3]$ rm -rf data/ logs/
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>（3）格式化集群并启动。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ bin/hdfs namenode -format
[atguigu@hadoop102 hadoop-3.1.3]$ sbin/start-dfs.sh
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>3）查看结果</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 dfs]$ ll
总用量 12
drwx------. 3 atguigu atguigu 4096 12月 11 08:03 data
drwxrwxr-x. 3 atguigu atguigu 4096 12月 11 08:03 name1
drwxrwxr-x. 3 atguigu atguigu 4096 12月 11 08:03 name2
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p><strong>检查 name1 和 name2 里面的内容，发现一模一样。</strong></p> <h2 id="_3-2-datanode-多目录配置"><a href="#_3-2-datanode-多目录配置" class="header-anchor">#</a> 3.2 DataNode 多目录配置</h2> <p>1）DataNode 可以配置成多个目录，<strong>每个目录存储的数据不一样</strong>（数据不是副本）</p> <p><img src="/assets/img/image-20230629003732601.717046da.png" alt="image-20230629003732601"></p> <p>2）具体配置如下</p> <p>在 hdfs-site.xml 文件中添加如下内容</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;property&gt;
     &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
     &lt;value&gt;file://${hadoop.tmp.dir}/dfs/data1,file://${hadoop.tmp.dir}/dfs/data2&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>3）查看结果</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 dfs]$ ll
总用量 12
drwx------. 3 atguigu atguigu 4096 4月   4 14:22 data1
drwx------. 3 atguigu atguigu 4096 4月   4 14:22 data2
drwxrwxr-x. 3 atguigu atguigu 4096 12月 11 08:03 name1
drwxrwxr-x. 3 atguigu atguigu 4096 12月 11 08:03 name2
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>4）向集群上传一个文件，再次观察两个文件夹里面的内容发现不一致（一个有数一个没有）</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -put wcinput/word.txt /
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h2 id="_3-3-集群数据均衡之磁盘间数据均衡"><a href="#_3-3-集群数据均衡之磁盘间数据均衡" class="header-anchor">#</a> 3.3 集群数据均衡之磁盘间数据均衡</h2> <p>生产环境，由于硬盘空间不足，往往需要增加一块硬盘。刚加载的硬盘没有数据时，可以执行磁盘数据均衡命令。（Hadoop3.x 新特性）</p> <blockquote><p>同一台主机</p></blockquote> <p><img src="/assets/img/image-20230629003850739.fe0d62e6.png" alt="image-20230629003850739"></p> <p>（1）生成均衡计划（<strong>我们只有一块磁盘，不会生成计划</strong>）</p> <p>（2）执行均衡计划</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hdfs diskbalancer -execute hadoop103.plan.json
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（3）查看当前均衡任务的执行情况</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hdfs diskbalancer -query hadoop103
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（4）取消均衡任务</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hdfs diskbalancer -cancel hadoop103.plan.json
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h1 id="第-4-章-hdfs-集群扩容及缩容"><a href="#第-4-章-hdfs-集群扩容及缩容" class="header-anchor">#</a> 第 4 章 HDFS—集群扩容及缩容</h1> <h2 id="_4-1-添加白名单"><a href="#_4-1-添加白名单" class="header-anchor">#</a> 4.1 添加白名单</h2> <p>白名单：表示在白名单的主机 IP 地址可以，用来存储数据。</p> <p>企业中：配置白名单，可以尽量防止黑客恶意访问攻击。</p> <p><img src="/assets/img/image-20230630001204615.4be7115a.png" alt="image-20230630001204615"></p> <p>配置白名单步骤如下：</p> <ul><li><p>1）在 NameNode 节点的/opt/module/hadoop-3.1.3/etc/hadoop 目录下分别创建 whitelist 和 blacklist 文件</p> <ul><li><p>（1）创建白名单</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop]$ vim whitelist
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>在 whitelist 中添加如下主机名称，假如集群正常工作的节点为 102 103</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hadoop102
hadoop103
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></li> <li><p>（2）创建黑名单</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop]$ touch blacklist
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>保持空的就可以</p></li></ul></li> <li><p>2）在 hdfs-site.xml 配置文件中增加 dfs.hosts 配置参数</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;!-- 白名单 --&gt;
&lt;property&gt;
     &lt;name&gt;dfs.hosts&lt;/name&gt;
     &lt;value&gt;/opt/module/hadoop-3.1.3/etc/hadoop/whitelist&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 黑名单 --&gt;
&lt;property&gt;
     &lt;name&gt;dfs.hosts.exclude&lt;/name&gt;
     &lt;value&gt;/opt/module/hadoop-3.1.3/etc/hadoop/blacklist&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div></li> <li><p>3）分发配置文件 whitelist，hdfs-site.xml</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop104 hadoop]$ xsync hdfs-site.xml whitelist
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li> <li><p>4）第一次添加白名单必须重启集群，不是第一次，只需要刷新 NameNode 节点即可</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ myhadoop.sh stop
[atguigu@hadoop102 hadoop-3.1.3]$ myhadoop.sh start
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></li> <li><p>5）在 web 浏览器上查看 DN，http://hadoop102:9870/dfshealth.html#tab-datanode</p> <p><img src="/assets/img/image-20230630001510911.1a622a83.png" alt="image-20230630001510911"></p></li> <li><p>6）在 hadoop104 上执行上传数据数据失败</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop104 hadoop-3.1.3]$ hadoop fs -put NOTICE.txt /
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li> <li><p>7）二次修改白名单，增加 hadoop104</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop]$ vim whitelist
修改为如下内容
hadoop102
hadoop103
hadoop104
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div></li> <li><p>8）刷新 NameNode</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs dfsadmin -refreshNodes
Refresh nodes successful
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></li> <li><p>9）在 web 浏览器上查看 DN，http://hadoop102:9870/dfshealth.html#tab-datanode</p></li></ul> <p><img src="/assets/img/image-20230630001627630.3b616416.png" alt="image-20230630001627630"></p> <h2 id="_4-2-服役新服务器"><a href="#_4-2-服役新服务器" class="header-anchor">#</a> 4.2 服役新服务器</h2> <ul><li><p>1）需求</p> <p>随着公司业务的增长，数据量越来越大，原有的数据节点的容量已经不能满足存储数据的需求，需要在原有集群基础上动态添加新的数据节点。</p></li> <li><p>2）环境准备</p> <ul><li><p>（1）在 hadoop100 主机上再克隆一台 hadoop105 主机</p></li> <li><p>（2）修改 IP 地址和主机名称</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[root@hadoop105 ~]# vim /etc/sysconfig/network-scripts/ifcfg-ens33
[root@hadoop105 ~]# vim /etc/hostname
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></li> <li><p>（3）拷贝 hadoop102 的/opt/module 目录和/etc/profile.d/my_env.sh 到 hadoop105</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 opt]$ scp -r module/* atguigu@hadoop105:/opt/module/

[atguigu@hadoop102 opt]$ sudo scp /etc/profile.d/my_env.sh root@hadoop105:/etc/profile.d/my_env.sh

[atguigu@hadoop105 hadoop-3.1.3]$ source /etc/profile
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div></li> <li><p>（4）删除 hadoop105 上 Hadoop 的历史数据，data 和 log 数据</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop105 hadoop-3.1.3]$ rm -rf data/ logs/
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li> <li><p>（5）配置 hadoop102 和 hadoop103 到 hadoop105 的 ssh 无密登录</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop105

[atguigu@hadoop103 .ssh]$ ssh-copy-id hadoop105
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div></li></ul></li> <li><p>3）服役新节点具体步骤</p> <ul><li>（1）直接启动 DataNode，即可关联到集群</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop105 hadoop-3.1.3]$ hdfs --daemon start datanode
[atguigu@hadoop105 hadoop-3.1.3]$ yarn --daemon start nodemanager
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p><img src="/assets/img/image-20230630001941619.b75d0f81.png" alt="image-20230630001941619"></p></li> <li><p>4）在白名单中增加新服役的服务器</p> <ul><li><p>（1）在白名单 whitelist 中增加 hadoop104、hadoop105，并重启集群</p> <div class="language- line-numbers-mode"><pre class="language-text"><code> [atguigu@hadoop102 hadoop]$ vim whitelist
 修改为如下内容
 hadoop102
 hadoop103
 hadoop104
 hadoop105
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div></li> <li><p>（2）分发</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop]$ xsync whitelist
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li> <li><p>（3）刷新 NameNode</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs dfsadmin -refreshNodes
Refresh nodes successful
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></li></ul></li> <li><p>5）在 hadoop105 上上传文件</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop105 hadoop-3.1.3]$ hadoop fs -put /opt/module/hadoop-3.1.3/LICENSE.txt /
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><img src="/assets/img/image-20230630002144148.91f5cffe.png" alt="image-20230630002144148"></p> <p>思考：如果数据不均衡（hadoop105 数据少，其他节点数据多），怎么处理？</p></li></ul> <h2 id="_4-3-服务器间数据均衡"><a href="#_4-3-服务器间数据均衡" class="header-anchor">#</a> 4.3 服务器间数据均衡</h2> <ul><li>1）企业经验：</li></ul> <p>在企业开发中，如果经常在 hadoop102 和 hadoop104 上提交任务，且副本数为 2，由于数据本地性原则，就会导致 hadoop102 和 hadoop104 数据过多，hadoop103 存储的数据量小。</p> <p>另一种情况，就是新服役的服务器数据量比较少，需要执行集群均衡命令。</p> <p><img src="/assets/img/image-20230630002306206.57929a4a.png" alt="image-20230630002306206"></p> <ul><li><p>2）开启数据均衡命令：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop105 hadoop-3.1.3]$ sbin/start-balancer.sh -threshold 10
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>对于参数 10，代表的是集群中各个节点的磁盘空间利用率相差不超过 10%，可根据实际情况进行调整</p></li> <li><p>3）停止数据均衡命令：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop105 hadoop-3.1.3]$ sbin/stop-balancer.sh
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><blockquote><p>注意：由于 HDFS 需要启动单独的 Rebalance Server 来执行 Rebalance 操作，<a href="http://xn--NameNodestart-balancer-sy68a2bx05ag98dux2afg9ay6af924fm2hzl3e.sh" target="_blank" rel="noopener noreferrer">所以尽量不要在 NameNode 上执行 start-balancer.sh<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>，而是找一台比较空闲的机器。</p></blockquote> <h2 id="_4-4-黑名单退役服务器"><a href="#_4-4-黑名单退役服务器" class="header-anchor">#</a> 4.4 黑名单退役服务器</h2> <p>黑名单：表示在黑名单的主机 IP 地址不可以，用来存储数据。</p> <p>企业中：配置黑名单，用来退役服务器。</p> <p><img src="/assets/img/image-20230630002451232.c663d81e.png" alt="image-20230630002451232"></p> <p>黑名单配置步骤如下：</p></li> <li><p>1）编辑/opt/module/hadoop-3.1.3/etc/hadoop 目录下的 blacklist 文件</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop] vim blacklist
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>添加如下主机名称（要退役的节点）</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hadoop105
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><blockquote><p>注意：如果白名单中没有配置，需要在 hdfs-site.xml 配置文件中增加 dfs.hosts 配置参数</p></blockquote> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;!-- 黑名单 --&gt;
&lt;property&gt;
     &lt;name&gt;dfs.hosts.exclude&lt;/name&gt;
     &lt;value&gt;/opt/module/hadoop-3.1.3/etc/hadoop/blacklist&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div></li> <li><p>2）分发配置文件 blacklist，hdfs-site.xml</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop104 hadoop]$ xsync hdfs-site.xml blacklist
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li> <li><p>3）第一次添加黑名单必须重启集群，不是第一次，只需要刷新 NameNode 节点即可</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs dfsadmin -refreshNodes
Refresh nodes successful
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></li> <li><p>4）检查 Web 浏览器，退役节点的状态为 decommission in progress（退役中），说明数据节点正在复制块到其他节点</p> <p><img src="/assets/img/image-20230630002721564.c4edb77e.png" alt="image-20230630002721564"></p> <p><img src="data:image/png;base64,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" alt="image-20230630002726789"></p></li> <li><p>5）等待退役节点状态为 decommissioned（所有块已经复制完成），停止该节点及节点资源管理器。注意：如果副本数是 3，服役的节点小于等于 3，是不能退役成功的，需要修改副本数后才能退役</p> <p><img src="data:image/png;base64,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" alt="image-20230630002746276"></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop105 hadoop-3.1.3]$ hdfs --daemon stop datanode
stopping datanode
[atguigu@hadoop105 hadoop-3.1.3]$ yarn --daemon stop nodemanager
stopping nodemanager
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div></li> <li><p>6）如果数据不均衡，可以用命令实现集群的再平衡</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ sbin/start-balancer.sh -threshold 10
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li></ul> <h1 id="第-5-章-hdfs-存储优化"><a href="#第-5-章-hdfs-存储优化" class="header-anchor">#</a> 第 5 章 HDFS—存储优化</h1> <blockquote><p>注：演示纠删码和异构存储需要一共 5 台虚拟机。尽量拿另外一套集群。提前准备 5 台服务器的集群。</p></blockquote> <h2 id="_5-1-纠删码"><a href="#_5-1-纠删码" class="header-anchor">#</a> 5.1 纠删码</h2> <h3 id="_5-1-1-纠删码原理"><a href="#_5-1-1-纠删码原理" class="header-anchor">#</a> 5.1.1 纠删码原理</h3> <p>HDFS 默认情况下，一个文件有 3 个副本，这样提高了数据的可靠性，但也带来了 2 倍的冗余开销。Hadoop3.x 引入了纠删码，采用计算的方式，可以节省约 50％左右的存储空间。</p> <p><img src="/assets/img/image-20230630002921587.6fe26520.png" alt="image-20230630002921587"></p> <ul><li><p>1）纠删码操作相关的命令</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs ec
Usage: bin/hdfs ec [COMMAND]
          [-listPolicies]
          [-addPolicies -policyFile &lt;file&gt;]
          [-getPolicy -path &lt;path&gt;]
          [-removePolicy -policy &lt;policy&gt;]
          [-setPolicy -path &lt;path&gt; [-policy &lt;policy&gt;] [-replicate]]
          [-unsetPolicy -path &lt;path&gt;]
          [-listCodecs]
          [-enablePolicy -policy &lt;policy&gt;]
          [-disablePolicy -policy &lt;policy&gt;]
          [-help &lt;command-name&gt;].
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div></li> <li><p>2）查看当前支持的纠删码策略</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3] hdfs ec -listPolicies

Erasure Coding Policies:
ErasureCodingPolicy=[Name=RS-10-4-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=10, numParityUnits=4]], CellSize=1048576, Id=5], State=DISABLED

ErasureCodingPolicy=[Name=RS-3-2-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=3, numParityUnits=2]], CellSize=1048576, Id=2], State=DISABLED

ErasureCodingPolicy=[Name=RS-6-3-1024k, Schema=[ECSchema=[Codec=rs, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=1], State=ENABLED

ErasureCodingPolicy=[Name=RS-LEGACY-6-3-1024k, Schema=[ECSchema=[Codec=rs-legacy, numDataUnits=6, numParityUnits=3]], CellSize=1048576, Id=3], State=DISABLED

ErasureCodingPolicy=[Name=XOR-2-1-1024k, Schema=[ECSchema=[Codec=xor, numDataUnits=2, numParityUnits=1]], CellSize=1048576, Id=4], State=DISABLED
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div></li> <li><p>3）纠删码策略解释:</p> <ul><li>RS-3-2-1024k：使用 RS 编码，每 3 个数据单元，生成 2 个校验单元，共 5 个单元，也就是说：这 5 个单元中，只要有任意的 3 个单元存在（不管是数据单元还是校验单元，只要总数=3），就可以得到原始数据。每个单元的大小是 1024k=1024*1024=1048576。</li></ul> <p><img src="/assets/img/image-20230630003116899.9e2e2f15.png" alt="image-20230630003116899"></p> <ul><li><p>RS-10-4-1024k：使用 RS 编码，每 10 个数据单元（cell），生成 4 个校验单元，共 14 个单元，也就是说：这 14 个单元中，只要有任意的 10 个单元存在（不管是数据单元还是校验单元，只要总数=10），就可以得到原始数据。每个单元的大小是 1024k=1024*1024=1048576。</p></li> <li><p>RS-6-3-1024k：使用 RS 编码，每 6 个数据单元，生成 3 个校验单元，共 9 个单元，也就是说：这 9 个单元中，只要有任意的 6 个单元存在（不管是数据单元还是校验单元，只要总数=6），就可以得到原始数据。每个单元的大小是 1024k=1024*1024=1048576。</p></li> <li><p>RS-LEGACY-6-3-1024k：策略和上面的 RS-6-3-1024k 一样，只是编码的算法用的是 rs-legacy。</p></li> <li><p>XOR-2-1-1024k：使用 XOR 编码（速度比 RS 编码快），每 2 个数据单元，生成 1 个校验单元，共 3 个单元，也就是说：这 3 个单元中，只要有任意的 2 个单元存在（不管是数据单元还是校验单元，只要总数= 2），就可以得到原始数据。每个单元的大小是 1024k=1024*1024=1048576。</p></li></ul></li></ul> <h3 id="_5-1-2-纠删码案例实操"><a href="#_5-1-2-纠删码案例实操" class="header-anchor">#</a> 5.1.2 纠删码案例实操</h3> <p><img src="/assets/img/image-20230630003205173.0eb458ab.png" alt="image-20230630003205173"></p> <p>纠删码策略是给<strong>具体一个路径设置</strong>。所有往此路径下存储的文件，都会执行此策略。</p> <blockquote><p><strong>默认只开启对 RS-6-3-1024k 策略的支</strong>持，如要使用别的策略需要提前启用。</p></blockquote> <ul><li><p>1）需求：将/input 目录设置为 RS-3-2-1024k 策略</p></li> <li><p>2）具体步骤</p> <ul><li><p>（1）开启对 RS-3-2-1024k 策略的支持</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$  hdfs ec -enablePolicy  -policy RS-3-2-1024k
Erasure coding policy RS-3-2-1024k is enabled
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></li> <li><p>（2）在 HDFS 创建目录，并设置 RS-3-2-1024k 策略</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102  hadoop-3.1.3]$  hdfs dfs -mkdir /input
[atguigu@hadoop202 hadoop-3.1.3]$ hdfs ec -setPolicy -path /input -policy RS-3-2-1024k
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></li> <li><p>（3）上传文件，并查看文件编码后的存储情况</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs dfs -put web.log /input
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><blockquote><p>注：你所上传的文件需要大于 2M 才能看出效果。（低于 2M，只有一个数据单元和两个校验单元）</p></blockquote></li> <li><p>（4）查看存储路径的数据单元和校验单元，并作破坏实验</p></li></ul></li></ul> <h2 id="_5-2-异构存储-冷热数据分离"><a href="#_5-2-异构存储-冷热数据分离" class="header-anchor">#</a> 5.2 异构存储（冷热数据分离）</h2> <p>异构存储主要解决，不同的数据，存储在不同类型的硬盘中，达到最佳性能的问题。</p> <p><img src="/assets/img/image-20230703211657026.9965e28a.png" alt="image-20230703211657026"></p> <p><strong>存储类型和存储策略</strong></p> <p>1）关于存储类型</p> <ul><li>RAM_DISK：（内存镜像文件系统）</li> <li>SSD：（SSD 固态硬盘）</li> <li>DISK：（普通磁盘，在 HDFS 中，如果没有主动声明数据目录存储类型默认都是 DISK）</li> <li>ARCHIVE：（没有特指哪种存储介质，主要的指的是计算能力比较弱而存储密度比较高的存储介质，用来解决数据量的 容量扩增的问题，一般用于归档）</li></ul> <p>2）关于存储策略</p> <p><img src="/assets/img/image-20230703211920535.deb68032.png" alt="image-20230703211920535"></p> <blockquote><p>说明：从 Lazy_Persist 到 Cold，分别代表了设备的访问速度从快到慢</p></blockquote> <h3 id="_5-2-1-异构存储-shell-操作"><a href="#_5-2-1-异构存储-shell-操作" class="header-anchor">#</a> 5.2.1 异构存储 Shell 操作</h3> <p>（1）查看当前有哪些存储策略可以用</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs storagepolicies -listPolicies
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（2）为指定路径（<strong>数据存储目录</strong>）设置指定的存储策略</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hdfs storagepolicies -setStoragePolicy -path xxx -policy xxx
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（3）获取指定路径（数据存储目录或文件）的存储策略</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hdfs storagepolicies -getStoragePolicy -path xxx
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（4）取消存储策略；执行改命令之后该目录或者文件，以其上级的目录为准，如果是根目录，那么就是 HOT</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hdfs storagepolicies -unsetStoragePolicy -path xxx
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（5）查看文件块的分布</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>bin/hdfs fsck xxx -files -blocks -locations
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（6）查看集群节点</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hadoop dfsadmin -report
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h3 id="_5-2-2-测试环境准备"><a href="#_5-2-2-测试环境准备" class="header-anchor">#</a> <strong>5.2.2</strong> <strong>测试环境准备</strong></h3> <ul><li>1）测试环境描述</li></ul> <p>服务器规模：5 台</p> <p>集群配置：副本数为 2，创建好带有存储类型的目录（提前创建）</p> <p>集群规划：</p> <table><thead><tr><th>节点</th> <th>存储类型分配</th></tr></thead> <tbody><tr><td>hadoop102</td> <td>RAM_DISK，SSD</td></tr> <tr><td>hadoop103</td> <td>SSD，DISK</td></tr> <tr><td>hadoop104</td> <td>DISK，RAM_DISK</td></tr> <tr><td>hadoop105</td> <td>ARCHIVE</td></tr> <tr><td>hadoop106</td> <td>ARCHIVE</td></tr></tbody></table> <ul><li><p>2）配置文件信息</p> <p>（1）为 hadoop102 节点的 hdfs-site.xml 添加如下信息</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;property&gt;
	&lt;name&gt;dfs.replication&lt;/name&gt;
	&lt;value&gt;2&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
	&lt;name&gt;dfs.storage.policy.enabled&lt;/name&gt;
	&lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
	&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
	&lt;value&gt;[SSD]file:///opt/module/hadoop-3.1.3/hdfsdata/ssd,[RAM_DISK]file:///opt/module/hadoop-3.1.3/hdfsdata/ram_disk&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>（2）为 hadoop103 节点的 hdfs-site.xml 添加如下信息</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;property&gt;
	&lt;name&gt;dfs.replication&lt;/name&gt;
	&lt;value&gt;2&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
	&lt;name&gt;dfs.storage.policy.enabled&lt;/name&gt;
	&lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
	&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
	&lt;value&gt;[SSD]file:///opt/module/hadoop-3.1.3/hdfsdata/ssd,[DISK]file:///opt/module/hadoop-3.1.3/hdfsdata/disk&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>（3）为 hadoop104 节点的 hdfs-site.xml 添加如下信息</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;property&gt;
	&lt;name&gt;dfs.replication&lt;/name&gt;
	&lt;value&gt;2&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
	&lt;name&gt;dfs.storage.policy.enabled&lt;/name&gt;
	&lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
	&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
	&lt;value&gt;[RAM_DISK]file:///opt/module/hdfsdata/ram_disk,[DISK]file:///opt/module/hadoop-3.1.3/hdfsdata/disk&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>（4）为 hadoop105 节点的 hdfs-site.xml 添加如下信息</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;property&gt;
	&lt;name&gt;dfs.replication&lt;/name&gt;
	&lt;value&gt;2&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
	&lt;name&gt;dfs.storage.policy.enabled&lt;/name&gt;
	&lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
	&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
	&lt;value&gt;[ARCHIVE]file:///opt/module/hadoop-3.1.3/hdfsdata/archive&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>（5）为 hadoop106 节点的 hdfs-site.xml 添加如下信息</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;property&gt;
	&lt;name&gt;dfs.replication&lt;/name&gt;
	&lt;value&gt;2&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
	&lt;name&gt;dfs.storage.policy.enabled&lt;/name&gt;
	&lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
	&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
	&lt;value&gt;[ARCHIVE]file:///opt/module/hadoop-3.1.3/hdfsdata/archive&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div></li> <li><p>3）数据准备</p> <p>（1）启动集群</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs namenode -format
[atguigu@hadoop102 hadoop-3.1.3]$ myhadoop.sh start
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>（1）并在 HDFS 上创建文件目录</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -mkdir /hdfsdata
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（2）并将文件资料上传</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -put /opt/module/hadoop-3.1.3/NOTICE.txt /hdfsdata
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h3 id="_5-2-3-hot-存储策略案例"><a href="#_5-2-3-hot-存储策略案例" class="header-anchor">#</a> 5.2.3 HOT 存储策略案例</h3> <p>（1）最开始我们未设置存储策略的情况下，我们获取该目录的存储策略</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs storagepolicies -getStoragePolicy -path /hdfsdata
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（2）我们查看上传的文件块分布</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs fsck /hdfsdata -files -blocks -locations

[DatanodeInfoWithStorage[192.168.10.104:9866,DS-0b133854-7f9e-48df-939b-5ca6482c5afb,DISK], DatanodeInfoWithStorage[192.168.10.103:9866,DS-ca1bd3b9-d9a5-4101-9f92-3da5f1baa28b,DISK]]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>未设置存储策略，所有文件块都存储在 DISK 下。所以，默认存储策略为 HOT。</p> <h3 id="_5-2-4-warm-存储策略测试"><a href="#_5-2-4-warm-存储策略测试" class="header-anchor">#</a> <strong>5.2.4</strong> <strong>WARM 存储策略测试</strong></h3> <p>（1）接下来我们为数据降温</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs storagepolicies -setStoragePolicy -path /hdfsdata -policy WARM
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（2）再次查看文件块分布，我们可以看到文件块依然放在原处。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs fsck /hdfsdata -files -blocks -locations
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（3）我们需要让他 HDFS 按照存储策略自行移动文件块</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs mover /hdfsdata
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>4）再次查看文件块分布，</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs fsck /hdfsdata -files -blocks -locations

[DatanodeInfoWithStorage[192.168.10.105:9866,DS-d46d08e1-80c6-4fca-b0a2-4a3dd7ec7459,ARCHIVE], DatanodeInfoWithStorage[192.168.10.103:9866,DS-ca1bd3b9-d9a5-4101-9f92-3da5f1baa28b,DISK]]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>文件块一半在 DISK，一半在 ARCHIVE，符合我们设置的 WARM 策略</p></li></ul> <h3 id="_5-2-5-cold-策略测试"><a href="#_5-2-5-cold-策略测试" class="header-anchor">#</a> 5.2.5 COLD 策略测试</h3> <p>（1）我们继续将数据降温为 cold</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs storagepolicies -setStoragePolicy -path /hdfsdata -policy COLD
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><blockquote><p>注意：当我们将目录设置为 COLD 并且我们未配置 ARCHIVE 存储目录的情况下，不可以向该目录直接上传文件，会报出异常。</p></blockquote> <p>（2）手动转移</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>atguigu@hadoop102 hadoop-3.1.3]$ hdfs mover /hdfsdata
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（3）检查文件块的分布</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ bin/hdfs fsck /hdfsdata -files -blocks -locations

[DatanodeInfoWithStorage[192.168.10.105:9866,DS-d46d08e1-80c6-4fca-b0a2-4a3dd7ec7459,ARCHIVE], DatanodeInfoWithStorage[192.168.10.106:9866,DS-827b3f8b-84d7-47c6-8a14-0166096f919d,ARCHIVE]]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>所有文件块都在 ARCHIVE，符合 COLD 存储策略。</p> <h3 id="_5-2-6-one-ssd-策略测试"><a href="#_5-2-6-one-ssd-策略测试" class="header-anchor">#</a> <strong>5.2.6</strong> <strong>ONE_SSD 策略测试</strong></h3> <p>（1）接下来我们将存储策略从默认的 HOT 更改为 One_SSD</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs storagepolicies -setStoragePolicy -path /hdfsdata -policy One_SSD
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（2）手动转移文件块</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs mover /hdfsdata
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（3）转移完成后，我们查看文件块分布，</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ bin/hdfs fsck /hdfsdata -files -blocks -locations



[DatanodeInfoWithStorage[192.168.10.104:9866,DS-0b133854-7f9e-48df-939b-5ca6482c5afb,DISK], DatanodeInfoWithStorage[192.168.10.103:9866,DS-2481a204-59dd-46c0-9f87-ec4647ad429a,SSD]]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>文件块分布为一半在 SSD，一半在 DISK，符合 One_SSD 存储策略。</p> <h3 id="_5-2-7-all-ssd-策略测试"><a href="#_5-2-7-all-ssd-策略测试" class="header-anchor">#</a> <strong>5.2.7</strong> <strong>ALL_SSD 策略测试</strong></h3> <p>（1）接下来，我们再将存储策略更改为 All_SSD</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs storagepolicies -setStoragePolicy -path /hdfsdata -policy All_SSD
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（2）手动转移文件块</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs mover /hdfsdata
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（3）查看文件块分布，我们可以看到，</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ bin/hdfs fsck /hdfsdata -files -blocks -locations



[DatanodeInfoWithStorage[192.168.10.102:9866,DS-c997cfb4-16dc-4e69-a0c4-9411a1b0c1eb,SSD], DatanodeInfoWithStorage[192.168.10.103:9866,DS-2481a204-59dd-46c0-9f87-ec4647ad429a,SSD]]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>所有的文件块都存储在 SSD，符合 All_SSD 存储策略。</p> <h3 id="_5-2-8-lazy-persist-策略测试"><a href="#_5-2-8-lazy-persist-策略测试" class="header-anchor">#</a> <strong>5.2.8</strong> <strong>LAZY_PERSIST 策略测试</strong></h3> <p>（1）继续改变策略，将存储策略改为 lazy_persist</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs storagepolicies -setStoragePolicy -path /hdfsdata -policy lazy_persist
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（2）手动转移文件块</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs mover /hdfsdata
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（3）查看文件块分布</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs fsck /hdfsdata -files -blocks -locations



[DatanodeInfoWithStorage[192.168.10.104:9866,DS-0b133854-7f9e-48df-939b-5ca6482c5afb,DISK], DatanodeInfoWithStorage[192.168.10.103:9866,DS-ca1bd3b9-d9a5-4101-9f92-3da5f1baa28b,DISK]]
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>这里我们发现所有的文件块都是存储在 DISK，按照理论一个副本存储在 RAM_DISK，其他副本存储在 DISK 中，这是因为，我们还需要配置<code>dfs.datanode.max.locked.memory</code>，<code>dfs.block.size</code>参数。</p> <p>那么出现存储策略为<code>LAZY_PERSIST</code>时，文件块副本都存储在 DISK 上的原因有如下两点：</p> <p>（1）当客户端所在的 DataNode 节点没有 RAM_DISK 时，则会写入客户端所在的 DataNode 节点的 DISK 磁盘，其余副本会写入其他节点的 DISK 磁盘。</p> <p>（2）当客户端所在的 DataNode 有 RAM_DISK，但<code>dfs.datanode.max.locked.memory</code>参数值未设置或者设置过小（小于<code>dfs.block.size</code>参数值）时，则会写入客户端所在的 DataNode 节点的 DISK 磁盘，其余副本会写入其他节点的 DISK 磁盘。</p> <p>但是由于虚拟机的<code>max locked memory</code>为 64KB，所以，如果参数配置过大，还会报出错误：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.lang.RuntimeException: Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) of 209715200 bytes is more than the datanode's available RLIMIT_MEMLOCK ulimit of 65536 bytes.
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>我们可以通过该命令查询此参数的内存</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ ulimit -a

max locked memory       (kbytes, -l) 64
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h1 id="第-6-章-hdfs-故障排除"><a href="#第-6-章-hdfs-故障排除" class="header-anchor">#</a> 第 6 章 HDFS—故障排除</h1> <h2 id="_6-1-namenode-故障处理"><a href="#_6-1-namenode-故障处理" class="header-anchor">#</a> 6.1 NameNode 故障处理</h2> <p><img src="/assets/img/image-20230703213641147.e76c51e7.png" alt="image-20230703213641147"></p> <p>1）需求：</p> <p>NameNode 进程挂了并且存储的数据也丢失了，如何恢复 NameNode</p> <p>2）故障模拟</p> <p>（1）kill -9 NameNode 进程</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 current]$ kill -9 19886
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（2）删除 NameNode 存储的数据（/opt/module/hadoop-3.1.3/data/tmp/dfs/name）</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ rm -rf /opt/module/hadoop-3.1.3/data/dfs/name/*
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>3）问题解决</p> <p>（1）拷贝 SecondaryNameNode 中数据到原 NameNode 存储数据目录</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 dfs]$ scp -r atguigu@hadoop104:/opt/module/hadoop-3.1.3/data/dfs/namesecondary/* ./name/
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（2）重新启动 NameNode</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs --daemon start namenode
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（3）向集群上传一个文件 测试</p> <h3 id="_6-2-集群安全模式-磁盘修复"><a href="#_6-2-集群安全模式-磁盘修复" class="header-anchor">#</a> 6.2 集群安全模式&amp;磁盘修复</h3> <p><strong>1）安全模式</strong>：文件系统只接受读数据请求，而不接受删除、修改等变更请求</p> <p><strong>2）进入安全模式场景</strong></p> <ul><li><p>NameNode 在加载镜像文件和编辑日志期间处于安全模式；</p></li> <li><p>NameNode 再接收 DataNode 注册时，处于安全模式</p> <p><img src="/assets/img/image-20230703214010593.194946fd.png" alt="image-20230703214010593"></p></li></ul> <p><strong>3）退出安全模式条件</strong></p> <p><code>dfs.namenode.safemode.min.datanodes</code>: 最小可用 datanode 数量，默认 0</p> <p><code>dfs.namenode.safemode.threshold-pct</code>: 副本数达到最小要求的 block 占系统总 block 数的<strong>百分比</strong>，默认 0.999f。（只允许丢一个块）</p> <p><code>dfs.namenode.safemode.extension</code>:稳定时间，默认值 30000 毫秒，即 30 秒</p> <p><strong>4）基本语法</strong></p> <p>集群处于安全模式，不能执行重要操作（写操作）。集群启动完成后，自动退出安全模式。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>（1）bin/hdfs dfsadmin -safemode get	（功能描述：查看安全模式状态）
（2）bin/hdfs dfsadmin -safemode enter （功能描述：进入安全模式状态）
（3）bin/hdfs dfsadmin -safemode leave	（功能描述：离开安全模式状态）
（4）bin/hdfs dfsadmin -safemode wait	（功能描述：等待安全模式状态）
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p><strong>5）案例 1：启动集群进入安全模式</strong></p> <p>​ （1）重新启动集群</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 subdir0]$ myhadoop.sh stop
[atguigu@hadoop102 subdir0]$ myhadoop.sh start
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>​ （2）集群启动后，立即来到集群上删除数据，提示集群处于安全模式</p> <p><img src="/assets/img/image-20230703214225617.28931488.png" alt="image-20230703214225617"></p> <p><strong>6）案例 2：磁盘修复</strong></p> <p>需求：数据块损坏，进入安全模式，如何处理</p> <p>​ （1）测试-- 分别进入 hadoop102、hadoop103、hadoop104 的<code>/opt/module/hadoop-3.1.3/data/dfs/data/current/BP-1015489500-192.168.10.102-1611909480872/current/finalized/subdir0/subdir0</code>目录，统一删除某 2 个块信息</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 subdir0]$ pwd
/opt/module/hadoop-3.1.3/data/dfs/data/current/BP-1015489500-192.168.10.102-1611909480872/current/finalized/subdir0/subdir0

[atguigu@hadoop102 subdir0]$ rm -rf blk_1073741847 blk_1073741847_1023.meta
[atguigu@hadoop102 subdir0]$ rm -rf blk_1073741865 blk_1073741865_1042.meta
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>说明：hadoop103/hadoop104 重复执行以上命令</p> <p>（2）重新启动集群</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 subdir0]$ myhadoop.sh stop
[atguigu@hadoop102 subdir0]$ myhadoop.sh start
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>（3）观察 http://hadoop102:9870/dfshealth.html#tab-overview</p> <p><img src="/assets/img/image-20230703214406307.0e3fc2fe.png" alt="image-20230703214406307"></p> <p>说明：安全模式已经打开，块的数量没有达到要求。</p> <p>（4）离开安全模式</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 subdir0]$ hdfs dfsadmin -safemode get
Safe mode is ON
[atguigu@hadoop102 subdir0]$ hdfs dfsadmin -safemode leave
Safe mode is OFF
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>（5）观察 http://hadoop102:9870/dfshealth.html#tab-overview</p> <p><img src="/assets/img/image-20230703214432417.ebaebf49.png" alt="image-20230703214432417"></p> <p>（6）将元数据删除</p> <p><img src="/assets/img/image-20230703214443108.e85d24f7.png" alt="image-20230703214443108"></p> <p><img src="/assets/img/image-20230703214449225.ded592fa.png" alt="image-20230703214449225"></p> <p>​ (7）观察<a href="#tab-overview">http://hadoop102:9870/dfshealth.html#tab-overview</a>，集群已经正常</p> <p>7）案例 3：</p> <p>​ 需求：模拟等待安全模式</p> <p><strong>（1）查看当前模式</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs dfsadmin -safemode get

Safe mode is OFF
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p><strong>（2）先进入安全模式</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ bin/hdfs dfsadmin -safemode enter
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><strong>（3）创建并执行下面的脚本</strong></p> <p>在/opt/module/hadoop-3.1.3 路径上，编辑一个脚本 safemode.sh</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ vim safemode.sh

\#!/bin/bash

hdfs dfsadmin -safemode wait

hdfs dfs -put /opt/module/hadoop-3.1.3/README.txt /



[atguigu@hadoop102 hadoop-3.1.3]$ chmod 777 safemode.sh



[atguigu@hadoop102 hadoop-3.1.3]$ ./safemode.sh
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><p><strong>（4）再打开一个窗口，执行</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ bin/hdfs dfsadmin -safemode leave
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><strong>（5）再观察上一个窗口</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>Safe mode is OFF
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><strong>（6）HDFS 集群上已经有上传的数据了</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>![img](../../.vuepress/public/Hadoop/wps1-16883919226401.jpg)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h2 id="_6-3-慢磁盘监控"><a href="#_6-3-慢磁盘监控" class="header-anchor">#</a> 6.3 慢磁盘监控</h2> <p>“慢磁盘”指的时写入数据非常慢的一类磁盘。其实慢性磁盘并不少见，当机器运行时间长了，上面跑的任务多了，磁盘的读写性能自然会退化，严重时就会出现写入数据延时的问题。</p> <p><strong>如何发现慢磁盘？</strong></p> <p>正常在 HDFS 上创建一个目录，只需要不到 1s 的时间。如果你发现创建目录超过 1 分钟及以上，而且这个现象并不是每次都有。只是偶尔慢了一下，就很有可能存在慢磁盘。</p> <p>可以采用如下方法找出是哪块磁盘慢：</p> <p><strong>1）通过心跳未联系时间。</strong></p> <p>一般出现慢磁盘现象，会影响到 DataNode 与 NameNode 之间的心跳。正常情况心跳时间间隔是 3s。超过 3s 说明有异常。</p> <p><img src="/assets/img/image-20230703214853874.7b12c466.png" alt="image-20230703214853874"></p> <p><strong>2）fio 命令，测试磁盘的读写性能</strong></p> <p>（1）顺序读测试</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]# sudo yum install -y fio
[atguigu@hadoop102 ~]# sudo fio -filename=/home/atguigu/test.log -direct=1 -iodepth 1 -thread -rw=read -ioengine=psync -bs=16k -size=2G -numjobs=10 -runtime=60 -group_reporting -name=test_r

Run status group 0 (all jobs):
   READ: bw=360MiB/s (378MB/s), 360MiB/s-360MiB/s (378MB/s-378MB/s), io=20.0GiB (21.5GB), run=56885-56885msec
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>结果显示，磁盘的总体顺序读速度为<strong>360MiB/s</strong>。</p> <p>（2）顺序写测试</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]# sudo fio -filename=/home/atguigu/test.log -direct=1 -iodepth 1 -thread -rw=write -ioengine=psync -bs=16k -size=2G -numjobs=10 -runtime=60 -group_reporting -name=test_w


Run status group 0 (all jobs):
  WRITE: bw=341MiB/s (357MB/s), 341MiB/s-341MiB/s (357MB/s-357MB/s), io=19.0GiB (21.4GB), run=60001-60001msec
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>结果显示，磁盘的总体顺序写速度为<strong>341MiB/s。</strong></p> <p>（3）随机写测试</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]# sudo fio -filename=/home/atguigu/test.log -direct=1 -iodepth 1 -thread -rw=randwrite -ioengine=psync -bs=16k -size=2G -numjobs=10 -runtime=60 -group_reporting -name=test_randw
Run status group 0 (all jobs):
  WRITE: bw=309MiB/s (324MB/s), 309MiB/s-309MiB/s (324MB/s-324MB/s), io=18.1GiB (19.4GB), run=60001-60001msec
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>结果显示，磁盘的总体随机写速度为<strong>309MiB/s</strong>。</p> <p>（4）混合随机读写：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]# sudo fio -filename=/home/atguigu/test.log -direct=1 -iodepth 1 -thread -rw=randrw -rwmixread=70 -ioengine=psync -bs=16k -size=2G -numjobs=10 -runtime=60 -group_reporting -name=test_r_w -ioscheduler=noop

Run status group 0 (all jobs):
   READ: bw=220MiB/s (231MB/s), 220MiB/s-220MiB/s (231MB/s-231MB/s), io=12.9GiB (13.9GB), run=60001-60001msec
  WRITE: bw=94.6MiB/s (99.2MB/s), 94.6MiB/s-94.6MiB/s (99.2MB/s-99.2MB/s), io=5674MiB (5950MB), run=60001-60001msec
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>结果显示，磁盘的总体混合随机读写，读速度为<strong>220MiB/s</strong>，写速度<strong>94.6MiB/s</strong>。</p> <h2 id="_6-4-小文件归档"><a href="#_6-4-小文件归档" class="header-anchor">#</a> <strong>6.4 小文件归档</strong></h2> <p><strong>1）HDFS 存储小文件弊端</strong></p> <p><img src="/assets/img/image-20230703215414610.77ec21ca.png" alt="image-20230703215414610"></p> <p>每个文件均按块存储，每个块的元数据存储在 NameNode 的内存中，因此 HDFS 存储小文件会非常低效。<strong>因为大量的小文件会耗尽 NameNode 中的大部分内存。</strong> 但注意，存储小文件所需要的磁盘容量和数据块的大小无关。例如，一个 1MB 的文件设置为 128MB 的块存储，实际使用的是 1MB 的磁盘空间，而不是 128MB。</p> <p><strong>2）解决存储小文件办法之一</strong></p> <p>HDFS 存档文件或 HAR 文件，是一个更高效的文件存档工具，它将文件存入 HDFS 块，在减少 NameNode 内存使用的同时，允许对文件进行透明的访问。具体说来，HDFS 存档文件对内还是一个一个独立文件，<strong>对 NameNode 而言却是一个整体</strong>，减少了 NameNode 的内存。
<img src="/assets/img/image-20230703215528701.edf2dc2e.png" alt="image-20230703215528701"></p> <p><strong>3）案例实操</strong></p> <p>（1）需要启动 YARN 进程</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ start-yarn.sh
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（2）归档文件</p> <p>把/input 目录里面的所有文件归档成一个叫 input.har 的归档文件，并把归档后文件存储到/output 路径下。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hadoop archive -archiveName input.har -p  /input   /output
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（3）查看归档</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -ls /output/input.har
[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -ls har:///output/input.har
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>（4）解归档文件</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hadoop fs -cp har:///output/input.har/*    /
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h1 id="第-7-章-hdfs-集群迁移"><a href="#第-7-章-hdfs-集群迁移" class="header-anchor">#</a> 第 7 章 HDFS—集群迁移</h1> <h2 id="_7-1-apache-和-apache-集群间数据拷贝"><a href="#_7-1-apache-和-apache-集群间数据拷贝" class="header-anchor">#</a> 7.1 Apache 和 Apache 集群间数据拷贝</h2> <p><strong>1）scp 实现两个远程主机之间的文件复制</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>	scp -r hello.txt root@hadoop103:/user/atguigu/hello.txt		// 推 push
	scp -r root@hadoop103:/user/atguigu/hello.txt  hello.txt		// 拉 pull
	scp -r root@hadoop103:/user/atguigu/hello.txt root@hadoop104:/user/atguigu  是通过本地主机中转实现两个远程主机的文件复制；如果在两个远程主机之间ssh没有配置的情况下可以使用该方式。
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p><strong>2）采用 distcp 命令实现两个 Hadoop 集群之间的递归数据复制</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$  bin/hadoop distcp hdfs://hadoop102:8020/user/atguigu/hello.txt hdfs://hadoop105:8020/user/atguigu/hello.txt
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h2 id="_7-2-apache-和-cdh-集群间数据拷贝"><a href="#_7-2-apache-和-cdh-集群间数据拷贝" class="header-anchor">#</a> 7.2 Apache 和 CDH 集群间数据拷贝</h2> <p>...</p> <h1 id="第-8-章-mapreduce-生产经验"><a href="#第-8-章-mapreduce-生产经验" class="header-anchor">#</a> 第 8 章 MapReduce 生产经验</h1> <h2 id="_8-1-mapreduce-跑的慢的原因"><a href="#_8-1-mapreduce-跑的慢的原因" class="header-anchor">#</a> 8.1 MapReduce 跑的慢的原因</h2> <p>MapReduce 程序效率的瓶颈在于两点：</p> <p><strong>1）计算机性能</strong></p> <p>CPU、内存、磁盘、网络</p> <p><strong>2）I/O 操作优化</strong></p> <p>（1）数据倾斜</p> <p>（2）Map 运行时间太长，导致 Reduce 等待过久</p> <p>（3）小文件过多</p> <h2 id="_8-2-mapreduce-常用调优参数"><a href="#_8-2-mapreduce-常用调优参数" class="header-anchor">#</a> 8.2 MapReduce 常用调优参数</h2> <p><img src="/assets/img/image-20230703220857400.f60baf0f.png" alt="image-20230703220857400"></p> <p><img src="/assets/img/image-20230703221117361.611f45d1.png" alt="image-20230703221117361"></p> <h2 id="_8-3-mapreduce-数据倾斜问题"><a href="#_8-3-mapreduce-数据倾斜问题" class="header-anchor">#</a> 8.3 MapReduce 数据倾斜问题</h2> <p><strong>1）数据倾斜现象</strong></p> <p>数据频率倾斜——某一个区域的数据量要远远大于其他区域。</p> <p>数据大小倾斜——部分记录的大小远远大于平均值。</p> <p><img src="/assets/img/image-20230703221332387.15ee3a1f.png" alt="image-20230703221332387"></p> <p><strong>2）减少数据倾斜的方法</strong></p> <p><strong>（1）首先检查是否空值过多造成的数据倾斜</strong></p> <p>生产环境，可以直接过滤掉空值；如果想保留空值，就自定义分区，将空值加随机数打散。最后再二次聚合。</p> <p><strong>（2）能在 map 阶段提前处理，最好先在 Map 阶段处理。如：Combiner、MapJoin</strong></p> <p><strong>（3）设置多个 reduce 个数</strong></p> <h1 id="第-9-章-hadoop-yarn-生产经验"><a href="#第-9-章-hadoop-yarn-生产经验" class="header-anchor">#</a> 第 9 章 Hadoop-Yarn 生产经验</h1> <h2 id="_9-1-常用的调优参数"><a href="#_9-1-常用的调优参数" class="header-anchor">#</a> 9.1 常用的调优参数</h2> <p>1）调优参数列表</p> <p>（1）Resourcemanager 相关</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>yarn.resourcemanager.scheduler.client.thread-count	ResourceManager处理调度器请求的线程数量
yarn.resourcemanager.scheduler.class	配置调度器
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>（2）Nodemanager 相关</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>yarn.nodemanager.resource.memory-mb	              NodeManager使用内存数
yarn.nodemanager.resource.system-reserved-memory-mb  NodeManager为系统保留多少内存，和上一个参数二者取一即可

yarn.nodemanager.resource.cpu-vcores	NodeManager使用CPU核数
yarn.nodemanager.resource.count-logical-processors-as-cores	是否将虚拟核数当作CPU核数
yarn.nodemanager.resource.pcores-vcores-multiplier	虚拟核数和物理核数乘数，例如：4核8线程，该参数就应设为2
yarn.nodemanager.resource.detect-hardware-capabilities	是否让yarn自己检测硬件进行配置

yarn.nodemanager.pmem-check-enabled	是否开启物理内存检查限制container
yarn.nodemanager.vmem-check-enabled	是否开启虚拟内存检查限制container
yarn.nodemanager.vmem-pmem-ratio        虚拟内存物理内存比例
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p>（3）Container 容器相关</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>yarn.scheduler.minimum-allocation-mb	     容器最小内存
yarn.scheduler.maximum-allocation-mb	     容器最大内存
yarn.scheduler.minimum-allocation-vcores	 容器最小核数
yarn.scheduler.maximum-allocation-vcores	 容器最大核数
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>2）参数具体使用案例</p> <p>详见《大数据技术之 Hadoop（Yarn）》，第 2.1 节。</p> <h2 id="_9-2-容量调度器使用"><a href="#_9-2-容量调度器使用" class="header-anchor">#</a> 9.2 容量调度器使用</h2> <p>详见《大数据技术之 Hadoop（Yarn）》，第 2.2 节。</p> <h2 id="_9-3-公平调度器使用"><a href="#_9-3-公平调度器使用" class="header-anchor">#</a> 9.3 公平调度器使用</h2> <p>详见《尚硅谷大数据技术之 Hadoop（Yarn）》，第 2.3 节。</p> <h2 id="第-10-章-hadoop-综合调优"><a href="#第-10-章-hadoop-综合调优" class="header-anchor">#</a> 第 10 章 Hadoop 综合调优</h2> <h2 id="_10-1-hadoop-小文件优化方法"><a href="#_10-1-hadoop-小文件优化方法" class="header-anchor">#</a> 10.1 Hadoop 小文件优化方法</h2> <h3 id="_10-1-1-hadoop-小文件弊端"><a href="#_10-1-1-hadoop-小文件弊端" class="header-anchor">#</a> 10.1.1 Hadoop 小文件弊端</h3> <p>HDFS 上每个文件都要在 NameNode 上创建对应的元数据，这个元数据的大小约为<strong>150byte</strong>，这样当小文件比较多的时候，就会产生很多的元数据文件，<strong>一方面会大量占用 NameNode 的内存空间，另一方面就是元数据文件过多，使得寻址索引速度变慢。</strong></p> <p>小文件过多，在进行 MR 计算时，会生成过多切片，需要启动过多的 MapTask。每个 MapTask 处理的数据量小，<strong>导致 MapTask 的处理时间比启动时间还小，白白消耗资源。</strong></p> <h3 id="_10-1-2-hadoop-小文件解决方案"><a href="#_10-1-2-hadoop-小文件解决方案" class="header-anchor">#</a> 10.1.2 Hadoop 小文件解决方案</h3> <p><strong>1）在数据采集的时候，就将小文件或小批数据合成大文件再上传 HDFS（数据源头）</strong> <strong>2）Hadoop Archive（存储方向）</strong></p> <p>是一个高效的将小文件放入 HDFS 块中的文件存档工具，能够将多个小文件打包成一个 HAR 文件，从而达到减少 NameNode 的内存使用</p> <p><strong>3）CombineTextInputFormat（计算方向）</strong></p> <p>CombineTextInputFormat 用于将多个小文件在切片过程中生成一个单独的切片或者少量的切片。</p> <p><strong>4）开启 uber 模式，实现 JVM 重用（计算方向）</strong></p> <p>默认情况下，每个 Task 任务都需要启动一个 JVM 来运行，如果 Task 任务计算的数据量很小，我们可以让同一个 Job 的多个 Task 运行在一个 JVM 中，不必为每个 Task 都开启一个 JVM。</p> <p>（1）未开启 uber 模式，在/input 路径上上传多个小文件并执行 wordcount 程序</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output2
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（2）观察控制台</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>2021-02-14 16:13:50,607 INFO mapreduce.Job: Job job_1613281510851_0002 running in uber mode : false
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（3）观察 http://hadoop103:8088/cluster</p> <p><img src="data:image/png;base64,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" alt="image-20230703225208870"><img src="/assets/img/image-20230703225211794.ecf5184b.png" alt="image-20230703225211794"><img src="/assets/img/image-20230703225215277.5f5213ea.png" alt="image-20230703225215277"></p> <p>（4）开启 uber 模式，在 mapred-site.xml 中添加如下配置</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;!--  开启uber模式，默认关闭 --&gt;
&lt;property&gt;
  	&lt;name&gt;mapreduce.job.ubertask.enable&lt;/name&gt;
  	&lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;

&lt;!-- uber模式中最大的mapTask数量，可向下修改  --&gt;
&lt;property&gt;
  	&lt;name&gt;mapreduce.job.ubertask.maxmaps&lt;/name&gt;
  	&lt;value&gt;9&lt;/value&gt;
&lt;/property&gt;
&lt;!-- uber模式中最大的reduce数量，可向下修改 --&gt;
&lt;property&gt;
  	&lt;name&gt;mapreduce.job.ubertask.maxreduces&lt;/name&gt;
  	&lt;value&gt;1&lt;/value&gt;
&lt;/property&gt;
&lt;!-- uber模式中最大的输入数据量，默认使用dfs.blocksize 的值，可向下修改 --&gt;
&lt;property&gt;
  	&lt;name&gt;mapreduce.job.ubertask.maxbytes&lt;/name&gt;
  	&lt;value&gt;&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br></div></div><p>（5）分发配置</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop]$ xsync mapred-site.xml
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（6）再次执行 wordcount 程序</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output2
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>​ （7）观察控制台</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>2021-02-14 16:28:36,198 INFO mapreduce.Job: Job job_1613281510851_0003 running in uber mode : true
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（8）观察 http://hadoop103:8088/cluster</p> <p><img src="/assets/img/image-20230703225335522.f9421bf9.png" alt="image-20230703225335522"></p> <h2 id="_10-2-测试-mapreduce-计算性能"><a href="#_10-2-测试-mapreduce-计算性能" class="header-anchor">#</a> 10.2 测试 MapReduce 计算性能</h2> <p>使用 Sort 程序评测 MapReduce</p> <blockquote><p>注：一个虚拟机不超过 150G 磁盘尽量不要执行这段代码</p></blockquote> <p>（1）使用 RandomWriter 来产生随机数，每个节点运行 10 个 Map 任务，每个 Map 产生大约 1G 大小的二进制随机数</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 mapreduce]$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar randomwriter random-data
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（2）执行 Sort 程序</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 mapreduce]$ hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar sort random-data sorted-data
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（3）验证数据是否真正排好序了</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 mapreduce]$
hadoop jar /opt/module/hadoop-3.1.3/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.3-tests.jar testmapredsort -sortInput random-data -sortOutput sorted-data
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h3 id="_10-3-企业开发场景案例"><a href="#_10-3-企业开发场景案例" class="header-anchor">#</a> 10.3 企业开发场景案例</h3> <h3 id="_10-3-1-需求"><a href="#_10-3-1-需求" class="header-anchor">#</a> 10.3.1 需求</h3> <p>（1）需求：从 1G 数据中，统计每个单词出现次数。服务器 3 台，每台配置 4G 内存，4 核 CPU，4 线程。</p> <p>（2）需求分析：</p> <p>1G / 128m = 8 个 MapTask；1 个 ReduceTask；1 个 mrAppMaster</p> <p>平均每个节点运行 10 个 / 3 台 ≈ 3 个任务（4 3 3）</p> <h3 id="_10-3-2-hdfs-参数调优"><a href="#_10-3-2-hdfs-参数调优" class="header-anchor">#</a> 10.3.2 HDFS 参数调优</h3> <p>（1）修改：hadoop-env.sh</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>export HDFS_NAMENODE_OPTS=&quot;-Dhadoop.security.logger=INFO,RFAS -Xmx1024m&quot;

export HDFS_DATANODE_OPTS=&quot;-Dhadoop.security.logger=ERROR,RFAS -Xmx1024m&quot;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>（2）修改 hdfs-site.xml</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;!-- NameNode有一个工作线程池，默认值是10 有公式的在上面--&gt;
&lt;property&gt;
    &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt;
    &lt;value&gt;21&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>（3）修改 core-site.xml</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;!-- 配置垃圾回收时间为60分钟 --&gt;
&lt;property&gt;
    &lt;name&gt;fs.trash.interval&lt;/name&gt;
    &lt;value&gt;60&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>（4）分发配置</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop]$ xsync hadoop-env.sh hdfs-site.xml core-site.xml
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><strong>10.3.3 MapReduce 参数调优</strong></p> <p>（1）修改 mapred-site.xml</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;!-- 环形缓冲区大小，默认100m --&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.task.io.sort.mb&lt;/name&gt;
  &lt;value&gt;100&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 环形缓冲区溢写阈值，默认0.8 --&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.map.sort.spill.percent&lt;/name&gt;
  &lt;value&gt;0.80&lt;/value&gt;
&lt;/property&gt;

&lt;!-- merge合并次数，默认10个 --&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.task.io.sort.factor&lt;/name&gt;
  &lt;value&gt;10&lt;/value&gt;
&lt;/property&gt;

&lt;!-- maptask内存，默认1g； maptask堆内存大小默认和该值大小一致mapreduce.map.java.opts --&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.map.memory.mb&lt;/name&gt;
  &lt;value&gt;-1&lt;/value&gt;
  &lt;description&gt;The amount of memory to request from the scheduler for each    map task. If this is not specified or is non-positive, it is inferred from mapreduce.map.java.opts and mapreduce.job.heap.memory-mb.ratio. If java-opts are also not specified, we set it to 1024.
  &lt;/description&gt;
&lt;/property&gt;

&lt;!-- matask的CPU核数，默认1个 --&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.map.cpu.vcores&lt;/name&gt;
  &lt;value&gt;1&lt;/value&gt;
&lt;/property&gt;

&lt;!-- matask异常重试次数，默认4次 --&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.map.maxattempts&lt;/name&gt;
  &lt;value&gt;4&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 每个Reduce去Map中拉取数据的并行数。默认值是5 --&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.reduce.shuffle.parallelcopies&lt;/name&gt;
  &lt;value&gt;5&lt;/value&gt;
&lt;/property&gt;

&lt;!-- Buffer大小占Reduce可用内存的比例，默认值0.7 --&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.reduce.shuffle.input.buffer.percent&lt;/name&gt;
  &lt;value&gt;0.70&lt;/value&gt;
&lt;/property&gt;

&lt;!-- Buffer中的数据达到多少比例开始写入磁盘，默认值0.66。 --&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.reduce.shuffle.merge.percent&lt;/name&gt;
  &lt;value&gt;0.66&lt;/value&gt;
&lt;/property&gt;

&lt;!-- reducetask内存，默认1g；reducetask堆内存大小默认和该值大小一致mapreduce.reduce.java.opts --&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.reduce.memory.mb&lt;/name&gt;
  &lt;value&gt;-1&lt;/value&gt;
  &lt;description&gt;The amount of memory to request from the scheduler for each    reduce task. If this is not specified or is non-positive, it is inferred
    from mapreduce.reduce.java.opts and mapreduce.job.heap.memory-mb.ratio.
    If java-opts are also not specified, we set it to 1024.
  &lt;/description&gt;
&lt;/property&gt;

&lt;!-- reducetask的CPU核数，默认1个 --&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.reduce.cpu.vcores&lt;/name&gt;
  &lt;value&gt;2&lt;/value&gt;
&lt;/property&gt;

&lt;!-- reducetask失败重试次数，默认4次 --&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.reduce.maxattempts&lt;/name&gt;
  &lt;value&gt;4&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 当MapTask完成的比例达到该值后才会为ReduceTask申请资源。默认是0.05 --&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.job.reduce.slowstart.completedmaps&lt;/name&gt;
  &lt;value&gt;0.05&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 如果程序在规定的默认10分钟内没有读到数据，将强制超时退出 --&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.task.timeout&lt;/name&gt;
  &lt;value&gt;600000&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br><span class="line-number">83</span><br><span class="line-number">84</span><br><span class="line-number">85</span><br><span class="line-number">86</span><br><span class="line-number">87</span><br><span class="line-number">88</span><br><span class="line-number">89</span><br></div></div><p>（2）分发配置</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop]$ xsync mapred-site.xml
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h3 id="_10-3-4-yarn-参数调优"><a href="#_10-3-4-yarn-参数调优" class="header-anchor">#</a> 10.3.4 Yarn 参数调优</h3> <p>（1）修改 yarn-site.xml 配置参数如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;!-- 选择调度器，默认容量 --&gt;
&lt;property&gt;
	&lt;description&gt;The class to use as the resource scheduler.&lt;/description&gt;
	&lt;name&gt;yarn.resourcemanager.scheduler.class&lt;/name&gt;
	&lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler&lt;/value&gt;
&lt;/property&gt;

&lt;!-- ResourceManager处理调度器请求的线程数量,默认50；如果提交的任务数大于50，可以增加该值，但是不能超过3台 * 4线程 = 12线程（去除其他应用程序实际不能超过8） --&gt;
&lt;property&gt;
	&lt;description&gt;Number of threads to handle scheduler interface.&lt;/description&gt;
	&lt;name&gt;yarn.resourcemanager.scheduler.client.thread-count&lt;/name&gt;
	&lt;value&gt;8&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 是否让yarn自动检测硬件进行配置，默认是false，如果该节点有很多其他应用程序，建议手动配置。如果该节点没有其他应用程序，可以采用自动 --&gt;
&lt;property&gt;
	&lt;description&gt;Enable auto-detection of node capabilities such as
	memory and CPU.
	&lt;/description&gt;
	&lt;name&gt;yarn.nodemanager.resource.detect-hardware-capabilities&lt;/name&gt;
	&lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 是否将虚拟核数当作CPU核数，默认是false，采用物理CPU核数 --&gt;
&lt;property&gt;
	&lt;description&gt;Flag to determine if logical processors(such as
	hyperthreads) should be counted as cores. Only applicable on Linux
	when yarn.nodemanager.resource.cpu-vcores is set to -1 and
	yarn.nodemanager.resource.detect-hardware-capabilities is true.
	&lt;/description&gt;
	&lt;name&gt;yarn.nodemanager.resource.count-logical-processors-as-cores&lt;/name&gt;
	&lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 虚拟核数和物理核数乘数，默认是1.0 --&gt;
&lt;property&gt;
	&lt;description&gt;Multiplier to determine how to convert phyiscal cores to
	vcores. This value is used if yarn.nodemanager.resource.cpu-vcores
	is set to -1(which implies auto-calculate vcores) and
	yarn.nodemanager.resource.detect-hardware-capabilities is set to true. The	number of vcores will be calculated as	number of CPUs * multiplier.
	&lt;/description&gt;
	&lt;name&gt;yarn.nodemanager.resource.pcores-vcores-multiplier&lt;/name&gt;
	&lt;value&gt;1.0&lt;/value&gt;
&lt;/property&gt;

&lt;!-- NodeManager使用内存数，默认8G，修改为4G内存 --&gt;
&lt;property&gt;
	&lt;description&gt;Amount of physical memory, in MB, that can be allocated
	for containers. If set to -1 and
	yarn.nodemanager.resource.detect-hardware-capabilities is true, it is
	automatically calculated(in case of Windows and Linux).
	In other cases, the default is 8192MB.
	&lt;/description&gt;
	&lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;
	&lt;value&gt;4096&lt;/value&gt;
&lt;/property&gt;

&lt;!-- nodemanager的CPU核数，不按照硬件环境自动设定时默认是8个，修改为4个 --&gt;
&lt;property&gt;
	&lt;description&gt;Number of vcores that can be allocated
	for containers. This is used by the RM scheduler when allocating
	resources for containers. This is not used to limit the number of
	CPUs used by YARN containers. If it is set to -1 and
	yarn.nodemanager.resource.detect-hardware-capabilities is true, it is
	automatically determined from the hardware in case of Windows and Linux.
	In other cases, number of vcores is 8 by default.&lt;/description&gt;
	&lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;
	&lt;value&gt;4&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 容器最小内存，默认1G --&gt;
&lt;property&gt;
	&lt;description&gt;The minimum allocation for every container request at the RM	in MBs. Memory requests lower than this will be set to the value of this	property. Additionally, a node manager that is configured to have less memory	than this value will be shut down by the resource manager.
	&lt;/description&gt;
	&lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt;
	&lt;value&gt;1024&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 容器最大内存，默认8G，修改为2G --&gt;
&lt;property&gt;
	&lt;description&gt;The maximum allocation for every container request at the RM	in MBs. Memory requests higher than this will throw an	InvalidResourceRequestException.
	&lt;/description&gt;
	&lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt;
	&lt;value&gt;2048&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 容器最小CPU核数，默认1个 --&gt;
&lt;property&gt;
	&lt;description&gt;The minimum allocation for every container request at the RM	in terms of virtual CPU cores. Requests lower than this will be set to the	value of this property. Additionally, a node manager that is configured to	have fewer virtual cores than this value will be shut down by the resource	manager.
	&lt;/description&gt;
	&lt;name&gt;yarn.scheduler.minimum-allocation-vcores&lt;/name&gt;
	&lt;value&gt;1&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 容器最大CPU核数，默认4个，修改为2个 --&gt;
&lt;property&gt;
	&lt;description&gt;The maximum allocation for every container request at the RM	in terms of virtual CPU cores. Requests higher than this will throw an
	InvalidResourceRequestException.&lt;/description&gt;
	&lt;name&gt;yarn.scheduler.maximum-allocation-vcores&lt;/name&gt;
	&lt;value&gt;2&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 虚拟内存检查，默认打开，修改为关闭 --&gt;
&lt;property&gt;
	&lt;description&gt;Whether virtual memory limits will be enforced for
	containers.&lt;/description&gt;
	&lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;
	&lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 虚拟内存和物理内存设置比例,默认2.1 --&gt;
&lt;property&gt;
	&lt;description&gt;Ratio between virtual memory to physical memory when	setting memory limits for containers. Container allocations are	expressed in terms of physical memory, and virtual memory usage	is allowed to exceed this allocation by this ratio.
	&lt;/description&gt;
	&lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt;
	&lt;value&gt;2.1&lt;/value&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br><span class="line-number">83</span><br><span class="line-number">84</span><br><span class="line-number">85</span><br><span class="line-number">86</span><br><span class="line-number">87</span><br><span class="line-number">88</span><br><span class="line-number">89</span><br><span class="line-number">90</span><br><span class="line-number">91</span><br><span class="line-number">92</span><br><span class="line-number">93</span><br><span class="line-number">94</span><br><span class="line-number">95</span><br><span class="line-number">96</span><br><span class="line-number">97</span><br><span class="line-number">98</span><br><span class="line-number">99</span><br><span class="line-number">100</span><br><span class="line-number">101</span><br><span class="line-number">102</span><br><span class="line-number">103</span><br><span class="line-number">104</span><br><span class="line-number">105</span><br><span class="line-number">106</span><br><span class="line-number">107</span><br><span class="line-number">108</span><br><span class="line-number">109</span><br><span class="line-number">110</span><br><span class="line-number">111</span><br><span class="line-number">112</span><br><span class="line-number">113</span><br><span class="line-number">114</span><br><span class="line-number">115</span><br><span class="line-number">116</span><br></div></div><p>（2）分发配置</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop]$ xsync yarn-site.xml
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h3 id="_10-3-5-执行程序"><a href="#_10-3-5-执行程序" class="header-anchor">#</a> 10.3.5 执行程序</h3> <p>（1）重启集群</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ sbin/stop-yarn.sh
[atguigu@hadoop103 hadoop-3.1.3]$ sbin/start-yarn.sh
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>（2）执行 WordCount 程序</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（3）观察 Yarn 任务执行页面</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>http://hadoop103:8088/cluster/apps
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></div></div>  <div class="page-edit"><div class="edit-link"><a href="https://github.com/andanyang/vuepress-theme-vdoing/edit/master/docs/大数据/001.Hadoop/0008.Hadoop（生产调优手册）.md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2024/03/11, 02:40:47</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/Hadoop/Yarn/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">第七章大数据技术之 Hadoop（Yarn）</div></a> <a href="/Hadoop/HA/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">Hadoop HA 高可用</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/Hadoop/Yarn/" class="prev">第七章大数据技术之 Hadoop（Yarn）</a></span> <span class="next"><a href="/Hadoop/HA/">Hadoop HA 高可用</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/bigdata/spark/SparkStreaming_Driver_Executer/"><div>
            spark中代码的执行位置（Driver or Executer）
            <!----></div></a> <span class="date">12-12</span></dt></dl><dl><dd>02</dd> <dt><a href="/bigdata/spark/SparkStreaming/"><div>
            大数据技术之 SparkStreaming
            <!----></div></a> <span class="date">12-12</span></dt></dl><dl><dd>03</dd> <dt><a href="/bigdata/spark/sql/"><div>
            Spark 核心编程之 RDD 累加器与广播变量
            <!----></div></a> <span class="date">12-06</span></dt></dl> <dl><dd></dd> <dt><a href="/archives/" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="mailto:1218853253@qq.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/andanyang" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="https://music.163.com/#/playlist?id=755597173" title="听音乐" target="_blank" class="iconfont icon-erji"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2019-2024
    <span>Young | <a href="https://github.com/andanyoung/young-blog/blob/master/LICENSE" target="_blank">MIT License</a> <br/> <a  href="https://beian.miit.gov.cn/" target="_blank">浙ICP备20002744号</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><div></div></div></div>
    <script src="/assets/js/app.e4caa6db.js" defer></script><script src="/assets/js/2.d1be14c5.js" defer></script><script src="/assets/js/3.4f4335cf.js" defer></script>
  </body>
</html>
