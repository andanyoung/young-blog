<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>第三章Hadoop 运行环境搭建 | Young&#39;s blog</title>
    <meta name="generator" content="VuePress 1.9.5">
    <link rel="icon" href="/img/favicon.ico">
    <meta name="description" content="Young丶java后端技术博客,专注后端学习与总结。擅长spring boot,JAVA基础总结,等方面的知识,关注spring,架构,elasticsearch,mysql领域.">
    <meta name="keywords" content="前端博客,个人技术博客,前端,前端开发,前端框架,web前端,前端面试题,技术文档,学习,面试,JavaScript,js,ES6,TypeScript,vue,python,css3,html5,Node,git,github,markdown">
    <meta name="baidu-site-verification" content="7F55weZDDc">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/assets/css/0.styles.d9c8cf8c.css" as="style"><link rel="preload" href="/assets/js/app.6558865c.js" as="script"><link rel="preload" href="/assets/js/2.583df165.js" as="script"><link rel="preload" href="/assets/js/19.64474d57.js" as="script"><link rel="prefetch" href="/assets/js/10.5e061793.js"><link rel="prefetch" href="/assets/js/100.f158fbbd.js"><link rel="prefetch" href="/assets/js/101.97f7473e.js"><link rel="prefetch" href="/assets/js/102.eb5ae778.js"><link rel="prefetch" href="/assets/js/103.6700fe38.js"><link rel="prefetch" href="/assets/js/104.cf4e477a.js"><link rel="prefetch" href="/assets/js/105.d64538f4.js"><link rel="prefetch" href="/assets/js/106.cf32e7c7.js"><link rel="prefetch" href="/assets/js/107.227af51d.js"><link rel="prefetch" href="/assets/js/108.930ed4f6.js"><link rel="prefetch" href="/assets/js/109.bc3d1a91.js"><link rel="prefetch" href="/assets/js/11.c260de17.js"><link rel="prefetch" href="/assets/js/110.e467adf9.js"><link rel="prefetch" href="/assets/js/111.cb6c54db.js"><link rel="prefetch" href="/assets/js/112.8d38ba40.js"><link rel="prefetch" href="/assets/js/113.47b60d34.js"><link rel="prefetch" href="/assets/js/114.53420071.js"><link rel="prefetch" href="/assets/js/115.858785eb.js"><link rel="prefetch" href="/assets/js/116.95ada16c.js"><link rel="prefetch" href="/assets/js/117.e5f521ed.js"><link rel="prefetch" href="/assets/js/118.814720b9.js"><link rel="prefetch" href="/assets/js/119.c5c90afc.js"><link rel="prefetch" href="/assets/js/12.db817585.js"><link rel="prefetch" href="/assets/js/120.60b49c87.js"><link rel="prefetch" href="/assets/js/121.a616e563.js"><link rel="prefetch" href="/assets/js/122.c69a4ebd.js"><link rel="prefetch" href="/assets/js/123.9edd985e.js"><link rel="prefetch" href="/assets/js/124.401bfd54.js"><link rel="prefetch" href="/assets/js/125.d4d0a42b.js"><link rel="prefetch" href="/assets/js/126.d46bfdc5.js"><link rel="prefetch" href="/assets/js/127.b3a21be0.js"><link rel="prefetch" href="/assets/js/128.2722ab0b.js"><link rel="prefetch" href="/assets/js/13.fd3eb24c.js"><link rel="prefetch" href="/assets/js/14.695f7d95.js"><link rel="prefetch" href="/assets/js/15.55fde81d.js"><link rel="prefetch" href="/assets/js/16.7cdc1294.js"><link rel="prefetch" href="/assets/js/17.b6cc527c.js"><link rel="prefetch" href="/assets/js/18.512015df.js"><link rel="prefetch" href="/assets/js/20.1dd97260.js"><link rel="prefetch" href="/assets/js/21.7e691bea.js"><link rel="prefetch" href="/assets/js/22.32e9141c.js"><link rel="prefetch" href="/assets/js/23.63138d3b.js"><link rel="prefetch" href="/assets/js/24.e584cd4d.js"><link rel="prefetch" href="/assets/js/25.6fc3eeb0.js"><link rel="prefetch" href="/assets/js/26.0f22e48b.js"><link rel="prefetch" href="/assets/js/27.4fdc574f.js"><link rel="prefetch" href="/assets/js/28.c2b43481.js"><link rel="prefetch" href="/assets/js/29.1a8f640c.js"><link rel="prefetch" href="/assets/js/3.8b355a30.js"><link rel="prefetch" href="/assets/js/30.6eb69c64.js"><link rel="prefetch" href="/assets/js/31.201c1c59.js"><link rel="prefetch" href="/assets/js/32.b99b5337.js"><link rel="prefetch" href="/assets/js/33.58185a6a.js"><link rel="prefetch" href="/assets/js/34.19832557.js"><link rel="prefetch" href="/assets/js/35.17ba6cf1.js"><link rel="prefetch" href="/assets/js/36.134ec142.js"><link rel="prefetch" href="/assets/js/37.ce010d5a.js"><link rel="prefetch" href="/assets/js/38.67d66d12.js"><link rel="prefetch" href="/assets/js/39.43556e25.js"><link rel="prefetch" href="/assets/js/4.b3bee27c.js"><link rel="prefetch" href="/assets/js/40.fab7741a.js"><link rel="prefetch" href="/assets/js/41.9bab045a.js"><link rel="prefetch" href="/assets/js/42.5fdd9c6d.js"><link rel="prefetch" href="/assets/js/43.869cecd0.js"><link rel="prefetch" href="/assets/js/44.cbb6a48f.js"><link rel="prefetch" href="/assets/js/45.f59e42d1.js"><link rel="prefetch" href="/assets/js/46.0ea023ce.js"><link rel="prefetch" href="/assets/js/47.c3f2a821.js"><link rel="prefetch" href="/assets/js/48.4fe9f8fc.js"><link rel="prefetch" href="/assets/js/49.1b8014ec.js"><link rel="prefetch" href="/assets/js/5.7d22774e.js"><link rel="prefetch" href="/assets/js/50.4c446bce.js"><link rel="prefetch" href="/assets/js/51.f4e67f87.js"><link rel="prefetch" href="/assets/js/52.8f8faeb9.js"><link rel="prefetch" href="/assets/js/53.6bef61bb.js"><link rel="prefetch" href="/assets/js/54.c5d847f2.js"><link rel="prefetch" href="/assets/js/55.3ad61741.js"><link rel="prefetch" href="/assets/js/56.33ec1024.js"><link rel="prefetch" href="/assets/js/57.270bfb0e.js"><link rel="prefetch" href="/assets/js/58.11f84f55.js"><link rel="prefetch" href="/assets/js/59.fc7519d9.js"><link rel="prefetch" href="/assets/js/6.16ec3428.js"><link rel="prefetch" href="/assets/js/60.963f9cec.js"><link rel="prefetch" href="/assets/js/61.18e798f5.js"><link rel="prefetch" href="/assets/js/62.0acfdc73.js"><link rel="prefetch" href="/assets/js/63.59232fb7.js"><link rel="prefetch" href="/assets/js/64.e6186e20.js"><link rel="prefetch" href="/assets/js/65.d51e01c7.js"><link rel="prefetch" href="/assets/js/66.35d4ace5.js"><link rel="prefetch" href="/assets/js/67.d5d2490c.js"><link rel="prefetch" href="/assets/js/68.485caaa6.js"><link rel="prefetch" href="/assets/js/69.d527a11e.js"><link rel="prefetch" href="/assets/js/7.c078098e.js"><link rel="prefetch" href="/assets/js/70.e41bae47.js"><link rel="prefetch" href="/assets/js/71.3c4ae398.js"><link rel="prefetch" href="/assets/js/72.7dc219ab.js"><link rel="prefetch" href="/assets/js/73.88c80541.js"><link rel="prefetch" href="/assets/js/74.785a3b81.js"><link rel="prefetch" href="/assets/js/75.7a427044.js"><link rel="prefetch" href="/assets/js/76.d1b62bd2.js"><link rel="prefetch" href="/assets/js/77.a7a1cf37.js"><link rel="prefetch" href="/assets/js/78.00d15d87.js"><link rel="prefetch" href="/assets/js/79.c3a3a87f.js"><link rel="prefetch" href="/assets/js/8.525fd03f.js"><link rel="prefetch" href="/assets/js/80.6f7b688a.js"><link rel="prefetch" href="/assets/js/81.d389ade2.js"><link rel="prefetch" href="/assets/js/82.5a09265a.js"><link rel="prefetch" href="/assets/js/83.af881e6d.js"><link rel="prefetch" href="/assets/js/84.c50064da.js"><link rel="prefetch" href="/assets/js/85.58ae344c.js"><link rel="prefetch" href="/assets/js/86.3c880b88.js"><link rel="prefetch" href="/assets/js/87.ec9a9605.js"><link rel="prefetch" href="/assets/js/88.25a9f5e9.js"><link rel="prefetch" href="/assets/js/89.44bf0353.js"><link rel="prefetch" href="/assets/js/9.4293706c.js"><link rel="prefetch" href="/assets/js/90.146147c7.js"><link rel="prefetch" href="/assets/js/91.a8ad3ccc.js"><link rel="prefetch" href="/assets/js/92.f6870269.js"><link rel="prefetch" href="/assets/js/93.60d7826f.js"><link rel="prefetch" href="/assets/js/94.0127ed63.js"><link rel="prefetch" href="/assets/js/95.75f3c35f.js"><link rel="prefetch" href="/assets/js/96.708eeac4.js"><link rel="prefetch" href="/assets/js/97.648108b1.js"><link rel="prefetch" href="/assets/js/98.a5ea4ebc.js"><link rel="prefetch" href="/assets/js/99.1df8fb3e.js">
    <link rel="stylesheet" href="/assets/css/0.styles.d9c8cf8c.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/img/logo.png" alt="Young's blog" class="logo"> <span class="site-name can-hide">Young's blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/Spring/" class="nav-link">Spring</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="前端" class="dropdown-title"><a href="/web/" class="link-title">前端</a> <span class="title" style="display:none;">前端</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>前端文章1</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/8143cc480faf9a11/" class="nav-link">JavaScript</a></li></ul></li><li class="dropdown-item"><h4>学习笔记</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/note/javascript/" class="nav-link">《JavaScript教程》</a></li><li class="dropdown-subitem"><a href="/note/js/" class="nav-link">《JavaScript高级程序设计》</a></li><li class="dropdown-subitem"><a href="/note/es6/" class="nav-link">《ES6 教程》</a></li><li class="dropdown-subitem"><a href="/note/vue/" class="nav-link">《Vue》</a></li><li class="dropdown-subitem"><a href="/note/react/" class="nav-link">《React》</a></li><li class="dropdown-subitem"><a href="/note/typescript-axios/" class="nav-link">《TypeScript 从零实现 axios》</a></li><li class="dropdown-subitem"><a href="/note/git/" class="nav-link">《Git》</a></li><li class="dropdown-subitem"><a href="/pages/51afd6/" class="nav-link">TypeScript</a></li><li class="dropdown-subitem"><a href="/pages/4643cd/" class="nav-link">JS设计模式总结</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="页面" class="dropdown-title"><a href="/ui/" class="link-title">页面</a> <span class="title" style="display:none;">页面</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/8309a5b876fc95e3/" class="nav-link">HTML</a></li><li class="dropdown-item"><!----> <a href="/pages/0a83b083bdf257cb/" class="nav-link">CSS</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="技术" class="dropdown-title"><a href="/technology/" class="link-title">技术</a> <span class="title" style="display:none;">技术</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/9a7ee40fc232253e/" class="nav-link">技术文档</a></li><li class="dropdown-item"><!----> <a href="/pages/4c778760be26d8b3/" class="nav-link">GitHub技巧</a></li><li class="dropdown-item"><!----> <a href="/pages/117708e0af7f0bd9/" class="nav-link">Nodejs</a></li><li class="dropdown-item"><!----> <a href="/pages/41f87d890d0a02af/" class="nav-link">博客搭建</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="更多" class="dropdown-title"><a href="/more/" class="link-title">更多</a> <span class="title" style="display:none;">更多</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/f2a556/" class="nav-link">学习</a></li><li class="dropdown-item"><!----> <a href="/pages/aea6571b7a8bae86/" class="nav-link">面试</a></li><li class="dropdown-item"><!----> <a href="/pages/2d615df9a36a98ed/" class="nav-link">心情杂货</a></li><li class="dropdown-item"><!----> <a href="/pages/baaa02/" class="nav-link">实用技巧</a></li><li class="dropdown-item"><!----> <a href="/friends/" class="nav-link">友情链接</a></li></ul></div></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><a href="/pages/beb6c0bd8a66cea6/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/andanyang/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="/img/logo.png"> <div class="blogger-info"><h3>Young</h3> <span></span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/Spring/" class="nav-link">Spring</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="前端" class="dropdown-title"><a href="/web/" class="link-title">前端</a> <span class="title" style="display:none;">前端</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>前端文章1</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/8143cc480faf9a11/" class="nav-link">JavaScript</a></li></ul></li><li class="dropdown-item"><h4>学习笔记</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/note/javascript/" class="nav-link">《JavaScript教程》</a></li><li class="dropdown-subitem"><a href="/note/js/" class="nav-link">《JavaScript高级程序设计》</a></li><li class="dropdown-subitem"><a href="/note/es6/" class="nav-link">《ES6 教程》</a></li><li class="dropdown-subitem"><a href="/note/vue/" class="nav-link">《Vue》</a></li><li class="dropdown-subitem"><a href="/note/react/" class="nav-link">《React》</a></li><li class="dropdown-subitem"><a href="/note/typescript-axios/" class="nav-link">《TypeScript 从零实现 axios》</a></li><li class="dropdown-subitem"><a href="/note/git/" class="nav-link">《Git》</a></li><li class="dropdown-subitem"><a href="/pages/51afd6/" class="nav-link">TypeScript</a></li><li class="dropdown-subitem"><a href="/pages/4643cd/" class="nav-link">JS设计模式总结</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="页面" class="dropdown-title"><a href="/ui/" class="link-title">页面</a> <span class="title" style="display:none;">页面</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/8309a5b876fc95e3/" class="nav-link">HTML</a></li><li class="dropdown-item"><!----> <a href="/pages/0a83b083bdf257cb/" class="nav-link">CSS</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="技术" class="dropdown-title"><a href="/technology/" class="link-title">技术</a> <span class="title" style="display:none;">技术</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/9a7ee40fc232253e/" class="nav-link">技术文档</a></li><li class="dropdown-item"><!----> <a href="/pages/4c778760be26d8b3/" class="nav-link">GitHub技巧</a></li><li class="dropdown-item"><!----> <a href="/pages/117708e0af7f0bd9/" class="nav-link">Nodejs</a></li><li class="dropdown-item"><!----> <a href="/pages/41f87d890d0a02af/" class="nav-link">博客搭建</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="更多" class="dropdown-title"><a href="/more/" class="link-title">更多</a> <span class="title" style="display:none;">更多</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/f2a556/" class="nav-link">学习</a></li><li class="dropdown-item"><!----> <a href="/pages/aea6571b7a8bae86/" class="nav-link">面试</a></li><li class="dropdown-item"><!----> <a href="/pages/2d615df9a36a98ed/" class="nav-link">心情杂货</a></li><li class="dropdown-item"><!----> <a href="/pages/baaa02/" class="nav-link">实用技巧</a></li><li class="dropdown-item"><!----> <a href="/friends/" class="nav-link">友情链接</a></li></ul></div></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><a href="/pages/beb6c0bd8a66cea6/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/andanyang/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><a href="/pages/bigdata-generality/" class="sidebar-link">第一章 大数据技术之大数据概论</a></li><li><a href="/pages/Hadoop-Concept-explanation/" class="sidebar-link">第二章大数据技术之 Hadoop概念讲解</a></li><li><a href="/Hadoop/Build-Hadoop-running-environment/" aria-current="page" class="active sidebar-link">第三章Hadoop 运行环境搭建</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/Hadoop/Build-Hadoop-running-environment/#_2-1-利用模板机-hadoop100-克隆三台虚拟机-hadoop102-hadoop103-hadoop104" class="sidebar-link">2.1 利用模板机 hadoop100，克隆三台虚拟机：hadoop102 hadoop103 hadoop104</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Build-Hadoop-running-environment/#_2-2-修改克隆机-ip-以下以-hadoop102-举例说明" class="sidebar-link">2.2 修改克隆机 IP，以下以 hadoop102 举例说明</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Build-Hadoop-running-environment/#_2-3-修改克隆机主机名-以下以-hadoop102-举例说明" class="sidebar-link">2.3 修改克隆机主机名，以下以 hadoop102 举例说明</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Build-Hadoop-running-environment/#_1-4-重启克隆机-hadoop102" class="sidebar-link">1.4 重启克隆机 hadoop102</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Build-Hadoop-running-environment/#_6-1-本地运行模式-官方-wordcount" class="sidebar-link">6.1 本地运行模式（官方 WordCount）</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/Build-Hadoop-running-environment/#_6-2-完全分布式运行模式-开发重点" class="sidebar-link">6.2 完全分布式运行模式（开发重点）</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/Hadoop/Build-Hadoop-running-environment/#_6-2-1-虚拟机准备" class="sidebar-link">6.2.1 虚拟机准备</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Build-Hadoop-running-environment/#_6-2-2-编写集群分发脚本-xsync" class="sidebar-link">6.2.2 编写集群分发脚本 xsync</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_1-scp-secure-copy-安全拷贝" class="sidebar-link">1）scp（secure copy）安全拷贝</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_2-rsync-远程同步工具" class="sidebar-link">2）rsync 远程同步工具</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_3-xsync-集群分发脚本" class="sidebar-link">3）xsync 集群分发脚本</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Build-Hadoop-running-environment/#_6-2-3-ssh-无密登录配置" class="sidebar-link">6.2.3 SSH 无密登录配置</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_1-配置-ssh" class="sidebar-link">1）配置 ssh</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_2-无密钥配置" class="sidebar-link">2）无密钥配置</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_3-ssh-文件夹下-ssh-的文件功能解释" class="sidebar-link">3）.ssh 文件夹下（~/.ssh）的文件功能解释</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Build-Hadoop-running-environment/#_6-2-4-集群配置" class="sidebar-link">6.2.4 集群配置</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_1-集群部署规划" class="sidebar-link">1） 集群部署规划</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_2-配置文件说明" class="sidebar-link">2）配置文件说明</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_3-配置集群" class="sidebar-link">3）配置集群</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_4-在集群上分发配置好的-hadoop-配置文件" class="sidebar-link">4）在集群上分发配置好的 Hadoop 配置文件</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_5-去-103-和-104-上查看文件分发情况" class="sidebar-link">5）去 103 和 104 上查看文件分发情况</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_6-2-5-群起集群" class="sidebar-link">6.2.5 群起集群</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_1-配置-workers" class="sidebar-link">1）配置 workers</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_2-启动集群" class="sidebar-link">2）启动集群</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_3-集群基本测试" class="sidebar-link">3）集群基本测试</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Build-Hadoop-running-environment/#_6-2-6-配置历史服务器" class="sidebar-link">6.2.6 配置历史服务器</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Build-Hadoop-running-environment/#_1-配置-mapred-site-xml" class="sidebar-link">1）配置 mapred-site.xml</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Build-Hadoop-running-environment/#_6-2-7-配置日志的聚集" class="sidebar-link">6.2.7 配置日志的聚集</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Build-Hadoop-running-environment/#_6-2-8-集群启动-停止方式总结" class="sidebar-link">6.2.8 集群启动/停止方式总结</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_1-各个模块分开启动-停止-配置-ssh-是前提-常用" class="sidebar-link">1）各个模块分开启动/停止（配置 ssh 是前提）常用</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_2-各个服务组件逐一启动-停止" class="sidebar-link">2）各个服务组件逐一启动/停止</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Build-Hadoop-running-environment/#_6-2-9-编写-hadoop-集群常用脚本" class="sidebar-link">6.2.9 编写 Hadoop 集群常用脚本</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_1-hadoop-集群启停脚本-包含-hdfs-yarn-historyserver-myhadoop-sh" class="sidebar-link">1）Hadoop 集群启停脚本（包含 HDFS，Yarn，Historyserver）：myhadoop.sh</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_2-查看三台服务器-java-进程脚本-jpsall" class="sidebar-link">2）查看三台服务器 Java 进程脚本：jpsall</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Build-Hadoop-running-environment/#_3-分发-home-atguigu-bin-目录-保证自定义脚本在三台机器上都可以使用" class="sidebar-link">3）分发/home/atguigu/bin 目录，保证自定义脚本在三台机器上都可以使用</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Build-Hadoop-running-environment/#_6-2-10-常用端口号说明" class="sidebar-link">6.2.10 常用端口号说明</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/Build-Hadoop-running-environment/#_6-2-11-集群时间同步" class="sidebar-link">6.2.11 集群时间同步</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_1-需求" class="sidebar-link">1）需求</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_2-时间服务器配置-必须-root-用户" class="sidebar-link">2）时间服务器配置（必须 root 用户）</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/Build-Hadoop-running-environment/#_3-其他机器配置-必须-root-用户" class="sidebar-link">3）其他机器配置（必须 root 用户）</a></li></ul></li></ul></li><li><a href="/pages/Hadoop-working-mechanism/" class="sidebar-link">第四章Hadoop之HDFS详解以及工作机制介绍</a></li><li><a href="/pages/haddop-MapReduce/" class="sidebar-link">第五章MapReduce编程框架</a></li><li><a href="/pages/5cb5f8/" class="sidebar-link">第六章Hadoop 数据压缩</a></li><li><a href="/Hadoop/Yarn/" class="sidebar-link">第七章大数据技术之 Hadoop（Yarn）</a></li><li><a href="/pages/c19893/" class="sidebar-link">第八章Hadoop（生产调优手册）</a></li><li><a href="/pages/4a90c0/" class="sidebar-link">hadoo3.x 在windows10下编译</a></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/categories/?category=Hadoop" title="分类" data-v-06225672>Hadoop</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/andanyoung" target="_blank" title="作者" class="beLink" data-v-06225672>andanyang</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2023-06-01</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABGpJREFUSA3tVVtoXFUU3fvOI53UlmCaKIFmwEhsE7QK0ipFEdHEKpXaZGrp15SINsXUWvBDpBgQRKi0+KKoFeJHfZA+ED9KKoIU2gYD9UejTW4rVIzm0VSTziPzuNu1z507dibTTjL4U/DAzLn3nL3X2o91ziX6f9wMFdh6Jvbm9nNSV0msViVO6tN1Rm7NMu2OpeJ9lWBUTDxrJbYTS0hInuwciu9eLHlFxCLCZEk3MegsJmZ5K/JD6t7FkFdEvGUo1g7qJoG3MHImqRIn8/nzY1K9UPKKiJmtnUqHVE3Gbuay6vJE/N2FEmuxFjW2nUuE0yQXRRxLiTUAzs36zhZvOXJPdX850EVnnLZkB8prodQoM5JGj7Xk2mvC7JB8tG04Ef5PiXtG0UtxupRQSfTnBoCy554x18yJHI6I+G5Eru4LHmPJZEQsrvPUbMiA8G/WgMK7w7I+ez7++o2ANfbrjvaOl1tFMs+htG3IrZH9/hDX1Pr8Tc0UvH8tcX29KzAgIGcEkINyW5BF9x891hw6VYqgJHEk0huccS7vh3C6gTiODL+26huuBtbct8eZnqLML8PkxGYpuPZBqtqwkSjgc4mB5gbgig5i+y0UDK35LMxXisn9xQtK+nd26gTIHsHe/oblK/b29fUmN/8Y+9jAQrnBp56m1LcDlDp9irKTExSKduXJVWSqdBMA08pEJnEIOB3FPPMybu/oeV8zFeYN3xx576Q6RH+VmplE4ncQV5v+5rzSoyOU7PuEAg8g803PwBJ0CExno/jcMbN8tONYeOmHiuUNryvm3fRUy4tMPVLdAGkUhNWuggGrJcXPv+ouCjz0MKUHz1J2/E8IC9nqTabcxgaBYM0hPhD5Y65FsbxRQKxCQrDjDctW7PUM3HuZunFyifSAqEfuzCp48Il24luWUWZoyJCaPR82jE0+kFA643wRFVni4RYSq3ohJO2pZ7B5dO4xkDWbEpossJPLSrPjYID8rS2UHTlvyNxqIGsg674XJJ7vnh5L7PNwC4hh2sjCI96mzszOTpxLF0T7l88Yz7lAuK6OnL8gXLOnTvpzSb22YG8W7us3jSebFHeeqnXRG1vt+MoUM84LQIBmMsCTAcOauTh0T0l0neQK7m2bLMt2mGxU3HYssS0J2cdv5wljlPsrIuZLAG/2DOZIXgCYT8uMGZN+e2kSirfxZOPCsC0f24nTZzspnVn9VePS1Z5vubmAGGXG8ZFno9Hel0yfA5ZPhF7Dh972BQJ2qCpgH67lmWtBYbvk6sz02wjky2vXyz0XErP/kFB619js1BtwfOV4OPRqOQBjy3Qbk18vigUPPSD5ceHnwck7W9bhAqZdd7SuG7w4/P2F/GaJh8c7e9qgow+Q7cGBo+98WsLkuktFqiZabtXuQTu/Y5ETbR0v7tNSFnvrmu6pjdoan2KjMu8q/Hmj1EfCO2ZGfEIbIXKUlw8qaX9/b2oeSJmFksSeT/Fn0V3nSypChh4Gjh74ybO9aeZ/AN2dwciu2/MhAAAAAElFTkSuQmCC">第三章Hadoop 运行环境搭建<!----></h1>  <div class="theme-vdoing-content content__default"><p><img src="/assets/img/29893098fdf3fee9479ced13d40799bd.87b93a1e.png" alt="Hadoop"></p> <h1 id="_1-模板虚拟机环境准备"><a href="#_1-模板虚拟机环境准备" class="header-anchor">#</a> 1 模板虚拟机环境准备</h1> <blockquote><p><a href="https://andyoung.blog.csdn.net/article/details/124333491" target="_blank" rel="noopener noreferrer">VMware 虚拟机安装详细教程网络 NAT、网桥配置<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></blockquote> <p>1.1 安装模板虚拟机，IP 地址 192.168.10.100、主机名称 hadoop100、内存 4G、硬盘 50G</p> <p>1.2 hadoop100 虚拟机配置要求如下（本文 Linux 系统全部以 CentOS-7.5-x86-1804 为例）</p> <p>（1）使用 yum 安装需要虚拟机可以正常上网，yum 安装前可以先测试下虚拟机联网情况</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[root@hadoop100 ~]# ping www.baidu.com
PING www.baidu.com (14.215.177.39) 56(84) bytes of data.
64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=1 ttl=128 time=8.60 ms
64 bytes from 14.215.177.39 (14.215.177.39): icmp_seq=2 ttl=128 time=7.72 ms
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>（2）安装 epel-release</p> <p>注：Extra Packages for Enterprise Linux 是为“红帽系”的操作系统提供额外的软件包，适用于 RHEL、CentOS 和 Scientific Linux。相当于是一个软件仓库，大多数 rpm 包在官方 repository 中是找不到的）</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[root@hadoop100 ~]# yum install -y epel-release
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><mark>（3）注意：如果 Linux 安装的是最小系统版，还需要安装如下工具；如果安装的是 Linux 桌面标准版，不需要执行如下操作</mark></p> <ul><li><p>net-tool：工具包集合，包含 ifconfig 等命令</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[root@hadoop100 ~]# yum install -y net-tools
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li> <li><p>vim：编辑器</p> <div class="language- extra-class"><pre><code>```
[root@hadoop100 ~]# yum install -y vim
```
</code></pre></div><p>1.3 关闭防火墙，关闭防火墙开机自启</p></li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>[root@hadoop100 ~]# systemctl stop firewalld
[root@hadoop100 ~]# systemctl disable firewalld.service
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><blockquote><p>注意：在企业开发时，通常单个服务器的防火墙时关闭的。公司整体对外会设置非常安全的防火墙</p></blockquote> <p>1.4 创建 atguigu 用户，并修改 atguigu 用户的密码</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[root@hadoop100 ~]# useradd atguigu
[root@hadoop100 ~]# passwd atguigu
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>1.5 配置 atguigu 用户具有 root 权限，方便后期加 sudo 执行 root 权限的命</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[root@hadoop100 ~]# vim /etc/sudoers
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>修改/etc/sudoers 文件，在%wheel 这行下面添加一行，如下所示：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>## Allow root to run any commands anywhere
root    ALL=(ALL)     ALL

## Allows people in group wheel to run all commands
%wheel  ALL=(ALL)       ALL
atguigu   ALL=(ALL)     NOPASSWD:ALL
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><blockquote><p>注意：atguigu 这一行不要直接放到 root 行下面，因为所有用户都属于 wheel 组，你先配置了 atguigu 具有免密功能，但是程序执行到%wheel 行时，该功能又被覆盖回需要密码。所以 atguigu 要放到%wheel 这行下面。</p></blockquote> <p>1.6 在/opt 目录下创建文件夹，并修改所属主和所属组</p> <p>（1）在/opt 目录下创建 module、software 文件夹</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[root@hadoop100 ~]# mkdir /opt/module
[root@hadoop100 ~]# mkdir /opt/software
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>（2）修改 module、software 文件夹的所有者和所属组均为 atguigu 用户</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[root@hadoop100 ~]# chown atguigu:atguigu /opt/module
[root@hadoop100 ~]# chown atguigu:atguigu /opt/software
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>（3）查看 module、software 文件夹的所有者和所属组</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[root@hadoop100 ~]# cd /opt/
[root@hadoop100 opt]# ll
总用量 12
drwxr-xr-x. 2 atguigu atguigu 4096 5月  28 17:18 module
drwxr-xr-x. 2 root    root    4096 9月   7 2017 rh
drwxr-xr-x. 2 atguigu atguigu 4096 5月  28 17:18 software
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>1.7 卸载虚拟机自带的 JDK</p> <blockquote><p>注意：如果你的虚拟机是最小化安装不需要执行这一步。</p></blockquote> <div class="language- line-numbers-mode"><pre class="language-text"><code>[root@hadoop100 ~]# rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><ul><li><p>rpm -qa：查询所安装的所有 rpm 软件包</p></li> <li><p>grep -i：忽略大小写</p></li> <li><p>xargs -n1：表示每次只传递一个参数</p></li> <li><p>rpm -e –nodeps：强制卸载软件</p> <p>1.8 重启虚拟机</p></li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>[root@hadoop100 ~]# reboot
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h1 id="_2-克隆虚拟机"><a href="#_2-克隆虚拟机" class="header-anchor">#</a> 2. 克隆虚拟机</h1> <h2 id="_2-1-利用模板机-hadoop100-克隆三台虚拟机-hadoop102-hadoop103-hadoop104"><a href="#_2-1-利用模板机-hadoop100-克隆三台虚拟机-hadoop102-hadoop103-hadoop104" class="header-anchor">#</a> 2.1 利用模板机 hadoop100，克隆三台虚拟机：hadoop102 hadoop103 hadoop104</h2> <blockquote><p>注意：克隆时，要先关闭 hadoop100</p></blockquote> <h2 id="_2-2-修改克隆机-ip-以下以-hadoop102-举例说明"><a href="#_2-2-修改克隆机-ip-以下以-hadoop102-举例说明" class="header-anchor">#</a> 2.2 修改克隆机 IP，以下以 hadoop102 举例说明</h2> <p>（1）修改克隆虚拟机的静态 IP</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[root@hadoop100 ~]# vim /etc/sysconfig/network-scripts/ifcfg-ens33
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>改成</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>DEVICE=ens33
TYPE=Ethernet
ONBOOT=yes
BOOTPROTO=static
NAME=&quot;ens33&quot;
IPADDR=192.168.10.102
PREFIX=24
GATEWAY=192.168.10.2
DNS1=192.168.10.2
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>（2）查看 Linux 虚拟机的虚拟网络编辑器，编辑-&gt;虚拟网络编辑器-&gt;VMnet8</p> <p><img src="/assets/img/image-20230705223048368.667d7e27.png" alt="image-20230705223048368"></p> <p><img src="/assets/img/image-20230705223100257.3a90dcd9.png" alt="image-20230705223100257"></p> <p>（3）查看 Windows 系统适配器 VMware Network Adapter VMnet8 的 IP 地址</p> <p><img src="/assets/img/image-20230705223132640.5b29e4d4.png" alt="image-20230705223132640"></p> <p><img src="/assets/img/image-20230705223157584.5b29e4d4.png" alt="image-20230705223157584"></p> <p>（4）保证 Linux 系统 ifcfg-ens33 文件中 IP 地址、虚拟网络编辑器地址和 Windows 系统 VM8 网络 IP 地址相同。</p> <h2 id="_2-3-修改克隆机主机名-以下以-hadoop102-举例说明"><a href="#_2-3-修改克隆机主机名-以下以-hadoop102-举例说明" class="header-anchor">#</a> 2.3 修改克隆机主机名，以下以 hadoop102 举例说明</h2> <p>（1）修改主机名称</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[root@hadoop100 ~]# vim /etc/hostname
hadoop102
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>（2）配置 Linux 克隆机主机名称映射 hosts 文件，打开/etc/hosts</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[root@hadoop100 ~]# vim /etc/hosts
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>添加如下内容</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>192.168.10.100 hadoop100
192.168.10.101 hadoop101
192.168.10.102 hadoop102
192.168.10.103 hadoop103
192.168.10.104 hadoop104
192.168.10.105 hadoop105
192.168.10.106 hadoop106
192.168.10.107 hadoop107
192.168.10.108 hadoop108
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><h2 id="_1-4-重启克隆机-hadoop102"><a href="#_1-4-重启克隆机-hadoop102" class="header-anchor">#</a> 1.4 重启克隆机 hadoop102</h2> <div class="language- line-numbers-mode"><pre class="language-text"><code>[root@hadoop100 ~]# reboot
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>1.5 修改 windows 的主机映射文件（hosts 文件）</p> <p>（1）如果操作系统是 window7，可以直接修改</p> <p>（a）进入 C:\Windows\System32\drivers\etc 路径</p> <p>（b）打开 hosts 文件并添加如下内容，然后保存</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>192.168.10.100 hadoop100
192.168.10.101 hadoop101
192.168.10.102 hadoop102
192.168.10.103 hadoop103
192.168.10.104 hadoop104
192.168.10.105 hadoop105
192.168.10.106 hadoop106
192.168.10.107 hadoop107
192.168.10.108 hadoop108
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>（2）如果操作系统是 window10，先拷贝出来，修改保存以后，再覆盖即可</p> <p>（a）进入 C:\Windows\System32\drivers\etc 路径</p> <p>（b）拷贝 hosts 文件到桌面</p> <p>（c）打开桌面 hosts 文件并添加如下内容</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>192.168.10.100 hadoop100
192.168.10.101 hadoop101
192.168.10.102 hadoop102
192.168.10.103 hadoop103
192.168.10.104 hadoop104
192.168.10.105 hadoop105
192.168.10.106 hadoop106
192.168.10.107 hadoop107
192.168.10.108 hadoop108
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>（d）将桌面 hosts 文件覆盖 C:\Windows\System32\drivers\etc 路径 hosts 文件</p> <h1 id="_3-hadoop-编译安装-选做"><a href="#_3-hadoop-编译安装-选做" class="header-anchor">#</a> 3 <strong>Hadoop 编译安装（选做）</strong></h1> <ul><li>为什么要重新编译 Hadoop 源码?</li></ul> <p>匹配不同操作系统本地库环境，Hadoop 某些操作比如压缩、IO 需要调用系统本地库（<strong>.so|</strong>.dll）修改源码、重构源码</p> <ul><li>如何编译 Hadoop 源码包根目录下文件：BUILDING.txt 详细步骤参考附件资料</li></ul> <p><img src="/assets/img/8a3ace63c0c2336bf9727400aa79f4d9.a19851e1.png" alt="img"></p> <ul><li><p>安装编译相关的依赖</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code>yum <span class="token function">install</span> gcc gcc-c++ <span class="token function">make</span> autoconf automake libtool <span class="token function">curl</span> lzo-devel zlib-devel openssl openssl-devel ncurses-devel snappy snappy-devel <span class="token function">bzip2</span> bzip2-devel lzo lzo-devel lzop libXtst zlib <span class="token parameter variable">-y</span>

yum <span class="token function">install</span> <span class="token parameter variable">-y</span> doxygen cyrus-sasl* saslwrapper-devel*
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div></li> <li><p>手动安装 cmake</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token comment">#yum卸载已安装cmake 版本低</span>
yum erase cmake

<span class="token comment">#解压</span>
<span class="token function">tar</span> zxvf CMake-3.19.4.tar.gz

<span class="token comment">#编译安装</span>
<span class="token builtin class-name">cd</span> /export/server/CMake-3.19.4

./configure

<span class="token function">make</span> <span class="token operator">&amp;&amp;</span> <span class="token function">make</span> <span class="token function">install</span>

<span class="token comment">#验证</span>
<span class="token punctuation">[</span>root@node4 ~<span class="token punctuation">]</span><span class="token comment"># cmake -version</span>
cmake version <span class="token number">3.19</span>.4

<span class="token comment">#如果没有正确显示版本 请断开SSH连接 重写登录</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div></li> <li><p>手动安装 snappy</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token comment">#卸载已经安装的</span>

<span class="token function">rm</span> <span class="token parameter variable">-rf</span> /usr/local/lib/libsnappy*
<span class="token function">rm</span> <span class="token parameter variable">-rf</span> /lib64/libsnappy*

<span class="token comment">#上传解压</span>
<span class="token function">tar</span> zxvf snappy-1.1.3.tar.gz

<span class="token comment">#编译安装</span>
<span class="token builtin class-name">cd</span> /export/server/snappy-1.1.3
./configure
<span class="token function">make</span> <span class="token operator">&amp;&amp;</span> <span class="token function">make</span> <span class="token function">install</span>

<span class="token comment">#验证是否安装</span>
<span class="token punctuation">[</span>root@node4 snappy-1.1.3<span class="token punctuation">]</span><span class="token comment"># ls -lh /usr/local/lib |grep snappy</span>
-rw-r--r-- <span class="token number">1</span> root root 511K Nov  <span class="token number">4</span> <span class="token number">17</span>:13 libsnappy.a
-rwxr-xr-x <span class="token number">1</span> root root  <span class="token number">955</span> Nov  <span class="token number">4</span> <span class="token number">17</span>:13 libsnappy.la
lrwxrwxrwx <span class="token number">1</span> root root   <span class="token number">18</span> Nov  <span class="token number">4</span> <span class="token number">17</span>:13 libsnappy.so -<span class="token operator">&gt;</span> libsnappy.so.1.3.0
lrwxrwxrwx <span class="token number">1</span> root root   <span class="token number">18</span> Nov  <span class="token number">4</span> <span class="token number">17</span>:13 libsnappy.so.1 -<span class="token operator">&gt;</span> libsnappy.so.1.3.0
-rwxr-xr-x <span class="token number">1</span> root root 253K Nov  <span class="token number">4</span> <span class="token number">17</span>:13 libsnappy.so.1.3.0
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div></li> <li><p>安装配置 JDK 1.8</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token comment">#解压安装包</span>
<span class="token function">tar</span> zxvf jdk-8u65-linux-x64.tar.gz

<span class="token comment">#配置环境变量</span>
<span class="token function">vim</span> /etc/profile

<span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_HOME</span><span class="token operator">=</span>/export/server/jdk1.8.0_241
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$JAVA_HOME</span>/bin
<span class="token builtin class-name">export</span> <span class="token assign-left variable">CLASSPATH</span><span class="token operator">=</span>.:<span class="token variable">$JAVA_HOME</span>/lib/dt.jar:<span class="token variable">$JAVA_HOME</span>/lib/tools.jar

<span class="token builtin class-name">source</span> /etc/profile

<span class="token comment">#验证是否安装成功</span>
<span class="token function">java</span> <span class="token parameter variable">-version</span>

<span class="token function">java</span> version <span class="token string">&quot;1.8.0_241&quot;</span>
Java<span class="token punctuation">(</span>TM<span class="token punctuation">)</span> SE Runtime Environment <span class="token punctuation">(</span>build <span class="token number">1.8</span>.0_241-b07<span class="token punctuation">)</span>
Java HotSpot<span class="token punctuation">(</span>TM<span class="token punctuation">)</span> <span class="token number">64</span>-Bit Server VM <span class="token punctuation">(</span>build <span class="token number">25.241</span>-b07, mixed mode<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div></li> <li><p>安装配置 maven</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token comment">#解压安装包</span>
<span class="token function">tar</span> zxvf apache-maven-3.5.4-bin.tar.gz

<span class="token comment">#配置环境变量</span>
<span class="token function">vim</span> /etc/profile

<span class="token builtin class-name">export</span> <span class="token assign-left variable">MAVEN_HOME</span><span class="token operator">=</span>/export/server/apache-maven-3.5.4
<span class="token builtin class-name">export</span> <span class="token assign-left variable">MAVEN_OPTS</span><span class="token operator">=</span><span class="token string">&quot;-Xms4096m -Xmx4096m&quot;</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span>:<span class="token variable">$MAVEN_HOME</span>/bin:<span class="token environment constant">$PATH</span>

<span class="token builtin class-name">source</span> /etc/profile

<span class="token comment">#验证是否安装成功</span>
<span class="token punctuation">[</span>root@node4 ~<span class="token punctuation">]</span><span class="token comment"># mvn -v</span>
Apache Maven <span class="token number">3.5</span>.4

<span class="token comment">#添加maven 阿里云仓库地址 加快国内编译速度</span>
<span class="token function">vim</span> /export/server/apache-maven-3.5.4/conf/settings.xml

<span class="token operator">&lt;</span>mirrors<span class="token operator">&gt;</span>
     <span class="token operator">&lt;</span>mirror<span class="token operator">&gt;</span>
           <span class="token operator">&lt;</span>id<span class="token operator">&gt;</span>alimaven<span class="token operator">&lt;</span>/id<span class="token operator">&gt;</span>
           <span class="token operator">&lt;</span>name<span class="token operator">&gt;</span>aliyun maven<span class="token operator">&lt;</span>/name<span class="token operator">&gt;</span>
           <span class="token operator">&lt;</span>url<span class="token operator">&gt;</span>http://maven.aliyun.com/nexus/content/groups/public/<span class="token operator">&lt;</span>/url<span class="token operator">&gt;</span>
           <span class="token operator">&lt;</span>mirrorOf<span class="token operator">&gt;</span>central<span class="token operator">&lt;</span>/mirrorOf<span class="token operator">&gt;</span>
      <span class="token operator">&lt;</span>/mirror<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>/mirrors<span class="token operator">&gt;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br></div></div></li> <li><p>安装 ProtocolBuffer 3.7.1</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token comment">#卸载之前版本的protobuf</span>

<span class="token comment">#解压</span>
<span class="token function">tar</span> zxvf protobuf-3.7.1.tar.gz

<span class="token comment">#编译安装</span>
<span class="token builtin class-name">cd</span> /export/server/protobuf-3.7.1
./autogen.sh
./configure
<span class="token function">make</span> <span class="token operator">&amp;&amp;</span> <span class="token function">make</span> <span class="token function">install</span>

<span class="token comment">#验证是否安装成功</span>
<span class="token punctuation">[</span>root@node4 protobuf-3.7.1<span class="token punctuation">]</span><span class="token comment"># protoc --version</span>
libprotoc <span class="token number">3.7</span>.1
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br></div></div></li> <li><p>编译 hadoop</p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token comment">#上传解压源码包</span>
<span class="token function">tar</span> zxvf hadoop-3.3.0-src.tar.gz

<span class="token comment">#编译</span>
<span class="token builtin class-name">cd</span> /root/hadoop-3.3.0-src

mvn clean package -Pdist,native <span class="token parameter variable">-DskipTests</span> <span class="token parameter variable">-Dtar</span> <span class="token parameter variable">-Dbundle.snappy</span> <span class="token parameter variable">-Dsnappy.lib</span><span class="token operator">=</span>/usr/local/lib

<span class="token comment">#参数说明：</span>

Pdist,native ：把重新编译生成的hadoop动态库；
DskipTests ：跳过测试
Dtar ：最后把文件以tar打包
Dbundle.snappy ：添加snappy压缩支持【默认官网下载的是不支持的】
<span class="token assign-left variable">Dsnappy.lib</span><span class="token operator">=</span>/usr/local/lib ：指snappy在编译机器上安装后的库路径
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div></li> <li><p>编译之后的安装包路径</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>/root/hadoop-3.3.0-src/hadoop-dist/target
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li></ul> <h1 id="_4-在-hadoop102-安装-hadoop"><a href="#_4-在-hadoop102-安装-hadoop" class="header-anchor">#</a> 4 在 hadoop102 安装 Hadoop</h1> <p>Hadoop 下载地址：<a href="https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/" target="_blank" rel="noopener noreferrer">https://archive.apache.org/dist/hadoop/common/hadoop-3.1.3/<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>1）用 XShell 文件传输工具将 hadoop-3.1.3.tar.gz 导入到 opt 目录下面的 software 文件夹下面</p> <p>2）进入到 Hadoop 安装包路径下</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ cd /opt/software/
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>3）解压安装文件到/opt/module 下面</p> <p>4）查看是否解压成功</p> <p>5）将 Hadoop 添加到环境变量</p> <p>（1）获取 Hadoop 安装路径</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ pwd
/opt/module/hadoop-3.1.3
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>（2）打开/etc/profile.d/my_env.sh 文件</p> <ul><li><p>在 my_env.sh 文件末尾添加如下内容：（shift+g）</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>#HADOOP_HOME
export HADOOP_HOME=/opt/module/hadoop-3.1.3
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div></li> <li><p>保存并退出</p></li></ul> <p>（3）让修改后的文件生效</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>atguigu@hadoop102 hadoop-3.1.3]$ source /etc/profile
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>6）测试是否安装成功</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hadoop version
Hadoop 3.1.3
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>7）重启（如果 Hadoop 命令不能用再重启虚拟机）</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ sudo reboot
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h1 id="_5-hadoop-目录结构"><a href="#_5-hadoop-目录结构" class="header-anchor">#</a> 5 Hadoop 目录结构</h1> <p>1）查看 Hadoop 目录结构</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ ll
总用量 52
drwxr-xr-x. 2 atguigu atguigu  4096 5月  22 2017 bin
drwxr-xr-x. 3 atguigu atguigu  4096 5月  22 2017 etc
drwxr-xr-x. 2 atguigu atguigu  4096 5月  22 2017 include
drwxr-xr-x. 3 atguigu atguigu  4096 5月  22 2017 lib
drwxr-xr-x. 2 atguigu atguigu  4096 5月  22 2017 libexec
-rw-r--r--. 1 atguigu atguigu 15429 5月  22 2017 LICENSE.txt
-rw-r--r--. 1 atguigu atguigu   101 5月  22 2017 NOTICE.txt
-rw-r--r--. 1 atguigu atguigu  1366 5月  22 2017 README.txt
drwxr-xr-x. 2 atguigu atguigu  4096 5月  22 2017 sbin
drwxr-xr-x. 4 atguigu atguigu  4096 5月  22 2017 share
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>2）重要目录</p> <p>（1）bin 目录：存放对 Hadoop 相关服务（hdfs，yarn，mapred）进行操作的脚本</p> <p>（2）etc 目录：Hadoop 的配置文件目录，存放 Hadoop 的配置文件</p> <p>（3）lib 目录：存放 Hadoop 的本地库（对数据进行压缩解压缩功能）</p> <p>（4）sbin 目录：存放启动或停止 Hadoop 相关服务的脚本</p> <p>（5）share 目录：存放 Hadoop 的依赖 jar 包、文档、和官方案例</p> <h1 id="_6-hadoop-运行模式"><a href="#_6-hadoop-运行模式" class="header-anchor">#</a> 6 Hadoop 运行模式</h1> <p>1）Hadoop 官方网站：http://hadoop.apache.org/</p> <p>2）Hadoop 运行模式包括：<strong>本地模式</strong>、<strong>伪分布式模式</strong>以及<strong>完全分布式模式</strong>。</p> <ul><li><p><strong>本地模式</strong>：单机运行，只是用来演示一下官方案例。生产环境不用。</p></li> <li><p><strong>伪分布式模式</strong>： 也是单机运行，但是具备 Hadoop 集群的所有功能，一台服务器模拟一个分布式的环境。个别缺钱的公司用来测试，生产环境不用。</p></li> <li><p><strong>完全分布式模式</strong>：多台服务器组成分布式环境。生产环境使用。</p></li></ul> <h2 id="_6-1-本地运行模式-官方-wordcount"><a href="#_6-1-本地运行模式-官方-wordcount" class="header-anchor">#</a> 6.1 本地运行模式（官方 WordCount）</h2> <p>1）创建在 hadoop-3.1.3 文件下面创建一个 wcinput 文件夹</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ mkdir wcinput
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>2）在 wcinput 文件下创建一个 word.txt 文件</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ cd wcinput
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>3）编辑 word.txt 文件</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 wcinput]$ vim word.txt
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><ul><li>在文件中输入如下内容</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>hadoop yarn
hadoop mapreduce
atguigu
atguigu
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><ul><li>保存退出：wq</li></ul> <p>4）回到 Hadoop 目录/opt/module/hadoop-3.1.3</p> <p>5）执行程序</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount wcinput wcoutput
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>6）查看结果</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ cat wcoutput/part-r-00000
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>看到如下结果：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>atguigu 2
hadoop  2
mapreduce       1
yarn    1
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><h2 id="_6-2-完全分布式运行模式-开发重点"><a href="#_6-2-完全分布式运行模式-开发重点" class="header-anchor">#</a> 6.2 完全分布式运行模式（开发重点）</h2> <p>分析：
1）准备 3 台客户机（关闭防火墙、静态 IP、主机名称）
2）安装 JDK
3）配置环境变量
4）安装 Hadoop
5）配置环境变量
6）配置集群
7）单点启动
8）配置 ssh
9）群起并测试集群</p> <h3 id="_6-2-1-虚拟机准备"><a href="#_6-2-1-虚拟机准备" class="header-anchor">#</a> 6.2.1 虚拟机准备</h3> <h3 id="_6-2-2-编写集群分发脚本-xsync"><a href="#_6-2-2-编写集群分发脚本-xsync" class="header-anchor">#</a> 6.2.2 编写集群分发脚本 xsync</h3> <h4 id="_1-scp-secure-copy-安全拷贝"><a href="#_1-scp-secure-copy-安全拷贝" class="header-anchor">#</a> 1）scp（secure copy）安全拷贝</h4> <p>（1）scp 定义</p> <p>scp 可以实现服务器与服务器之间的数据拷贝。（from server1 to server2）</p> <p>（2）基本语法</p> <p><code>scp -r $pdir/$fname $user@$host:$pdir/$fname</code></p> <p>命令 递归 要拷贝的文件路径/名称 目的地用户@主机:目的地路径/名称</p> <p>（3）案例实操</p> <ul><li><p>前提：在 hadoop102、hadoop103、hadoop104 都已经创建好的/opt/module、Ø /opt/software 两个目录，并且已经把这两个目录修改为 atguigu:atguigu</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ sudo chown atguigu:atguigu -R /opt/module
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（a）在 hadoop102 上，将 hadoop102 中/opt/module/jdk1.8.0_212 目录拷贝到 hadoop103 上。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ scp -r /opt/module/jdk1.8.0_212  atguigu@hadoop103:/opt/module
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（b）在 hadoop103 上，将 hadoop102 中/opt/module/hadoop-3.1.3 目录拷贝到 hadoop103 上。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop103 ~]$ scp -r atguigu@hadoop102:/opt/module/hadoop-3.1.3 /opt/module/
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（c）在 hadoop103 上操作，将 hadoop102 中/opt/module 目录下所有目录拷贝到 hadoop104 上。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop103 opt]$ scp -r atguigu@hadoop102:/opt/module/* atguigu@hadoop104:/opt/module
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li></ul> <h4 id="_2-rsync-远程同步工具"><a href="#_2-rsync-远程同步工具" class="header-anchor">#</a> 2）rsync 远程同步工具</h4> <p>rsync 主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。</p> <p><strong>rsync 和 scp 区别</strong>：用 rsync 做文件的复制要比 scp 的速度快，rsync 只对差异文件做更新。scp 是把所有文件都复制过去。</p> <p>（1）基本语法</p> <p>rsync -av $pdir/$fname $user@$host:$pdir/$fname</p> <p>命令 选项参数 要拷贝的文件路径/名称 目的地用户@主机:目的地路径/名称</p> <p>选项参数说明</p> <table><thead><tr><th>选项</th> <th>功能</th></tr></thead> <tbody><tr><td>-a</td> <td>归档拷贝</td></tr> <tr><td>-v</td> <td>显示复制过程</td></tr></tbody></table> <p>（2）案例实操</p> <p>（a）删除 hadoop103 中/opt/module/hadoop-3.1.3/wcinput</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop103 hadoop-3.1.3]$ rm -rf wcinput/
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（b）同步 hadoop102 中的/opt/module/hadoop-3.1.3 到 hadoop103</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 module]$ rsync -av hadoop-3.1.3/ atguigu@hadoop103:/opt/module/hadoop-3.1.3/
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h4 id="_3-xsync-集群分发脚本"><a href="#_3-xsync-集群分发脚本" class="header-anchor">#</a> 3）xsync 集群分发脚本</h4> <ul><li><p>（1）需求：循环复制文件到所有节点的相同目录下</p></li> <li><p>（2）需求分析：</p> <ul><li><p>（a）rsync 命令原始拷贝：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>rsync  -av     /opt/module  		 atguigu@hadoop103:/opt/
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li> <li><p>b）期望脚本：</p> <p>xsync 要同步的文件名称</p></li> <li><p>（c）期望脚本在任何路径都能使用（脚本放在声明了全局环境变量的路径）</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ echo $PATH
/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/atguigu/.local/bin:/home/atguigu/bin:/opt/module/jdk1.8.0_212/bin
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></li></ul></li> <li><p>（3）脚本实现</p> <ul><li>（a）在/home/atguigu/bin 目录下创建 xsync 文件</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 opt]$ cd /home/atguigu
[atguigu@hadoop102 ~]$ mkdir bin
[atguigu@hadoop102 ~]$ cd bin
[atguigu@hadoop102 bin]$ vim xsync
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>在该文件中编写如下代码</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>#!/bin/bash

#1. 判断参数个数
if [ $# -lt 1 ]
then
    echo Not Enough Arguement!
    exit;
fi

#2. 遍历集群所有机器
for host in hadoop102 hadoop103 hadoop104
do
    echo ====================  $host  ====================
    #3. 遍历所有目录，挨个发送

    for file in $@
    do
        #4. 判断文件是否存在
        if [ -e $file ]
            then
                #5. 获取父目录
                pdir=$(cd -P $(dirname $file); pwd)

                #6. 获取当前文件的名称
                fname=$(basename $file)
                ssh $host &quot;mkdir -p $pdir&quot;
                rsync -av $pdir/$fname $host:$pdir
            else
                echo $file does not exists!
        fi
    done
done
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br></div></div><ul><li><p>（b）修改脚本 xsync 具有执行权限</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 bin]$ chmod +x xsync
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li> <li><p>（c）测试脚本</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ xsync /home/atguigu/bin
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li> <li><p>（d）将脚本复制到/bin 中，以便全局调用</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 bin]$ sudo cp xsync /bin/
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li> <li><p>（e）同步环境变量配置（root 所有者）</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ sudo ./bin/xsync /etc/profile.d/my_env.sh
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><blockquote><p>注意：如果用了 sudo，那么 xsync 一定要给它的路径补全。</p></blockquote> <p>让环境变量生效</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop103 bin]$ source /etc/profile
[atguigu@hadoop104 opt]$ source /etc/profile
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></li></ul></li></ul> <h3 id="_6-2-3-ssh-无密登录配置"><a href="#_6-2-3-ssh-无密登录配置" class="header-anchor">#</a> 6.2.3 SSH 无密登录配置</h3> <h4 id="_1-配置-ssh"><a href="#_1-配置-ssh" class="header-anchor">#</a> 1）配置 ssh</h4> <p>（1）基本语法
ssh 另一台电脑的 IP 地址
（2）ssh 连接时出现 Host key verification failed 的解决方法</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ ssh hadoop103
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><ul><li>如果出现如下内容</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>Are you sure you want to continue connecting (yes/no)?
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><ul><li>输入 yes，并回车</li></ul> <p>（3）退回到 hadoop102</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop103 ~]$ exit
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h4 id="_2-无密钥配置"><a href="#_2-无密钥配置" class="header-anchor">#</a> 2）无密钥配置</h4> <p>（1）免密登录原理</p> <p><img src="/assets/img/image-20230705225744859.24b53e89.png" alt="image-20230705225744859"></p> <p>（2）生成公钥和私钥</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 .ssh]$ pwd
/home/atguigu/.ssh

[atguigu@hadoop102 .ssh]$ ssh-keygen -t rsa
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>然后敲（三个回车），就会生成两个文件 id_rsa（私钥）、id_rsa.pub（公钥）</p> <p>（3）将公钥拷贝到要免密登录的目标机器上</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop102
[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop103
[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop104
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><blockquote><p>注意：</p> <p>还需要在 hadoop103 上采用 atguigu 账号配置一下无密登录到 hadoop102、hadoop103、hadoop104 服务器上。</p> <p>还需要在 hadoop104 上采用 atguigu 账号配置一下无密登录到 hadoop102、hadoop103、hadoop104 服务器上。</p> <p>还需要在 hadoop102 上采用 root 账号，配置一下无密登录到 hadoop102、hadoop103、hadoop104；</p></blockquote> <h4 id="_3-ssh-文件夹下-ssh-的文件功能解释"><a href="#_3-ssh-文件夹下-ssh-的文件功能解释" class="header-anchor">#</a> 3）.ssh 文件夹下（~/.ssh）的文件功能解释</h4> <table><thead><tr><th>known_hosts</th> <th>记录 ssh 访问过计算机的公钥（public key）</th></tr></thead> <tbody><tr><td>id_rsa</td> <td>生成的私钥</td></tr> <tr><td>id_rsa.pub</td> <td>生成的公钥</td></tr> <tr><td>authorized_keys</td> <td>存放授权过的无密登录服务器公钥</td></tr></tbody></table> <h3 id="_6-2-4-集群配置"><a href="#_6-2-4-集群配置" class="header-anchor">#</a> 6.2.4 集群配置</h3> <h4 id="_1-集群部署规划"><a href="#_1-集群部署规划" class="header-anchor">#</a> 1） 集群部署规划</h4> <p>注意：</p> <ul><li><p>NameNode 和 SecondaryNameNode 不要安装在同一台服务器</p></li> <li><p>ResourceManager 也很消耗内存，不要和 NameNode、SecondaryNameNode 配置在同一台机器上。</p></li></ul> <table><thead><tr><th></th> <th>hadoop102</th> <th>hadoop103</th> <th>hadoop104</th></tr></thead> <tbody><tr><td>HDFS</td> <td>NameNodeDataNode</td> <td>DataNode</td> <td>SecondaryNameNodeDataNode</td></tr> <tr><td>YARN</td> <td>NodeManager</td> <td>ResourceManagerNodeManager</td> <td>NodeManager</td></tr></tbody></table> <h4 id="_2-配置文件说明"><a href="#_2-配置文件说明" class="header-anchor">#</a> 2）配置文件说明</h4> <p>Hadoop 配置文件分两类：默认配置文件和自定义配置文件，只有用户想修改某一默认配置值时，才需要修改自定义配置文件，更改相应属性值。</p> <p>（1）默认配置文件：</p> <table><thead><tr><th>要获取的默认文件</th> <th>文件存放在 Hadoop 的 jar 包中的位置</th></tr></thead> <tbody><tr><td>[core-default.xml]</td> <td>hadoop-common-3.1.3.jar/core-default.xml</td></tr> <tr><td>[hdfs-default.xml]</td> <td>hadoop-hdfs-3.1.3.jar/hdfs-default.xml</td></tr> <tr><td>[yarn-default.xml]</td> <td>hadoop-yarn-common-3.1.3.jar/yarn-default.xml</td></tr> <tr><td>[mapred-default.xml]</td> <td>hadoop-mapreduce-client-core-3.1.3.jar/mapred-default.xml</td></tr></tbody></table> <p>（2）自定义配置文件：</p> <p><strong>core-site.xml、hdfs-site.xml、yarn-site.xml、mapred-site.xml</strong>四个配置文件存放在<code>$HADOOP_HOME/etc/hadoop</code>这个路径上，用户可以根据项目需求重新进行修改配置。</p> <h4 id="_3-配置集群"><a href="#_3-配置集群" class="header-anchor">#</a> 3）配置集群</h4> <ul><li><p><strong>hadoop-env.sh</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>#文件最后添加
export JAVA_HOME=/export/server/jdk1.8.0_241

export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br></div></div></li></ul> <p>（1）核心配置文件</p> <p>配置<strong>core-site.xml</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ cd $HADOOP_HOME/etc/hadoop
[atguigu@hadoop102 hadoop]$ vim core-site.xml
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>文件内容如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;

&lt;configuration&gt;
    &lt;!-- 指定NameNode的地址 --&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://hadoop102:8020&lt;/value&gt;
    &lt;/property&gt;

    &lt;!-- 指定hadoop数据的存储目录 --&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;/opt/module/hadoop-3.1.3/data&lt;/value&gt;
    &lt;/property&gt;

    &lt;!-- 配置HDFS网页登录使用的静态用户为atguigu --&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;
        &lt;value&gt;atguigu&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br></div></div><p>（2）HDFS 配置文件</p> <p>配置 hdfs-site.xml</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;

&lt;configuration&gt;
	&lt;!-- nn web端访问地址--&gt;
	&lt;property&gt;
        &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;
        &lt;value&gt;hadoop102:9870&lt;/value&gt;
    &lt;/property&gt;
	&lt;!-- 2nn web端访问地址--&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
        &lt;value&gt;hadoop104:9868&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><p>（3）YARN 配置文件</p> <p>配置 yarn-site.xml</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;

&lt;configuration&gt;
    &lt;!-- 指定MR走shuffle --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;

    &lt;!-- 指定ResourceManager的地址--&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
        &lt;value&gt;hadoop103&lt;/value&gt;
    &lt;/property&gt;

    &lt;!-- 环境变量的继承 --&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;
        &lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br></div></div><p>（4）MapReduce 配置文件</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;

&lt;configuration&gt;
	&lt;!-- 指定MapReduce程序运行在Yarn上 --&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><h4 id="_4-在集群上分发配置好的-hadoop-配置文件"><a href="#_4-在集群上分发配置好的-hadoop-配置文件" class="header-anchor">#</a> 4）在集群上分发配置好的 Hadoop 配置文件</h4> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop]$ xsync /opt/module/hadoop-3.1.3/etc/hadoop/
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h4 id="_5-去-103-和-104-上查看文件分发情况"><a href="#_5-去-103-和-104-上查看文件分发情况" class="header-anchor">#</a> 5）去 103 和 104 上查看文件分发情况</h4> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop103 ~]$ cat /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml
[atguigu@hadoop104 ~]$ cat /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h4 id="_6-2-5-群起集群"><a href="#_6-2-5-群起集群" class="header-anchor">#</a> 6.2.5 群起集群</h4> <h4 id="_1-配置-workers"><a href="#_1-配置-workers" class="header-anchor">#</a> 1）配置 workers</h4> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop]$ vim /opt/module/hadoop-3.1.3/etc/hadoop/workers
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>在该文件中增加如下内容：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hadoop102
hadoop103
hadoop104
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><blockquote><p>注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行</p></blockquote> <p>同步所有节点配置文件</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop]$ xsync /opt/module/hadoop-3.1.3/etc
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h4 id="_2-启动集群"><a href="#_2-启动集群" class="header-anchor">#</a> 2）启动集群</h4> <p>（1）<strong>如果集群是第一次启动</strong>，需要在 hadoop102 节点格式化 NameNode（<mark>注意：格式化 NameNode，会产生新的集群 id，导致 NameNode 和 DataNode 的集群 id 不一致，集群找不到已往数据。如果集群在运行过程中报错，需要重新格式化 NameNode 的话，一定要先停止 namenode 和 datanode 进程，并且要删除所有机器的 data 和 logs 目录，然后再进行格式化。</mark>）</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hdfs namenode -format
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（2）启动 HDFS</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ sbin/start-dfs.sh
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（3）<mark>在配置了 ResourceManager 的节点（hadoop103）</mark>启动 YARN</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop103 hadoop-3.1.3]$ sbin/start-yarn.sh
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（4）Web 端查看 HDFS 的 NameNode</p> <p>（a）浏览器中输入：http://hadoop102:9870</p> <p>（b）查看 HDFS 上存储的数据信息</p> <p>（5）Web 端查看 YARN 的 ResourceManager</p> <p>（a）浏览器中输入：http://hadoop103:8088</p> <p>（b）查看 YARN 上运行的 Job 信息</p> <h4 id="_3-集群基本测试"><a href="#_3-集群基本测试" class="header-anchor">#</a> 3）集群基本测试</h4> <p>（1）上传文件到集群</p> <ul><li><p>上传小文件</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ hadoop fs -mkdir /input
[atguigu@hadoop102 ~]$ hadoop fs -put $HADOOP_HOME/wcinput/word.txt /input
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></li> <li><p>上传大文件</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ hadoop fs -put  /opt/software/jdk-8u212-linux-x64.tar.gz  /
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li></ul> <p>（2）上传文件后查看文件存放在什么位置</p> <ul><li>查看 HDFS 文件存储路径</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 subdir0]$ pwd
/opt/module/hadoop-3.1.3/data/dfs/data/current/BP-1436128598-192.168.10.102-1610603650062/current/finalized/subdir0/subdir0
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><ul><li><p>查看 HDFS 在磁盘存储文件内容</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 subdir0]$ cat blk_1073741825
hadoop yarn
hadoop mapreduce
atguigu
atguigu
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div></li></ul> <p>（3）拼接</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>-rw-rw-r--. 1 atguigu atguigu 134217728 5月  23 16:01 blk_1073741836
-rw-rw-r--. 1 atguigu atguigu   1048583 5月  23 16:01 blk_1073741836_1012.meta
-rw-rw-r--. 1 atguigu atguigu  63439959 5月  23 16:01 blk_1073741837
-rw-rw-r--. 1 atguigu atguigu    495635 5月  23 16:01 blk_1073741837_1013.meta
[atguigu@hadoop102 subdir0]$ cat blk_1073741836&gt;&gt;tmp.tar.gz
[atguigu@hadoop102 subdir0]$ cat blk_1073741837&gt;&gt;tmp.tar.gz
[atguigu@hadoop102 subdir0]$ tar -zxvf tmp.tar.gz
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>（4）下载</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop104 software]$ hadoop fs -get /jdk-8u212-linux-x64.tar.gz ./
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（5）执行 wordcount 程序</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h3 id="_6-2-6-配置历史服务器"><a href="#_6-2-6-配置历史服务器" class="header-anchor">#</a> 6.2.6 配置历史服务器</h3> <p>为了查看程序的历史运行情况，需要配置一下历史服务器。具体配置步骤如下：</p> <h3 id="_1-配置-mapred-site-xml"><a href="#_1-配置-mapred-site-xml" class="header-anchor">#</a> 1）配置 mapred-site.xml</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop]$ vim mapred-site.xml
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>在该文件里面增加如下配置。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;!-- 历史服务器端地址 --&gt;
&lt;property&gt;
    &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
    &lt;value&gt;hadoop102:10020&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 历史服务器web端地址 --&gt;
&lt;property&gt;
    &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
    &lt;value&gt;hadoop102:19888&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p>2）分发配置</p> <p>3）<strong>在 hadoop102 启动历史服务器</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop]$ mapred --daemon start historyserver
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>4）查看历史服务器是否启动</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop]$ jps
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>5）查看 JobHistory</p> <p>http://hadoop102:19888/jobhistory</p> <h3 id="_6-2-7-配置日志的聚集"><a href="#_6-2-7-配置日志的聚集" class="header-anchor">#</a> 6.2.7 配置日志的聚集</h3> <p>日志聚集概念：应用运行完成以后，将程序运行日志信息上传到 HDFS 系统上。</p> <p><img src="/assets/img/image-20230705231151490.d432a5f3.png" alt="image-20230705231151490"></p> <p>日志聚集功能好处：可以方便的查看到程序运行详情，方便开发调试。</p> <blockquote><p>注意：开启日志聚集功能，需要重新启动 NodeManager 、ResourceManager 和 HistoryServer。</p></blockquote> <p>开启日志聚集功能具体步骤如下：</p> <p>1）配置 yarn-site.xml</p> <p>在该文件里面增加如下配置。</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;!-- 开启日志聚集功能 --&gt;
&lt;property&gt;
    &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 设置日志聚集服务器地址 --&gt;
&lt;property&gt;
    &lt;name&gt;yarn.log.server.url&lt;/name&gt;
    &lt;value&gt;http://hadoop102:19888/jobhistory/logs&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 设置日志保留时间为7天 --&gt;
&lt;property&gt;
    &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;
    &lt;value&gt;604800&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><p>2）分发配置</p> <p>3）关闭 NodeManager 、ResourceManager 和 HistoryServer</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop103 hadoop-3.1.3]$ sbin/stop-yarn.sh
[atguigu@hadoop103 hadoop-3.1.3]$ mapred --daemon stop historyserver
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>4）启动 NodeManager 、ResourceManage 和 HistoryServer</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop103 ~]$ start-yarn.sh
[atguigu@hadoop102 ~]$ mapred --daemon start historyserver
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>5）删除 HDFS 上已经存在的输出文件</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ hadoop fs -rm -r /output
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>6）执行 WordCount 程序</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 hadoop-3.1.3]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>7）查看日志</p> <p>（1）历史服务器地址</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>http://hadoop102:19888/jobhistory
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（2）历史任务列表</p> <p><img src="/assets/img/image-20230705231407827.42d7ff3f.png" alt="image-20230705231407827"></p> <p>（3）查看任务运行日志</p> <p><img src="/assets/img/image-20230705231417103.57243b49.png" alt="image-20230705231417103"></p> <p>（4）运行日志详情</p> <p><img src="/assets/img/image-20230705231427820.45bebeb6.png" alt="image-20230705231427820"></p> <h3 id="_6-2-8-集群启动-停止方式总结"><a href="#_6-2-8-集群启动-停止方式总结" class="header-anchor">#</a> 6.2.8 集群启动/停止方式总结</h3> <h4 id="_1-各个模块分开启动-停止-配置-ssh-是前提-常用"><a href="#_1-各个模块分开启动-停止-配置-ssh-是前提-常用" class="header-anchor">#</a> 1）各个模块分开启动/停止（配置 ssh 是前提）常用</h4> <p>（1）整体启动/停止 HDFS</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>start-dfs.sh/stop-dfs.sh
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（2）整体启动/停止 YARN</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>start-yarn.sh/stop-yarn.sh
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h4 id="_2-各个服务组件逐一启动-停止"><a href="#_2-各个服务组件逐一启动-停止" class="header-anchor">#</a> 2）各个服务组件逐一启动/停止</h4> <p>（1）分别启动/停止 HDFS 组件</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>hdfs --daemon start/stop namenode/datanode/secondarynamenode
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（2）启动/停止 YARN</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>yarn --daemon start/stop  resourcemanager/nodemanager
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h3 id="_6-2-9-编写-hadoop-集群常用脚本"><a href="#_6-2-9-编写-hadoop-集群常用脚本" class="header-anchor">#</a> 6.2.9 编写 Hadoop 集群常用脚本</h3> <h4 id="_1-hadoop-集群启停脚本-包含-hdfs-yarn-historyserver-myhadoop-sh"><a href="#_1-hadoop-集群启停脚本-包含-hdfs-yarn-historyserver-myhadoop-sh" class="header-anchor">#</a> 1）Hadoop 集群启停脚本（包含 HDFS，Yarn，Historyserver）：myhadoop.sh</h4> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ cd /home/atguigu/bin
[atguigu@hadoop102 bin]$ vim myhadoop.sh
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><ul><li>输入如下内容</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>#!/bin/bash

if [ $# -lt 1 ]
then
    echo &quot;No Args Input...&quot;
    exit ;
fi

case $1 in
&quot;start&quot;)
        echo &quot; =================== 启动 hadoop集群 ===================&quot;

        echo &quot; --------------- 启动 hdfs ---------------&quot;
        ssh hadoop102 &quot;/opt/module/hadoop-3.1.3/sbin/start-dfs.sh&quot;
        echo &quot; --------------- 启动 yarn ---------------&quot;
        ssh hadoop103 &quot;/opt/module/hadoop-3.1.3/sbin/start-yarn.sh&quot;
        echo &quot; --------------- 启动 historyserver ---------------&quot;
        ssh hadoop102 &quot;/opt/module/hadoop-3.1.3/bin/mapred --daemon start historyserver&quot;
;;
&quot;stop&quot;)
        echo &quot; =================== 关闭 hadoop集群 ===================&quot;

        echo &quot; --------------- 关闭 historyserver ---------------&quot;
        ssh hadoop102 &quot;/opt/module/hadoop-3.1.3/bin/mapred --daemon stop historyserver&quot;
        echo &quot; --------------- 关闭 yarn ---------------&quot;
        ssh hadoop103 &quot;/opt/module/hadoop-3.1.3/sbin/stop-yarn.sh&quot;
        echo &quot; --------------- 关闭 hdfs ---------------&quot;
        ssh hadoop102 &quot;/opt/module/hadoop-3.1.3/sbin/stop-dfs.sh&quot;
;;
*)
    echo &quot;Input Args Error...&quot;
;;
esac
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br></div></div><h4 id="_2-查看三台服务器-java-进程脚本-jpsall"><a href="#_2-查看三台服务器-java-进程脚本-jpsall" class="header-anchor">#</a> 2）查看三台服务器 Java 进程脚本：jpsall</h4> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ cd /home/atguigu/bin
[atguigu@hadoop102 bin]$ vim jpsall
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><ul><li><p>输入如下内容</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>#!/bin/bash

for host in hadoop102 hadoop103 hadoop104
do
        echo =============== $host ===============
        ssh $host jps
done
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div></li> <li><p>保存后退出，然后赋予脚本执行权限</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 bin]$ chmod +x jpsall
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></li></ul> <h3 id="_3-分发-home-atguigu-bin-目录-保证自定义脚本在三台机器上都可以使用"><a href="#_3-分发-home-atguigu-bin-目录-保证自定义脚本在三台机器上都可以使用" class="header-anchor">#</a> 3）分发/home/atguigu/bin 目录，保证自定义脚本在三台机器上都可以使用</h3> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ xsync /home/atguigu/bin/
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h3 id="_6-2-10-常用端口号说明"><a href="#_6-2-10-常用端口号说明" class="header-anchor">#</a> 6.2.10 常用端口号说明</h3> <table><thead><tr><th>端口名称</th> <th>Hadoop2.x</th> <th>Hadoop3.x</th></tr></thead> <tbody><tr><td>NameNode 内部通信端口</td> <td>8020 / 9000</td> <td>8020 / 9000/9820</td></tr> <tr><td>NameNode HTTP UI</td> <td>50070</td> <td>9870</td></tr> <tr><td>MapReduce 查看执行任务端口</td> <td>8088</td> <td>8088</td></tr> <tr><td>历史服务器通信端口</td> <td>19888</td> <td>19888</td></tr></tbody></table> <h3 id="_6-2-11-集群时间同步"><a href="#_6-2-11-集群时间同步" class="header-anchor">#</a> 6.2.11 集群时间同步</h3> <p><strong>如果服务器在公网环境（能连接外网），可以不采用集群时间同步</strong>，因为服务器会定期和公网时间进行校准；</p> <p>如果服务器在内网环境，必须要配置集群时间同步，否则时间久了，会产生时间偏差，导致集群执行任务时间不同步。</p> <h4 id="_1-需求"><a href="#_1-需求" class="header-anchor">#</a> <strong>1）需求</strong></h4> <p>找一个机器，作为时间服务器，所有的机器与这台集群时间进行定时的同步，生产环境根据任务对时间的准确程度要求周期同步。测试环境为了尽快看到效果，采用 1 分钟同步一次。</p> <p><img src="/assets/img/image-20230705231920927.cc9bdf5b.png" alt="image-20230705231920927"></p> <h4 id="_2-时间服务器配置-必须-root-用户"><a href="#_2-时间服务器配置-必须-root-用户" class="header-anchor">#</a> 2）时间服务器配置（必须 root 用户）</h4> <p>（1）查看所有节点 ntpd 服务状态和开机自启动状态</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ sudo systemctl status ntpd
[atguigu@hadoop102 ~]$ sudo systemctl start ntpd
[atguigu@hadoop102 ~]$ sudo systemctl is-enabled ntpd
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>（2）修改 hadoop102 的 ntp.conf 配置文件</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ sudo vim /etc/ntp.conf
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>修改内容如下</p> <p>（a）修改 1（授权 192.168.10.0-192.168.10.255 网段上的所有机器可以从这台机器上查询和同步时间）</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>#restrict 192.168.10.0 mask 255.255.255.0 nomodify notrap
为restrict 192.168.10.0 mask 255.255.255.0 nomodify notrap
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>（b）修改 2（集群在局域网中，不使用其他互联网上的时间）</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>server 0.centos.pool.ntp.org iburst
server 1.centos.pool.ntp.org iburst
server 2.centos.pool.ntp.org iburst
server 3.centos.pool.ntp.org iburst
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>为</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>#server 0.centos.pool.ntp.org iburst
#server 1.centos.pool.ntp.org iburst
#server 2.centos.pool.ntp.org iburst
#server 3.centos.pool.ntp.org iburst
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>（c）添加 3（当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步）</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>server 127.127.1.0
fudge 127.127.1.0 stratum 10
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>（3）修改 hadoop102 的/etc/sysconfig/ntpd 文件</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ sudo vim /etc/sysconfig/ntpd
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>加内容如下（让硬件时间与系统时间一起同步）</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>SYNC_HWCLOCK=yes
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（4）重新启动 ntpd 服务</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ sudo systemctl start ntpd
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（5）设置 ntpd 服务开机启动</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ sudo systemctl enable ntpd
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h4 id="_3-其他机器配置-必须-root-用户"><a href="#_3-其他机器配置-必须-root-用户" class="header-anchor">#</a> 3）其他机器配置（必须 root 用户）</h4> <p>（1）关闭所有节点上 ntp 服务和自启动</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop103 ~]$ sudo systemctl stop ntpd
[atguigu@hadoop103 ~]$ sudo systemctl disable ntpd
[atguigu@hadoop104 ~]$ sudo systemctl stop ntpd
[atguigu@hadoop104 ~]$ sudo systemctl disable ntpd
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>（2）在其他机器配置 1 分钟与时间服务器同步一次</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop103 ~]$ sudo crontab -e
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>编写定时任务如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>*/1 * * * * /usr/sbin/ntpdate hadoop102
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（3）修改任意机器时间</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop103 ~]$ sudo date -s &quot;2021-9-11 11:11:11&quot;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（4）1 分钟后查看机器是否与时间服务器同步</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop103 ~]$ sudo date
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></div></div>  <div class="page-edit"><div class="edit-link"><a href="https://github.com/andanyang/vuepress-theme-vdoing/edit/master/docs/Hadoop/0003.Hadoop 运行环境搭建.md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2023/07/21, 07:56:36</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/pages/Hadoop-Concept-explanation/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">第二章大数据技术之 Hadoop概念讲解</div></a> <a href="/pages/Hadoop-working-mechanism/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">第四章Hadoop之HDFS详解以及工作机制介绍</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/pages/Hadoop-Concept-explanation/" class="prev">第二章大数据技术之 Hadoop概念讲解</a></span> <span class="next"><a href="/pages/Hadoop-working-mechanism/">第四章Hadoop之HDFS详解以及工作机制介绍</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/digitalization/DX_technology_business/"><div>
            数字化转型的核心是技术？还是业务？
            <!----></div></a> <span class="date">07-13</span></dt></dl><dl><dd>02</dd> <dt><a href="/digitalization/terms_digital_factory/"><div>
            聊聊数字化工厂的一些术语
            <!----></div></a> <span class="date">07-13</span></dt></dl><dl><dd>03</dd> <dt><a href="/digitalization/BI_underlying_logic/"><div>
            BI的底层逻辑：业务流、信息流和数据流
            <!----></div></a> <span class="date">07-13</span></dt></dl> <dl><dd></dd> <dt><a href="/archives/" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="mailto:1218853253@qq.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/andanyang" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="https://music.163.com/#/playlist?id=755597173" title="听音乐" target="_blank" class="iconfont icon-erji"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2019-2023
    <span>Young | <a href="https://github.com/andanyoung/young-blog/blob/master/LICENSE" target="_blank">MIT License</a> <br/> <a  href="https://beian.miit.gov.cn/" target="_blank">浙ICP备20002744号</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><div></div></div></div>
    <script src="/assets/js/app.6558865c.js" defer></script><script src="/assets/js/2.583df165.js" defer></script><script src="/assets/js/19.64474d57.js" defer></script>
  </body>
</html>
