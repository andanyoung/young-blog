<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Hadoop HA 高可用 | Young&#39;s blog</title>
    <meta name="generator" content="VuePress 1.9.5">
    <link rel="icon" href="/img/favicon.ico">
    <meta name="description" content="Young丶java后端技术博客,专注后端学习与总结。擅长spring boot,JAVA基础总结,等方面的知识,关注spring,架构,elasticsearch,mysql领域.">
    <meta name="keywords" content="前端博客,个人技术博客,前端,前端开发,前端框架,web前端,前端面试题,技术文档,学习,面试,JavaScript,js,ES6,TypeScript,vue,python,css3,html5,Node,git,github,markdown">
    <meta name="baidu-site-verification" content="7F55weZDDc">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/assets/css/0.styles.1cda4d67.css" as="style"><link rel="preload" href="/assets/js/app.2b0d7625.js" as="script"><link rel="preload" href="/assets/js/2.3974175a.js" as="script"><link rel="preload" href="/assets/js/26.44857563.js" as="script"><link rel="prefetch" href="/assets/js/10.e3cb156b.js"><link rel="prefetch" href="/assets/js/100.c4efc6b7.js"><link rel="prefetch" href="/assets/js/101.da9e13a9.js"><link rel="prefetch" href="/assets/js/102.94d39313.js"><link rel="prefetch" href="/assets/js/103.dfc98dbb.js"><link rel="prefetch" href="/assets/js/104.6239091b.js"><link rel="prefetch" href="/assets/js/105.b3673428.js"><link rel="prefetch" href="/assets/js/106.eb0a493f.js"><link rel="prefetch" href="/assets/js/107.431a18a7.js"><link rel="prefetch" href="/assets/js/108.d5f65612.js"><link rel="prefetch" href="/assets/js/109.6b218057.js"><link rel="prefetch" href="/assets/js/11.ba6c0911.js"><link rel="prefetch" href="/assets/js/110.01b2ef71.js"><link rel="prefetch" href="/assets/js/111.65a62400.js"><link rel="prefetch" href="/assets/js/112.6529143f.js"><link rel="prefetch" href="/assets/js/113.d62e05ec.js"><link rel="prefetch" href="/assets/js/114.bd837623.js"><link rel="prefetch" href="/assets/js/115.9a5700b5.js"><link rel="prefetch" href="/assets/js/116.e318f292.js"><link rel="prefetch" href="/assets/js/117.cc2bff28.js"><link rel="prefetch" href="/assets/js/118.5f23f86a.js"><link rel="prefetch" href="/assets/js/119.65f75914.js"><link rel="prefetch" href="/assets/js/12.440a1c78.js"><link rel="prefetch" href="/assets/js/120.bb3039e0.js"><link rel="prefetch" href="/assets/js/121.0e8a661a.js"><link rel="prefetch" href="/assets/js/122.6692f21f.js"><link rel="prefetch" href="/assets/js/123.b9026ff5.js"><link rel="prefetch" href="/assets/js/124.acb726c3.js"><link rel="prefetch" href="/assets/js/125.fb7c8a8d.js"><link rel="prefetch" href="/assets/js/126.9bfa33ad.js"><link rel="prefetch" href="/assets/js/127.a0329a29.js"><link rel="prefetch" href="/assets/js/128.c9f35ad6.js"><link rel="prefetch" href="/assets/js/129.ea27b329.js"><link rel="prefetch" href="/assets/js/13.c9a84088.js"><link rel="prefetch" href="/assets/js/130.f2940479.js"><link rel="prefetch" href="/assets/js/131.6b891366.js"><link rel="prefetch" href="/assets/js/132.b3545b61.js"><link rel="prefetch" href="/assets/js/133.3e72f102.js"><link rel="prefetch" href="/assets/js/134.d0c25d72.js"><link rel="prefetch" href="/assets/js/135.12a96cb4.js"><link rel="prefetch" href="/assets/js/136.5741869b.js"><link rel="prefetch" href="/assets/js/137.b3646569.js"><link rel="prefetch" href="/assets/js/138.2c06db28.js"><link rel="prefetch" href="/assets/js/139.86f88fba.js"><link rel="prefetch" href="/assets/js/14.d3b20ec5.js"><link rel="prefetch" href="/assets/js/140.2da46410.js"><link rel="prefetch" href="/assets/js/141.f4a2c912.js"><link rel="prefetch" href="/assets/js/142.19e7be2b.js"><link rel="prefetch" href="/assets/js/143.e6b5930e.js"><link rel="prefetch" href="/assets/js/144.973070e0.js"><link rel="prefetch" href="/assets/js/145.66d56e15.js"><link rel="prefetch" href="/assets/js/146.fe9e7002.js"><link rel="prefetch" href="/assets/js/147.5f46c6d1.js"><link rel="prefetch" href="/assets/js/148.854881c4.js"><link rel="prefetch" href="/assets/js/149.19ebb6a7.js"><link rel="prefetch" href="/assets/js/15.e2ddfb63.js"><link rel="prefetch" href="/assets/js/150.70616ebe.js"><link rel="prefetch" href="/assets/js/151.6399ffcd.js"><link rel="prefetch" href="/assets/js/152.c6ec5b9c.js"><link rel="prefetch" href="/assets/js/153.b07bb9d1.js"><link rel="prefetch" href="/assets/js/154.bc4c8e11.js"><link rel="prefetch" href="/assets/js/155.dbe61e45.js"><link rel="prefetch" href="/assets/js/156.15fc392e.js"><link rel="prefetch" href="/assets/js/157.72d9e547.js"><link rel="prefetch" href="/assets/js/158.d4ef66d9.js"><link rel="prefetch" href="/assets/js/159.68542aea.js"><link rel="prefetch" href="/assets/js/16.23cda74f.js"><link rel="prefetch" href="/assets/js/160.7f396b21.js"><link rel="prefetch" href="/assets/js/161.b47856a3.js"><link rel="prefetch" href="/assets/js/162.871b011d.js"><link rel="prefetch" href="/assets/js/163.32abf5ab.js"><link rel="prefetch" href="/assets/js/164.13f0ab91.js"><link rel="prefetch" href="/assets/js/165.71571fd1.js"><link rel="prefetch" href="/assets/js/166.9913199e.js"><link rel="prefetch" href="/assets/js/167.8f7d8421.js"><link rel="prefetch" href="/assets/js/168.505d9e47.js"><link rel="prefetch" href="/assets/js/169.4f346816.js"><link rel="prefetch" href="/assets/js/17.6f5c9214.js"><link rel="prefetch" href="/assets/js/170.5de3e4fd.js"><link rel="prefetch" href="/assets/js/171.b3741ab7.js"><link rel="prefetch" href="/assets/js/172.c78c2f8e.js"><link rel="prefetch" href="/assets/js/18.80cfbede.js"><link rel="prefetch" href="/assets/js/19.04f4ff92.js"><link rel="prefetch" href="/assets/js/20.0c51a5af.js"><link rel="prefetch" href="/assets/js/21.fdd12c13.js"><link rel="prefetch" href="/assets/js/22.84bf6a76.js"><link rel="prefetch" href="/assets/js/23.2322b9cb.js"><link rel="prefetch" href="/assets/js/24.978b8abe.js"><link rel="prefetch" href="/assets/js/25.d01c7571.js"><link rel="prefetch" href="/assets/js/27.b1666a4e.js"><link rel="prefetch" href="/assets/js/28.fe2e9c9d.js"><link rel="prefetch" href="/assets/js/29.fd2540e8.js"><link rel="prefetch" href="/assets/js/3.c6324e24.js"><link rel="prefetch" href="/assets/js/30.e46d0f32.js"><link rel="prefetch" href="/assets/js/31.e3ca9031.js"><link rel="prefetch" href="/assets/js/32.86f48cbe.js"><link rel="prefetch" href="/assets/js/33.f0e54135.js"><link rel="prefetch" href="/assets/js/34.26bdb6be.js"><link rel="prefetch" href="/assets/js/35.75ad5634.js"><link rel="prefetch" href="/assets/js/36.7a470040.js"><link rel="prefetch" href="/assets/js/37.34fd42ce.js"><link rel="prefetch" href="/assets/js/38.85c1b315.js"><link rel="prefetch" href="/assets/js/39.eb5d2cf5.js"><link rel="prefetch" href="/assets/js/4.5439b998.js"><link rel="prefetch" href="/assets/js/40.579ff10b.js"><link rel="prefetch" href="/assets/js/41.136928e5.js"><link rel="prefetch" href="/assets/js/42.e8e2bd30.js"><link rel="prefetch" href="/assets/js/43.9acdb787.js"><link rel="prefetch" href="/assets/js/44.c34897d6.js"><link rel="prefetch" href="/assets/js/45.1c62d72f.js"><link rel="prefetch" href="/assets/js/46.65f576a1.js"><link rel="prefetch" href="/assets/js/47.1a2e0155.js"><link rel="prefetch" href="/assets/js/48.aef46f65.js"><link rel="prefetch" href="/assets/js/49.afcea455.js"><link rel="prefetch" href="/assets/js/5.601edac7.js"><link rel="prefetch" href="/assets/js/50.8613b753.js"><link rel="prefetch" href="/assets/js/51.2a3ba853.js"><link rel="prefetch" href="/assets/js/52.32d91aac.js"><link rel="prefetch" href="/assets/js/53.6294def6.js"><link rel="prefetch" href="/assets/js/54.6397814a.js"><link rel="prefetch" href="/assets/js/55.c96eff3c.js"><link rel="prefetch" href="/assets/js/56.de5d0c05.js"><link rel="prefetch" href="/assets/js/57.97507c26.js"><link rel="prefetch" href="/assets/js/58.4bbbca6e.js"><link rel="prefetch" href="/assets/js/59.bb097816.js"><link rel="prefetch" href="/assets/js/6.9a9bce76.js"><link rel="prefetch" href="/assets/js/60.fe6ea46f.js"><link rel="prefetch" href="/assets/js/61.14d92fe9.js"><link rel="prefetch" href="/assets/js/62.63908200.js"><link rel="prefetch" href="/assets/js/63.96f3a75c.js"><link rel="prefetch" href="/assets/js/64.09e08987.js"><link rel="prefetch" href="/assets/js/65.4679fdd2.js"><link rel="prefetch" href="/assets/js/66.a7716039.js"><link rel="prefetch" href="/assets/js/67.7fbc5bff.js"><link rel="prefetch" href="/assets/js/68.6ce79e6a.js"><link rel="prefetch" href="/assets/js/69.867131d7.js"><link rel="prefetch" href="/assets/js/7.d4bb59db.js"><link rel="prefetch" href="/assets/js/70.af30d96f.js"><link rel="prefetch" href="/assets/js/71.5eb6cef3.js"><link rel="prefetch" href="/assets/js/72.a117a7ba.js"><link rel="prefetch" href="/assets/js/73.93020299.js"><link rel="prefetch" href="/assets/js/74.d15d41ff.js"><link rel="prefetch" href="/assets/js/75.0600aea2.js"><link rel="prefetch" href="/assets/js/76.f8855ea3.js"><link rel="prefetch" href="/assets/js/77.8e37f355.js"><link rel="prefetch" href="/assets/js/78.b2bdb73e.js"><link rel="prefetch" href="/assets/js/79.cef95aba.js"><link rel="prefetch" href="/assets/js/8.7d1cc855.js"><link rel="prefetch" href="/assets/js/80.01183f72.js"><link rel="prefetch" href="/assets/js/81.227259ad.js"><link rel="prefetch" href="/assets/js/82.f923dd45.js"><link rel="prefetch" href="/assets/js/83.206302b3.js"><link rel="prefetch" href="/assets/js/84.6970eb38.js"><link rel="prefetch" href="/assets/js/85.a950a1ec.js"><link rel="prefetch" href="/assets/js/86.2837338f.js"><link rel="prefetch" href="/assets/js/87.85cd5415.js"><link rel="prefetch" href="/assets/js/88.861d785d.js"><link rel="prefetch" href="/assets/js/89.58b7803d.js"><link rel="prefetch" href="/assets/js/9.284cd5e9.js"><link rel="prefetch" href="/assets/js/90.b3511130.js"><link rel="prefetch" href="/assets/js/91.d02e7f2a.js"><link rel="prefetch" href="/assets/js/92.5cdfecbc.js"><link rel="prefetch" href="/assets/js/93.02face78.js"><link rel="prefetch" href="/assets/js/94.254c282e.js"><link rel="prefetch" href="/assets/js/95.015ffd17.js"><link rel="prefetch" href="/assets/js/96.095b6b3c.js"><link rel="prefetch" href="/assets/js/97.9be64377.js"><link rel="prefetch" href="/assets/js/98.31e60fc6.js"><link rel="prefetch" href="/assets/js/99.8c1af265.js">
    <link rel="stylesheet" href="/assets/css/0.styles.1cda4d67.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/img/logo.png" alt="Young's blog" class="logo"> <span class="site-name can-hide">Young's blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/Spring/" class="nav-link">Spring</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="前端" class="dropdown-title"><a href="/web/" class="link-title">前端</a> <span class="title" style="display:none;">前端</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>前端文章1</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/8143cc480faf9a11/" class="nav-link">JavaScript</a></li></ul></li><li class="dropdown-item"><h4>学习笔记</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/note/javascript/" class="nav-link">《JavaScript教程》</a></li><li class="dropdown-subitem"><a href="/note/js/" class="nav-link">《JavaScript高级程序设计》</a></li><li class="dropdown-subitem"><a href="/note/es6/" class="nav-link">《ES6 教程》</a></li><li class="dropdown-subitem"><a href="/note/vue/" class="nav-link">《Vue》</a></li><li class="dropdown-subitem"><a href="/note/react/" class="nav-link">《React》</a></li><li class="dropdown-subitem"><a href="/note/typescript-axios/" class="nav-link">《TypeScript 从零实现 axios》</a></li><li class="dropdown-subitem"><a href="/note/git/" class="nav-link">《Git》</a></li><li class="dropdown-subitem"><a href="/pages/51afd6/" class="nav-link">TypeScript</a></li><li class="dropdown-subitem"><a href="/pages/4643cd/" class="nav-link">JS设计模式总结</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="页面" class="dropdown-title"><a href="/ui/" class="link-title">页面</a> <span class="title" style="display:none;">页面</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/8309a5b876fc95e3/" class="nav-link">HTML</a></li><li class="dropdown-item"><!----> <a href="/pages/0a83b083bdf257cb/" class="nav-link">CSS</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="技术" class="dropdown-title"><a href="/technology/" class="link-title">技术</a> <span class="title" style="display:none;">技术</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/9a7ee40fc232253e/" class="nav-link">技术文档</a></li><li class="dropdown-item"><!----> <a href="/pages/4c778760be26d8b3/" class="nav-link">GitHub技巧</a></li><li class="dropdown-item"><!----> <a href="/pages/117708e0af7f0bd9/" class="nav-link">Nodejs</a></li><li class="dropdown-item"><!----> <a href="/pages/41f87d890d0a02af/" class="nav-link">博客搭建</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="更多" class="dropdown-title"><a href="/more/" class="link-title">更多</a> <span class="title" style="display:none;">更多</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/f2a556/" class="nav-link">学习</a></li><li class="dropdown-item"><!----> <a href="/pages/aea6571b7a8bae86/" class="nav-link">面试</a></li><li class="dropdown-item"><!----> <a href="/pages/2d615df9a36a98ed/" class="nav-link">心情杂货</a></li><li class="dropdown-item"><!----> <a href="/pages/baaa02/" class="nav-link">实用技巧</a></li><li class="dropdown-item"><!----> <a href="/friends/" class="nav-link">友情链接</a></li></ul></div></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><a href="/pages/beb6c0bd8a66cea6/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/andanyang/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="/img/logo.png"> <div class="blogger-info"><h3>Young</h3> <span></span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/Spring/" class="nav-link">Spring</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="前端" class="dropdown-title"><a href="/web/" class="link-title">前端</a> <span class="title" style="display:none;">前端</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>前端文章1</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/8143cc480faf9a11/" class="nav-link">JavaScript</a></li></ul></li><li class="dropdown-item"><h4>学习笔记</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/note/javascript/" class="nav-link">《JavaScript教程》</a></li><li class="dropdown-subitem"><a href="/note/js/" class="nav-link">《JavaScript高级程序设计》</a></li><li class="dropdown-subitem"><a href="/note/es6/" class="nav-link">《ES6 教程》</a></li><li class="dropdown-subitem"><a href="/note/vue/" class="nav-link">《Vue》</a></li><li class="dropdown-subitem"><a href="/note/react/" class="nav-link">《React》</a></li><li class="dropdown-subitem"><a href="/note/typescript-axios/" class="nav-link">《TypeScript 从零实现 axios》</a></li><li class="dropdown-subitem"><a href="/note/git/" class="nav-link">《Git》</a></li><li class="dropdown-subitem"><a href="/pages/51afd6/" class="nav-link">TypeScript</a></li><li class="dropdown-subitem"><a href="/pages/4643cd/" class="nav-link">JS设计模式总结</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="页面" class="dropdown-title"><a href="/ui/" class="link-title">页面</a> <span class="title" style="display:none;">页面</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/8309a5b876fc95e3/" class="nav-link">HTML</a></li><li class="dropdown-item"><!----> <a href="/pages/0a83b083bdf257cb/" class="nav-link">CSS</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="技术" class="dropdown-title"><a href="/technology/" class="link-title">技术</a> <span class="title" style="display:none;">技术</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/9a7ee40fc232253e/" class="nav-link">技术文档</a></li><li class="dropdown-item"><!----> <a href="/pages/4c778760be26d8b3/" class="nav-link">GitHub技巧</a></li><li class="dropdown-item"><!----> <a href="/pages/117708e0af7f0bd9/" class="nav-link">Nodejs</a></li><li class="dropdown-item"><!----> <a href="/pages/41f87d890d0a02af/" class="nav-link">博客搭建</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="更多" class="dropdown-title"><a href="/more/" class="link-title">更多</a> <span class="title" style="display:none;">更多</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/f2a556/" class="nav-link">学习</a></li><li class="dropdown-item"><!----> <a href="/pages/aea6571b7a8bae86/" class="nav-link">面试</a></li><li class="dropdown-item"><!----> <a href="/pages/2d615df9a36a98ed/" class="nav-link">心情杂货</a></li><li class="dropdown-item"><!----> <a href="/pages/baaa02/" class="nav-link">实用技巧</a></li><li class="dropdown-item"><!----> <a href="/friends/" class="nav-link">友情链接</a></li></ul></div></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div><div class="nav-item"><a href="/pages/beb6c0bd8a66cea6/" class="nav-link">收藏</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div> <a href="https://github.com/andanyang/vuepress-theme-vdoing" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><a href="/Hadoop/bigdata-generality/" class="sidebar-link">第一章 大数据技术之大数据概论</a></li><li><a href="/Hadoop/Hadoop-Concept-explanation/" class="sidebar-link">第二章大数据技术之 Hadoop概念讲解</a></li><li><a href="/Hadoop/Build-Hadoop-running-environment/" class="sidebar-link">第三章Hadoop 运行环境搭建</a></li><li><a href="/Hadoop/Hadoop-working-mechanism/" class="sidebar-link">第四章Hadoop之HDFS详解以及工作机制介绍</a></li><li><a href="/Hadoop/haddop-MapReduce/" class="sidebar-link">第五章MapReduce编程框架</a></li><li><a href="/Hadoop/data_compression/" class="sidebar-link">第六章Hadoop 数据压缩</a></li><li><a href="/Hadoop/Yarn/" class="sidebar-link">第七章大数据技术之 Hadoop（Yarn）</a></li><li><a href="/Hadoop/Production_tuning_manual/" class="sidebar-link">第八章Hadoop（生产调优手册）</a></li><li><a href="/Hadoop/HA/" aria-current="page" class="active sidebar-link">Hadoop HA 高可用</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/Hadoop/HA/#_1-ha-概述" class="sidebar-link">1. HA 概述</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/HA/#_2-hdfs-ha-集群搭建" class="sidebar-link">2.  HDFS-HA 集群搭建</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/Hadoop/HA/#_2-1-hdfs-ha-核心问题" class="sidebar-link">2.1 HDFS-HA 核心问题</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/Hadoop/HA/#_3-hdfs-ha-手动模式" class="sidebar-link">3 HDFS-HA 手动模式</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/Hadoop/HA/#_3-1-环境准备" class="sidebar-link">3.1 环境准备</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/HA/#_3-2-规划集群" class="sidebar-link">3.2 规划集群</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/HA/#_3-3-配置-hdfs-ha-集群" class="sidebar-link">3.3 配置 HDFS-HA 集群</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/HA/#_3-4-启动-hdfs-ha-集群" class="sidebar-link">3.4 启动 HDFS-HA 集群</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/Hadoop/HA/#_4-hdfs-ha-自动模式" class="sidebar-link">4 HDFS-HA 自动模式</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/Hadoop/HA/#_4-1-hdfs-ha-自动故障转移工作机制" class="sidebar-link">4.1 HDFS-HA 自动故障转移工作机制</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/HA/#_4-2-hdfs-ha-自动故障转移的集群规划" class="sidebar-link">4.2 HDFS-HA 自动故障转移的集群规划</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/HA/#_4-3-配置-hdfs-ha-自动故障转移" class="sidebar-link">4.3 配置 HDFS-HA 自动故障转移</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/HA/#_1-具体配置" class="sidebar-link">1）具体配置</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/HA/#_2-启动" class="sidebar-link">2）启动</a></li><li class="sidebar-sub-header level4"><a href="/Hadoop/HA/#_3-验证" class="sidebar-link">3）验证</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/HA/#_4-4-hdfs-ha-自动故障转移-客户端如何配置-namenode-的ip" class="sidebar-link">4.4 HDFS-HA 自动故障转移 客户端如何配置 namenode 的ip</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/HA/#_4-5-zookeeper-failover-controller-zkfc" class="sidebar-link">4.5 ZooKeeper failover controller（ZKFC）</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/Hadoop/HA/#_5-1-yarn-ha-工作机制" class="sidebar-link">5.1 YARN-HA 工作机制</a></li><li class="sidebar-sub-header level2"><a href="/Hadoop/HA/#_5-2-配置-yarn-ha-集群" class="sidebar-link">5.2 配置 YARN-HA 集群</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/Hadoop/HA/#_1-环境准备" class="sidebar-link">1）环境准备</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/HA/#_2-规划集群" class="sidebar-link">2）规划集群</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/HA/#_3-核心问题" class="sidebar-link">3）核心问题</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/HA/#_4-具体配置" class="sidebar-link">4）具体配置</a></li><li class="sidebar-sub-header level3"><a href="/Hadoop/HA/#_5-启动-yarn" class="sidebar-link">5）启动 YARN</a></li></ul></li></ul></li><li><a href="/Hadoop/windows10_build/" class="sidebar-link">hadoop 3.x 在windows10下编译</a></li><li><a href="/Hadoop/DataNode_RUN_FAIL/" class="sidebar-link">hadoop 踩坑记 DataNode 启动失败(ClusterID不一致)：Initialization failed for Block pool</a></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/categories/?category=Hadoop" title="分类" data-v-06225672>Hadoop</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/andanyoung" target="_blank" title="作者" class="beLink" data-v-06225672>andanyang</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2022-06-20</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABH1JREFUSA3tVl1oHFUUPmdmd2ltklqbpJDiNnXFmgbFktho7YMPNiJSSZM0+CAYSkUELVhM6YuwIPpgoOKDqOBDC0XE2CQoNtQXBUFTTcCi+Wlh1V2TQExsUzcltd3M9Tt3ZjZzZ2fT+OJTL8yeM+eee757fmeJbq//KQL8X3DUSFOcfr7cRsRtxNQMWueeVzOkaITIGqQHNg5y8+jNW9ldM7A6nTpAjuolUikAwq7CE3WcM2RRDz+XGVgN3FptU/aUSlvq9Pa3iZ1+sgAqJyyAFqkipd9dqiwHF3P65YycLWc/6sqGrvoEoIp6DOFaX5h6+dnfjkWprwqsPk0dUGq5vySwDImC10KxFHgGL1SWoc92O3eVht09qdXNH11I2SsTsJYqMWzihqGMi+A+Garf3BAuuLI5oGlULyNfyB/HYNujwktOfRrMr5t77NmevqaUopx0grnKAyvVpmwUDB4x6FPXuGvYLTDwWsejwgtgkYKPqRJg8SV6xaiZ3ZTppGneS4yfH5/66fZSDHv+QZci/+h5c5UHtpy67JUqGppM0sh0Nc1dW6/N1W5Yoqat8/TU/VnadmdeW2PLLSyh0cvxBs3KbqTmwYPpxN4do/mzE8nEpvX/UMu2Wbp74zUAK5q6WkHns7V0eWkdPbPzd3rxkTGybadYySumVzhcaJFbs5UrEkQ/+CK8gF5dnh/6ciIZ73gwQ927L1IitoxKLXYP3SjYdOrHHfTZhRRlFyrorafPk20B3HPD1y2G3qKZME5Jcf3t/HUC13/8tSd++vqFveMUTwAUxSUFI1QekR1+bIze3D9MF2aq6cPvG72CgnldWCFqyRw3lwH8ZMerjTD9ElRO7Gv44wNpC90aASqGfVlz/Rx17srQ57/UU26hkhQqUB7dBR71WmzQhHUnblGmVOEw0jhbV1n9OlXUDCIRGaNV5Jp43N516fN7JmnTHdfp7Hgy0luO4aMhtkLL8Bi3bUWYvzh5Mn1dTxrL6QmGuRhGL/TiTTxRoEdTszSaq9GR0NGA3KdkOz3hqSV3MIDhQ5IVX/Ivx3umBti2es2h4eZby7x8br1rkf7Mo90AqC8aQ3sJeNzqFRu+vSANAQe3PL7l0HGOAdwDCeZYvNKeoZp1Qfs6Aipndh86HmFRi0LAnEO47wsqM6cdfjh3jBPUzhZy7nvlUfFsamED1VQt6aISHVymXZ/B2aCtIG8AI8xfobj2d3en1wWVhOeHELKmLQ1s211s88comkv4UCwWyF787mJdYXtNfhKAXVqnKTq8QZvGAGGOfaTo5pGZ/PwbUCr5+DPr/1J92JNHr9aOl/F3iI5+O1nfybsGxoimvZ3ViWSluDITw3P37mypheDIPY0tw7+O/5ApbkYw+zpfaUVu32Pi98+defdUhEpZkRFq0aqyNh9FuL9hpYbEm6iwi0z2REd09ZmyENEbuhjDWzKvZXTqKYaBIr3tt5kuPtQBZFvEUwHt60vfCNu41XsksH9Ij1BMMz1Y0OOunHNShFIP5868g5zeXmuLwL9T4b6Q2+KejgAAAABJRU5ErkJggg==">Hadoop HA 高可用<!----></h1>  <div class="theme-vdoing-content content__default"><h1 id="hadoop-ha-高可用"><a href="#hadoop-ha-高可用" class="header-anchor">#</a> Hadoop HA 高可用</h1> <blockquote><p>参考[<a href="https://hadoop.apache.org/docs/r3.3.6/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html" target="_blank" rel="noopener noreferrer">NameNode HA With QJM<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>]</p> <p>NFS 方式 [<a href="https://hadoop.apache.org/docs/r3.3.6/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithNFS.html" target="_blank" rel="noopener noreferrer">NFS的命名节点HA<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a>]</p></blockquote> <h2 id="_1-ha-概述"><a href="#_1-ha-概述" class="header-anchor">#</a> 1. HA 概述</h2> <p>（1）所谓 HA（High Availablity），即高可用（7*24 小时不中断服务）。</p> <p>（2）实现高可用最关键的策略是消除单点故障。HA 严格来说应该分成各个组件的 HA 机制：HDFS 的 HA 和 YARN 的 HA。</p> <p>（3）NameNode 主要在以下两个方面影响 HDFS 集群</p> <p>➢ NameNode 机器发生意外，如宕机，集群将无法使用，直到管理员重启</p> <p>➢ NameNode 机器需要升级，包括软件、硬件升级，此时集群也将无法使用</p> <p>HDFS HA 功能通过配置多个 NameNodes(Active/Standby)实现在集群中对 NameNode 的热备来解决上述问题。如果出现故障，如机器崩溃或机器需要升级维护，这时可通过此种方式将 NameNode 很快的切换到另外一台机器。</p> <h2 id="_2-hdfs-ha-集群搭建"><a href="#_2-hdfs-ha-集群搭建" class="header-anchor">#</a> 2.  HDFS-HA 集群搭建</h2> <p>当前 HDFS 集群的规划</p> <p><img src="/assets/img/image-20230905153634847.669a5db0.png" alt="image-20230905153634847"></p> <p>HA 的主要目的是消除 namenode 的单点故障,需要将 hdfs 集群规划成以下模样</p> <p><img src="/assets/img/image-20230905153657185.63d660a8.png" alt="image-20230905153657185"></p> <h3 id="_2-1-hdfs-ha-核心问题"><a href="#_2-1-hdfs-ha-核心问题" class="header-anchor">#</a> 2.1 HDFS-HA 核心问题</h3> <p>1）怎么保证三台 namenode 的数据一致</p> <ul><li><p>a. Fsimage:让一台 nn 生成数据,让其他机器 nn 同步</p></li> <li><p>b. Edits:需要引进新的模块 JournalNode 来保证 edtis 的文件的数据一致性</p></li></ul> <p>2）怎么让同时只有一台 nn 是 active，其他所有是 standby 的</p> <ul><li>a.手动分配</li> <li>b.自动分配</li></ul> <p>3）2nn 在 ha 架构中并不存在，定期合并 fsimage 和 edtis 的活谁来</p> <ul><li>由 standby 的 nn 来干</li></ul> <p>4）如果 nn 真的发生了问题，怎么让其他的 nn 上位干活</p> <ul><li>a.手动故障转移</li> <li>b.自动故障转移</li></ul> <h2 id="_3-hdfs-ha-手动模式"><a href="#_3-hdfs-ha-手动模式" class="header-anchor">#</a> 3 HDFS-HA 手动模式</h2> <h3 id="_3-1-环境准备"><a href="#_3-1-环境准备" class="header-anchor">#</a> 3.1 环境准备</h3> <p>（1）修改 IP</p> <p>（2）修改主机名及主机名和 IP 地址的映射</p> <p>（3）关闭防火墙</p> <p>（4）ssh 免密登录</p> <p>（5）安装 JDK，配置环境变量等</p> <h3 id="_3-2-规划集群"><a href="#_3-2-规划集群" class="header-anchor">#</a> 3.2 规划集群</h3> <p><img src="/assets/img/image-20230905153935080.d4f61e3d.png" alt="image-20230905153935080"></p> <h3 id="_3-3-配置-hdfs-ha-集群"><a href="#_3-3-配置-hdfs-ha-集群" class="header-anchor">#</a> 3.3 配置 HDFS-HA 集群</h3> <p>1）官方地址：http://hadoop.apache.org/</p> <p>2）在 opt 目录下创建一个 ha 文件夹</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ cd /opt
[atguigu@hadoop102 opt]$ sudo mkdir ha
[atguigu@hadoop102 opt]$ sudo chown atguigu:atguigu /opt/ha
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>3）将/opt/module/下的 hadoop-3.1.3 拷贝到/opt/ha 目录下（记得删除 data 和 log 目录）</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 opt]$ cp -r /opt/module/hadoop-3.1.3 /opt/ha/
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>4）配置 core-site.xml</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;configuration&gt;
    &lt;!-- 把多个 NameNode 的地址组装成一个集群 mycluster --&gt;
     &lt;property&gt;
         &lt;name&gt;fs.defaultFS&lt;/name&gt;
         &lt;value&gt;hdfs://mycluster&lt;/value&gt;
     &lt;/property&gt;
    &lt;!-- 指定 hadoop 运行时产生文件的存储目录 --&gt;
     &lt;property&gt;
         &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
         &lt;value&gt;/opt/ha/hadoop-3.1.3/data&lt;/value&gt;
     &lt;/property&gt;
&lt;/configuration&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br></div></div><p>5）配置 hdfs-site.xml</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;configuration&gt;
    &lt;!-- NameNode 数据存储目录 --&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
         &lt;value&gt;file://${hadoop.tmp.dir}/name&lt;/value&gt;
     &lt;/property&gt;
    &lt;!-- DataNode 数据存储目录 --&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
         &lt;value&gt;file://${hadoop.tmp.dir}/data&lt;/value&gt;
     &lt;/property&gt;
    &lt;!-- JournalNode 数据存储目录 --&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;
         &lt;value&gt;${hadoop.tmp.dir}/jn&lt;/value&gt;
     &lt;/property&gt;
    &lt;!-- 完全分布式集群名称 --&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.nameservices&lt;/name&gt;
         &lt;value&gt;mycluster&lt;/value&gt;
     &lt;/property&gt;
    &lt;!-- 集群中 NameNode 节点都有哪些 --&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt;
         &lt;value&gt;nn1,nn2,nn3&lt;/value&gt;
     &lt;/property&gt;
    &lt;!-- NameNode 的 RPC 通信地址 --&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;/name&gt;
         &lt;value&gt;hadoop102:8020&lt;/value&gt;
     &lt;/property&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;/name&gt;
         &lt;value&gt;hadoop103:8020&lt;/value&gt;
     &lt;/property&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn3&lt;/name&gt;
         &lt;value&gt;hadoop104:8020&lt;/value&gt;
     &lt;/property&gt;
    &lt;!-- NameNode 的 http 通信地址 --&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.namenode.http-address.mycluster.nn1&lt;/name&gt;
         &lt;value&gt;hadoop102:9870&lt;/value&gt;
     &lt;/property&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.namenode.http-address.mycluster.nn2&lt;/name&gt;
         &lt;value&gt;hadoop103:9870&lt;/value&gt;
     &lt;/property&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.namenode.http-address.mycluster.nn3&lt;/name&gt;
         &lt;value&gt;hadoop104:9870&lt;/value&gt;
     &lt;/property&gt;
    &lt;!-- 指定 NameNode 元数据在 JournalNode 上的存放位置 --&gt;
     &lt;property&gt;
        &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;
        &lt;value&gt;qjournal://hadoop102:8485;hadoop103:8485;hadoop104:8485/myclus
    	ter&lt;/value&gt;
     &lt;/property&gt;
    &lt;!-- 访问代理类：client 用于确定哪个 NameNode 为 Active --&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt;
         &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;
     &lt;/property&gt;
    &lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;
         &lt;value&gt;sshfence&lt;/value&gt;
     &lt;/property&gt;
    &lt;!-- 使用隔离机制时需要 ssh 秘钥登录--&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;
         &lt;value&gt;/home/atguigu/.ssh/id_rsa&lt;/value&gt;
     &lt;/property&gt;
&lt;/configuration&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br></div></div><p>6）分发配置好的 hadoop 环境到其他节点</p> <h3 id="_3-4-启动-hdfs-ha-集群"><a href="#_3-4-启动-hdfs-ha-集群" class="header-anchor">#</a> 3.4 启动 HDFS-HA 集群</h3> <p><strong>1）将 HADOOP_HOME 环境变量更改到 HA 目录(三台机器)</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ sudo vim /etc/profile.d/my_env.sh
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>将 HADOOP_HOME 部分改为如下</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>#HADOOP_HOME
export HADOOP_HOME=/opt/ha/hadoop-3.1.3
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p>去三台机器上 source 环境变量</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>atguigu@hadoop102 ~]$source /etc/profile
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>2）在各个 JournalNode 节点上，输入以下命令启动 journalnode 服务</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ hdfs --daemon start journalnode
[atguigu@hadoop103 ~]$ hdfs --daemon start journalnode
[atguigu@hadoop104 ~]$ hdfs --daemon start journalnode
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>3）在[nn1]上，对其进行格式化，并启动</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ hdfs namenode -format
[atguigu@hadoop102 ~]$ hdfs --daemon start namenode
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>4）在[nn2]和[nn3]上，同步 nn1 的元数据信息</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop103 ~]$ hdfs namenode -bootstrapStandby
[atguigu@hadoop104 ~]$ hdfs namenode -bootstrapStandby
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>5）启动[nn2]和[nn3]</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop103 ~]$ hdfs --daemon start namenode
[atguigu@hadoop104 ~]$ hdfs --daemon start namenode
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>6）查看 web 页面显示</p> <p><img src="/assets/img/image-20230905154655698.1f0441cb.png" alt="图 hadoop102(standby)"></p> <p><img src="/assets/img/image-20230905154713712.9e170336.png" alt="image-20230905154713712"></p> <p><img src="/assets/img/image-20230905154723872.1941dfb5.png" alt="image-20230905154723872"></p> <p>7）在所有节点上，启动 datanode</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ hdfs --daemon start datanode
[atguigu@hadoop103 ~]$ hdfs --daemon start datanode
[atguigu@hadoop104 ~]$ hdfs --daemon start datanode
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>8）将[nn1]切换为 Active</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ hdfs haadmin -transitionToActive nn1
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>9）查看是否 Active</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ hdfs haadmin -getServiceState nn1
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h2 id="_4-hdfs-ha-自动模式"><a href="#_4-hdfs-ha-自动模式" class="header-anchor">#</a> 4 HDFS-HA 自动模式</h2> <h3 id="_4-1-hdfs-ha-自动故障转移工作机制"><a href="#_4-1-hdfs-ha-自动故障转移工作机制" class="header-anchor">#</a> 4.1 HDFS-HA 自动故障转移工作机制</h3> <p>自动故障转移为 HDFS 部署增加了两个新组件：ZooKeeper 和 ZKFailoverController （ZKFC）进程，如图所示。ZooKeeper 是维护少量协调数据，通知客户端这些数据的改变 和监视客户端故障的高可用服务。</p> <p><img src="/assets/img/image-20230905154926719.605ea6dc.png" alt="image-20230905154926719"></p> <h3 id="_4-2-hdfs-ha-自动故障转移的集群规划"><a href="#_4-2-hdfs-ha-自动故障转移的集群规划" class="header-anchor">#</a> 4.2 HDFS-HA 自动故障转移的集群规划</h3> <p><img src="/assets/img/image-20230905155156458.407e747e.png" alt="image-20230905155156458"></p> <h3 id="_4-3-配置-hdfs-ha-自动故障转移"><a href="#_4-3-配置-hdfs-ha-自动故障转移" class="header-anchor">#</a> 4.3 配置 HDFS-HA 自动故障转移</h3> <h4 id="_1-具体配置"><a href="#_1-具体配置" class="header-anchor">#</a> 1）具体配置</h4> <p>（1）在 hdfs-site.xml 中增加</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;!-- 启用 nn 故障自动转移 --&gt;
&lt;property&gt;
    &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>（2）在 core-site.xml 文件中增加</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;!-- 指定 zkfc 要连接的 zkServer 地址 --&gt;
&lt;property&gt;
    &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;
    &lt;value&gt;hadoop102:2181,hadoop103:2181,hadoop104:2181&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>（3）修改后分发配置文件</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 etc]$ pwd
/opt/ha/hadoop-3.1.3/etc
[atguigu@hadoop102 etc]$ xsync hadoop/
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><h4 id="_2-启动"><a href="#_2-启动" class="header-anchor">#</a> 2）启动</h4> <p>（1）关闭所有 HDFS 服务：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ stop-dfs.sh
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（2）启动 Zookeeper 集群：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ zkServer.sh start
[atguigu@hadoop103 ~]$ zkServer.sh start
[atguigu@hadoop104 ~]$ zkServer.sh start
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>（3）启动 Zookeeper 以后，然后再初始化 HA 在 Zookeeper 中状态：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ hdfs zkfc -formatZK
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（4）启动 HDFS 服务：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ start-dfs.sh
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（5）可以去 zkCli.sh 客户端查看 Namenode 选举锁节点内容：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[zk: localhost:2181(CONNECTED) 7] get -s 
/hadoop-ha/mycluster/ActiveStandbyElectorLock
	
	myclusternn2 hadoop103 �&gt;(�&gt;
cZxid = 0x10000000b
ctime = Tue Jul 14 17:00:13 CST 2020
mZxid = 0x10000000b
mtime = Tue Jul 14 17:00:13 CST 2020
pZxid = 0x10000000b
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x40000da2eb70000
dataLength = 33
numChildren = 0
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><h4 id="_3-验证"><a href="#_3-验证" class="header-anchor">#</a> 3）验证</h4> <p>4.3 解决 NN 连接不上 JN 的问题</p> <p>自动故障转移配置好以后，然后使用 start-dfs.sh 群起脚本启动 hdfs 集群，有可能会遇到 NameNode 起来一会后，进程自动关闭的问题。查看 NameNode 日志，报错信息如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>2020-08-17 10:11:40,658 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop104/192.168.6.104:8485. Already tried 0 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:40,659 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop102/192.168.6.102:8485. Already tried 0 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:40,659 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop103/192.168.6.103:8485. Already tried 0 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:41,660 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop104/192.168.6.104:8485. Already tried 1 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:41,660 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop102/192.168.6.102:8485. Already tried 1 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:41,665 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop103/192.168.6.103:8485. Already tried 1 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:42,661 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop104/192.168.6.104:8485. Already tried 2 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:42,661 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop102/192.168.6.102:8485. Already tried 2 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:42,667 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop103/192.168.6.103:8485. Already tried 2 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:43,662 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop104/192.168.6.104:8485. Already tried 3 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:43,662 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop102/192.168.6.102:8485. Already tried 3 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:43,668 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop103/192.168.6.103:8485. Already tried 3 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:44,663 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop104/192.168.6.104:8485. Already tried 4 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:44,663 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop102/192.168.6.102:8485. Already tried 4 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:44,670 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop103/192.168.6.103:8485. Already tried 4 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:45,467 INFO 
org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 6001 
ms (timeout=20000 ms) for a response for selectStreamingInputStreams. No 
responses yet.
2020-08-17 10:11:45,664 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop102/192.168.6.102:8485. Already tried 5 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:45,664 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop104/192.168.6.104:8485. Already tried 5 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:45,672 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop103/192.168.6.103:8485. Already tried 5 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:46,469 INFO 
org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 7003 
ms (timeout=20000 ms) for a response for selectStreamingInputStreams. No 
responses yet.
2020-08-17 10:11:46,665 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop102/192.168.6.102:8485. Already tried 6 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:46,665 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop104/192.168.6.104:8485. Already tried 6 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:46,673 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop103/192.168.6.103:8485. Already tried 6 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:47,470 INFO 
org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 8004 
ms (timeout=20000 ms) for a response for selectStreamingInputStreams. No 
responses yet.
2020-08-17 10:11:47,666 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop102/192.168.6.102:8485. Already tried 7 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:47,667 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop104/192.168.6.104:8485. Already tried 7 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:47,674 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop103/192.168.6.103:8485. Already tried 7 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:48,471 INFO 
org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager: Waited 9005 
ms (timeout=20000 ms) for a response for selectStreamingInputStreams. No 
responses yet.
2020-08-17 10:11:48,668 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop102/192.168.6.102:8485. Already tried 8 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:48,668 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop104/192.168.6.104:8485. Already tried 8 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:48,675 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop103/192.168.6.103:8485. Already tried 8 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:49,669 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop102/192.168.6.102:8485. Already tried 9 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:49,673 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop104/192.168.6.104:8485. Already tried 9 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:49,676 INFO org.apache.hadoop.ipc.Client: Retrying connect 
to server: hadoop103/192.168.6.103:8485. Already tried 9 time(s); retry 
policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, 
sleepTime=1000 MILLISECONDS)
2020-08-17 10:11:49,678 WARN 
org.apache.hadoop.hdfs.server.namenode.FSEditLog: Unable to determine input 
streams from QJM to [192.168.6.102:8485, 192.168.6.103:8485, 
192.168.6.104:8485]. Skipping.
org.apache.hadoop.hdfs.qjournal.client.QuorumException: Got too many 
exceptions to achieve quorum size 2/3. 3 exceptions thrown:
192.168.6.103:8485: Call From hadoop102/192.168.6.102 to hadoop103:8485 
failed on connection exception: java.net.ConnectException: 拒绝连接; For more 
details see: http://wiki.apache.org/hadoop/ConnectionRefused
192.168.6.102:8485: Call From hadoop102/192.168.6.102 to hadoop102:8485 
failed on connection exception: java.net.ConnectException: 拒绝连接; For more 
details see: http://wiki.apache.org/hadoop/ConnectionRefused
192.168.6.104:8485: Call From hadoop102/192.168.6.102 to hadoop104:8485 
failed on connection exception: java.net.ConnectException: 拒绝连接; For more 
details see: http://wiki.apache.org/hadoop/ConnectionRefused
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br><span class="line-number">83</span><br><span class="line-number">84</span><br><span class="line-number">85</span><br><span class="line-number">86</span><br><span class="line-number">87</span><br><span class="line-number">88</span><br><span class="line-number">89</span><br><span class="line-number">90</span><br><span class="line-number">91</span><br><span class="line-number">92</span><br><span class="line-number">93</span><br><span class="line-number">94</span><br><span class="line-number">95</span><br><span class="line-number">96</span><br><span class="line-number">97</span><br><span class="line-number">98</span><br><span class="line-number">99</span><br><span class="line-number">100</span><br><span class="line-number">101</span><br><span class="line-number">102</span><br><span class="line-number">103</span><br><span class="line-number">104</span><br><span class="line-number">105</span><br><span class="line-number">106</span><br><span class="line-number">107</span><br><span class="line-number">108</span><br><span class="line-number">109</span><br><span class="line-number">110</span><br><span class="line-number">111</span><br><span class="line-number">112</span><br><span class="line-number">113</span><br><span class="line-number">114</span><br><span class="line-number">115</span><br><span class="line-number">116</span><br><span class="line-number">117</span><br><span class="line-number">118</span><br><span class="line-number">119</span><br><span class="line-number">120</span><br><span class="line-number">121</span><br><span class="line-number">122</span><br><span class="line-number">123</span><br><span class="line-number">124</span><br><span class="line-number">125</span><br><span class="line-number">126</span><br><span class="line-number">127</span><br><span class="line-number">128</span><br><span class="line-number">129</span><br><span class="line-number">130</span><br><span class="line-number">131</span><br><span class="line-number">132</span><br><span class="line-number">133</span><br><span class="line-number">134</span><br><span class="line-number">135</span><br><span class="line-number">136</span><br><span class="line-number">137</span><br><span class="line-number">138</span><br><span class="line-number">139</span><br><span class="line-number">140</span><br><span class="line-number">141</span><br><span class="line-number">142</span><br><span class="line-number">143</span><br><span class="line-number">144</span><br><span class="line-number">145</span><br><span class="line-number">146</span><br><span class="line-number">147</span><br><span class="line-number">148</span><br><span class="line-number">149</span><br><span class="line-number">150</span><br><span class="line-number">151</span><br></div></div><p>查看报错日志，可分析出报错原因是因为 NameNode 连接不上 JournalNode，而利 用 jps 命令查看到三台 JN 都已经正常启动，为什么 NN 还是无法正常连接到 JN 呢？这 是因为 start-dfs.sh 群起脚本默认的启动顺序是先启动 NN，再启动 DN，然后再启动 JN， 并且默认的 rpc 连接参数是重试次数为 10，每次重试的间隔是 1s，也就是说启动完 NN 以后的 10s 中内，JN 还启动不起来，NN 就会报错了。</p> <p>core-default.xml 里面有两个参数如下：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;!-- NN 连接 JN 重试次数，默认是 10 次 --&gt;
&lt;property&gt;
 &lt;name&gt;ipc.client.connect.max.retries&lt;/name&gt;
 &lt;value&gt;10&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 重试时间间隔，默认 1s --&gt;
&lt;property&gt;
 &lt;name&gt;ipc.client.connect.retry.interval&lt;/name&gt;
 &lt;value&gt;1000&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><p>解决方案：遇到上述问题后，可以稍等片刻，等 JN 成功启动后，手动启动下三台</p> <p><strong>NN:</strong></p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ hdfs --daemon start namenode
[atguigu@hadoop103 ~]$ hdfs --daemon start namenode
[atguigu@hadoop104 ~]$ hdfs --daemon start namenode
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>也可以在 core-site.xml 里面适当调大上面的两个参数：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;!-- NN 连接 JN 重试次数，默认是 10 次 --&gt;
&lt;property&gt;
 &lt;name&gt;ipc.client.connect.max.retries&lt;/name&gt;
 &lt;value&gt;20&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 重试时间间隔，默认 1s --&gt;
&lt;property&gt;
 &lt;name&gt;ipc.client.connect.retry.interval&lt;/name&gt;
 &lt;value&gt;5000&lt;/value&gt;
&lt;/property&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br></div></div><h3 id="_4-4-hdfs-ha-自动故障转移-客户端如何配置-namenode-的ip"><a href="#_4-4-hdfs-ha-自动故障转移-客户端如何配置-namenode-的ip" class="header-anchor">#</a> 4.4 HDFS-HA 自动故障转移 客户端如何配置 namenode 的ip</h3> <p>在 HDFS-HA 集群中，客户端需要配置名称节点的 IP 地址，以便连接到 HDFS 集群并进行读写操作。</p> <p>对于客户端而言，它们需要配置两个名称节点的 IP 地址，一个是主名称节点的 IP 地址，另一个是备用名称节点的 IP 地址。这样，当主名称节点出现故障时，客户端可以通过备用名称节点的 IP 地址连接到 HDFS 集群，保证数据的可用性。</p> <p>具体的配置方法如下：</p> <ul><li>1.在客户端的配置文件中，添加如下的配置项：</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>fs.defaultFS: hdfs://&lt;ha-namenode-IP-address&gt;:&lt;port&gt;/
dfs.ha.namenodes: &lt;ha-namenode-IP-address&gt;:&lt;port&gt;,&lt;ha-standby-namenode-IP-address&gt;:&lt;port&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>其中，<code>&lt;ha-namenode-IP-address&gt;</code>和<code>&lt;ha-standby-namenode-IP-address&gt;</code>分别表示主名称节点和备用名称节点的 IP 地址，<code>&lt;port&gt;</code>表示 HDFS 集群的端口号。</p> <ul><li>2.对于需要访问 HDFS 集群的应用程序，需要使用上述配置项指定 HDFS 集群的名称节点地址。例如，在 Java 程序中，可以使用如下的代码进行配置：</li></ul> <div class="language- line-numbers-mode"><pre class="language-text"><code>FileSystem.get(URI.create(“hdfs://&lt;ha-namenode-IP-address&gt;:&lt;port&gt;/“)).listFiles(“path”)
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>通过上述配置和代码，客户端可以连接到 HDFS-HA 集群，并在主名称节点和备用名称节点之间进行切换，以保证数据的可用性。当主名称节点出现故障时，客户端可以通过备用名称节点的 IP 地址连接到 HDFS 集群，继续进行读写操作。</p> <h3 id="_4-5-zookeeper-failover-controller-zkfc"><a href="#_4-5-zookeeper-failover-controller-zkfc" class="header-anchor">#</a> 4.5 ZooKeeper failover controller（ZKFC）</h3> <p>HDFS-HA 使用 ZooKeeper 作为其高可用性（HA）的协调器。然而，为了确保 NameNode 在故障转移期间正确地同步数据，还需要一个名为 ZooKeeper failover controller（ZKFC）的组件。</p> <p>ZKFC 是一个守护进程，负责监测 NameNode 和 ZooKeeper 的状态，并在 NameNode 故障时触发故障转移。它的主要功能是：</p> <ol><li>监测 NameNode 和 ZooKeeper 的状态：ZKFC 定期检查 NameNode 和 ZooKeeper 的状态，以确保它们都在正常运行。</li> <li>检测 NameNode 故障：如果 NameNode 停止响应或无法连接，ZKFC 将检测到故障。</li> <li>触发故障转移：一旦检测到 NameNode 故障，ZKFC 将触发故障转移，将备用 NameNode 切换为新的主 NameNode。</li> <li>同步数据：在故障转移期间，ZKFC 将确保备用 NameNode 正确地同步数据，以确保数据的一致性。</li></ol> <p>因此，虽然 ZooKeeper 是 HDFS-HA 的协调器，但 ZKFC 仍然是必不可少的，因为它确保了 NameNode 在故障转移期间正确地同步数据，从而确保了 HDFS 的高可用性。</p> <h1 id="yarn-ha-配置"><a href="#yarn-ha-配置" class="header-anchor">#</a> YARN-HA 配置</h1> <h2 id="_5-1-yarn-ha-工作机制"><a href="#_5-1-yarn-ha-工作机制" class="header-anchor">#</a> 5.1 YARN-HA 工作机制</h2> <p>1）官方文档： http://hadoop.apache.org/docs/r3.1.3/hadoop-yarn/hadoop-yarn-site/ResourceManagerHA.html</p> <p>2）YARN-HA 工作机制</p> <p><img src="/assets/img/image-20230905155853239.2768bd3a.png" alt="image-20230905155853239"></p> <h2 id="_5-2-配置-yarn-ha-集群"><a href="#_5-2-配置-yarn-ha-集群" class="header-anchor">#</a> 5.2 配置 YARN-HA 集群</h2> <h3 id="_1-环境准备"><a href="#_1-环境准备" class="header-anchor">#</a> 1）环境准备</h3> <p>（1）修改 IP</p> <p>（2）修改主机名及主机名和 IP 地址的映射</p> <p>（3）关闭防火墙</p> <p>（4）ssh 免密登录</p> <p>（5）安装 JDK，配置环境变量等</p> <p>（6）配置 Zookeeper 集群</p> <h3 id="_2-规划集群"><a href="#_2-规划集群" class="header-anchor">#</a> 2）规划集群</h3> <p><img src="/assets/img/image-20230905160006808.c9f7064d.png" alt="image-20230905160006808"></p> <h3 id="_3-核心问题"><a href="#_3-核心问题" class="header-anchor">#</a> <strong>3）核心问题</strong></h3> <ul><li>a .如果当前 active rm 挂了，其他 rm 怎么将其他 standby rm 上位</li></ul> <p>​    核心原理跟 hdfs 一样，利用了 zk 的临时节点</p> <ul><li>b. 当前 rm 上有很多的计算程序在等待运行,其他的 rm 怎么将这些程序接手过来接着跑</li></ul> <p>​	rm 会将当前的所有计算程序的状态存储在 zk 中,其他 rm 上位后会去读取，然后接着跑</p> <h3 id="_4-具体配置"><a href="#_4-具体配置" class="header-anchor">#</a> 4）具体配置</h3> <p>（1）yarn-site.xml</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>&lt;configuration&gt;
 &lt;property&gt;
     &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
     &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
 &lt;/property&gt;
 &lt;!-- 启用 resourcemanager ha --&gt;
 &lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;
     &lt;value&gt;true&lt;/value&gt;
 &lt;/property&gt;
 &lt;!-- 声明两台 resourcemanager 的地址 --&gt;
 &lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;
     &lt;value&gt;cluster-yarn1&lt;/value&gt;
 &lt;/property&gt;
 &lt;!--指定 resourcemanager 的逻辑列表--&gt;
 &lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;
     &lt;value&gt;rm1,rm2,rm3&lt;/value&gt;
&lt;/property&gt;
&lt;!-- ========== rm1 的配置 ========== --&gt;
&lt;!-- 指定 rm1 的主机名 --&gt;
 &lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;
     &lt;value&gt;hadoop102&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 指定 rm1 的 web 端地址 --&gt;
&lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.webapp.address.rm1&lt;/name&gt;
     &lt;value&gt;hadoop102:8088&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 指定 rm1 的内部通信地址 --&gt;
&lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.address.rm1&lt;/name&gt;
     &lt;value&gt;hadoop102:8032&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 指定 AM 向 rm1 申请资源的地址 --&gt;
&lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.scheduler.address.rm1&lt;/name&gt; 
     &lt;value&gt;hadoop102:8030&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 指定供 NM 连接的地址 --&gt; 
&lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.resource-tracker.address.rm1&lt;/name&gt;
     &lt;value&gt;hadoop102:8031&lt;/value&gt;
&lt;/property&gt;
&lt;!-- ========== rm2 的配置 ========== --&gt;
 &lt;!-- 指定 rm2 的主机名 --&gt;
 &lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;
     &lt;value&gt;hadoop103&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.webapp.address.rm2&lt;/name&gt;
     &lt;value&gt;hadoop103:8088&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.address.rm2&lt;/name&gt;
     &lt;value&gt;hadoop103:8032&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.scheduler.address.rm2&lt;/name&gt;
     &lt;value&gt;hadoop103:8030&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.resource-tracker.address.rm2&lt;/name&gt;
     &lt;value&gt;hadoop103:8031&lt;/value&gt;
&lt;/property&gt;
&lt;!-- ========== rm3 的配置 ========== --&gt;
&lt;!-- 指定 rm1 的主机名 --&gt;
 &lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.hostname.rm3&lt;/name&gt;
     &lt;value&gt;hadoop104&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 指定 rm1 的 web 端地址 --&gt;
&lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.webapp.address.rm3&lt;/name&gt;
     &lt;value&gt;hadoop104:8088&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 指定 rm1 的内部通信地址 --&gt;
&lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.address.rm3&lt;/name&gt;
     &lt;value&gt;hadoop104:8032&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 指定 AM 向 rm1 申请资源的地址 --&gt;
&lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.scheduler.address.rm3&lt;/name&gt; 
     &lt;value&gt;hadoop104:8030&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 指定供 NM 连接的地址 --&gt; 
&lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.resource-tracker.address.rm3&lt;/name&gt;
     &lt;value&gt;hadoop104:8031&lt;/value&gt;
&lt;/property&gt;
 &lt;!-- 指定 zookeeper 集群的地址 --&gt; 
 &lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;
     &lt;value&gt;hadoop102:2181,hadoop103:2181,hadoop104:2181&lt;/value&gt;
 &lt;/property&gt;
 &lt;!-- 启用自动恢复 --&gt; 
 &lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.recovery.enabled&lt;/name&gt;
     &lt;value&gt;true&lt;/value&gt;
 &lt;/property&gt;
 &lt;!-- 指定 resourcemanager 的状态信息存储在 zookeeper 集群 --&gt; 
 &lt;property&gt;
     &lt;name&gt;yarn.resourcemanager.store.class&lt;/name&gt; 
    &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateSt
    ore&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 环境变量的继承 --&gt;
&lt;property&gt;
 &lt;name&gt;yarn.nodemanager.env-whitelist&lt;/name&gt;
 
&lt;value&gt;JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLAS
SPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME&lt;/value&gt;
 &lt;/property&gt;
&lt;/configuration&gt;
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br><span class="line-number">83</span><br><span class="line-number">84</span><br><span class="line-number">85</span><br><span class="line-number">86</span><br><span class="line-number">87</span><br><span class="line-number">88</span><br><span class="line-number">89</span><br><span class="line-number">90</span><br><span class="line-number">91</span><br><span class="line-number">92</span><br><span class="line-number">93</span><br><span class="line-number">94</span><br><span class="line-number">95</span><br><span class="line-number">96</span><br><span class="line-number">97</span><br><span class="line-number">98</span><br><span class="line-number">99</span><br><span class="line-number">100</span><br><span class="line-number">101</span><br><span class="line-number">102</span><br><span class="line-number">103</span><br><span class="line-number">104</span><br><span class="line-number">105</span><br><span class="line-number">106</span><br><span class="line-number">107</span><br><span class="line-number">108</span><br><span class="line-number">109</span><br><span class="line-number">110</span><br><span class="line-number">111</span><br><span class="line-number">112</span><br><span class="line-number">113</span><br><span class="line-number">114</span><br><span class="line-number">115</span><br><span class="line-number">116</span><br><span class="line-number">117</span><br><span class="line-number">118</span><br></div></div><p>（2）同步更新其他节点的配置信息，分发配置文件</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 etc]$ xsync hadoop/
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h3 id="_5-启动-yarn"><a href="#_5-启动-yarn" class="header-anchor">#</a> 5）启动 YARN</h3> <p>（1）在 hadoop102 或者 hadoop103 中执行：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ start-yarn.sh
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（2）查看服务状态</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ yarn rmadmin -getServiceState rm1
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>（3）可以去 zkCli.sh 客户端查看 ResourceManager 选举锁节点内容：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>[atguigu@hadoop102 ~]$ zkCli.sh
[zk: localhost:2181(CONNECTED) 16] get -s 
/yarn-leader-election/cluster-yarn1/ActiveStandbyElectorLock
cluster-yarn1rm1
cZxid = 0x100000022
ctime = Tue Jul 14 17:06:44 CST 2020
mZxid = 0x100000022
mtime = Tue Jul 14 17:06:44 CST 2020
pZxid = 0x100000022
cversion = 0
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x30000da33080005
dataLength = 20
numChildren = 
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><p>（4）web 端查看 hadoop102:8088 和 hadoop103:8088 的 YARN 的状态</p> <p><img src="/assets/img/image-20230905160615298.1b6e4d77.png" alt="image-20230905160615298"></p></div></div>  <div class="page-edit"><div class="edit-link"><a href="https://github.com/andanyang/vuepress-theme-vdoing/edit/master/docs/Hadoop/0010.Hadoop HA 高可用.md" target="_blank" rel="noopener noreferrer">编辑</a> <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></div> <!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2023/09/12, 05:17:42</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/Hadoop/Production_tuning_manual/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">第八章Hadoop（生产调优手册）</div></a> <a href="/Hadoop/windows10_build/" class="page-nav-centre page-nav-centre-next"><div class="tooltip">hadoop 3.x 在windows10下编译</div></a></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/Hadoop/Production_tuning_manual/" class="prev">第八章Hadoop（生产调优手册）</a></span> <span class="next"><a href="/Hadoop/windows10_build/">hadoop 3.x 在windows10下编译</a>→
      </span></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/linux/vpn/"><div>
            手把手教你搭建OpenVPN（保姆级教程）
            <!----></div></a> <span class="date">09-09</span></dt></dl><dl><dd>02</dd> <dt><a href="/Spring_boot/Multithreaded_transaction_rollback_processing/"><div>
            多线程事务回滚的处理
            <!----></div></a> <span class="date">08-10</span></dt></dl><dl><dd>03</dd> <dt><a href="/Spring_boot/Spring_Transaction/"><div>
            Spring事务详解
            <!----></div></a> <span class="date">08-10</span></dt></dl> <dl><dd></dd> <dt><a href="/archives/" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="mailto:1218853253@qq.com" title="发邮件" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/andanyang" title="GitHub" target="_blank" class="iconfont icon-github"></a><a href="https://music.163.com/#/playlist?id=755597173" title="听音乐" target="_blank" class="iconfont icon-erji"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2019-2023
    <span>Young | <a href="https://github.com/andanyoung/young-blog/blob/master/LICENSE" target="_blank">MIT License</a> <br/> <a  href="https://beian.miit.gov.cn/" target="_blank">浙ICP备20002744号</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"><div></div></div></div>
    <script src="/assets/js/app.2b0d7625.js" defer></script><script src="/assets/js/2.3974175a.js" defer></script><script src="/assets/js/26.44857563.js" defer></script>
  </body>
</html>
