---
title: hadoop 踩坑记 DataNode 启动失败(ClusterID不一致)：Initialization failed for Block pool
date: 2022-06-30 12:41:40
permalink: /Hadoop/DataNode_RUN_FAIL/
categories:
  - Hadoop
tags:
  -
author:
  name: andanyang
  link: https://github.com/andanyoung
---

```
ERROR org.apache.hadoop.hdfs.server.datanode.DataNode:
Initialization failed for Block pool <registering>
(Datanode Uuid 1098277a-8189-4b88-9a9b-31dbb7cdd27f) service to hadoop162/192.168.1.162:8020. Exiting.
java.io.IOException: All specified directories have failed to load.
```

## 问题描述

开机启动集群时，发现有节点的 DataNode 没有启动。

确认配置信息没问题后，观察节点的中的 datanode 日志(配置文件中指定)发现：Initialization failed for Block pool

## 问题分析

在第一次格式化 dfs 后,启动并使用了 hadoop,后来又重新执行了格式化命令（hdfs namenode -format)，这时 NameNode 的 clusterID 会重新生成，而 DataNode 的 clusterID 保持不变。

每次 namenode format 会重新创建一个 namenodeId,而 data 目录包含了上次 format 时的 id，namenode format 清空了 NameNode 下的数据,但是没有清空 datanode 下的数据，导致启动时失败,所要做的就是每次 fotmat 前,清空 data 下的所有目录。

## 解决方法：

### 方法一：

停掉集群，删除问题节点的 data 目录下的所有内容。即 hdfs-site.xml 文件中配置的 dfs.data.dir 目录（我的目录：/opt/hadoopdata）。重新格式化 NameNode。

### 方法二：

停掉集群，然后将出现问题的 DataNode 节点目录/opt/hadoopdata/dfs/data/current/下的 VERSION 中 clusterID 的修改为与 NameNode 中/opt/hadoopdata/dfs/name/current/下的 VERSION 中 clusterID 一致即可。

其实只需要把 data/current/VERSION 中的 clusterID 改为和 name/current/VERSION 中的 clusterID 一致。
