---
title: Hadoop单节点伪分布式安装
date: 2022-09-15 00:05:21
permalink: /Flume/Advanced/
categories:
  - 大数据
  - Flume
tags:
  -
author:
  name: andanyang
  link: https://github.com/andanyoung
---

单节点安装只适合作为开发学习环境

> 参考： https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html

## 下载镜像

https://archive.apache.org/dist/hadoop/common/hadoop-3.3.6/

JAVA 环境安装

http://blog.admin4j.com/JAVA/INSTALL/

# **本地模式运行**

默认情况下，Hadoop 被配置为以非分布式模式运行，作为单个 Java 进程。这对调试很有用。

下面的示例复制未打包的 conf 目录作为输入，然后查找并显示给定正则表达式的每个匹配项。输出被写入给定的输出目录。

```
  $ mkdir input
  $ cp etc/hadoop/*.xml input
  $ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar grep input output 'dfs[a-z.]+'
  $ cat output/*
```

## **伪分布式模式**

Hadoop 还可以在单节点上以伪分布式模式运行，其中每个 Hadoop 守护进程在单独的 Java 进程中运行。

### 环境变量

（1）获取 Hadoop 安装路径

```
$ pwd
/opt/module/hadoop-3.1.3
```

（2）打开/etc/profile.d/my_env.sh 文件

在 my_env.sh 文件末尾添加如下内容：（shift+g）

```
#HADOOP_HOME
export HADOOP_HOME=/opt/module/hadoop-3.1.3
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
```

让修改后的文件生效

（3）让修改后的文件生效

```text
$ source /etc/profile
```

4）测试是否安装成功

```text
$ hadoop version
Hadoop 3.1.3
```

### 配置 Hadoop

- **hadoop-env.sh**

  ```
  #文件最后添加
  export JAVA_HOME=/export/server/jdk1.8.0_241

  # to limit who can execute the namenode command,
  export HDFS_NAMENODE_USER=root
  export HDFS_DATANODE_USER=root
  export HDFS_SECONDARYNAMENODE_USER=root
  export YARN_RESOURCEMANAGER_USER=root
  export YARN_NODEMANAGER_USER=root
  ```

- etc/hadoop/core-site.xml:

  ```
      <!-- 指定NameNode的地址 -->
      <property>
          <name>fs.defaultFS</name>
          <value>hdfs://hadoop102:8020</value>
      </property>

      <!-- 指定hadoop数据的存储目录 -->
      <property>
          <name>hadoop.tmp.dir</name>
          <value>/opt/module/hadoop-3.1.3/data</value>
      </property>

      <!-- 配置HDFS网页登录使用的静态用户为root -->
      <property>
          <name>hadoop.http.staticuser.user</name>
          <value>root</value>
      </property>
  ```

- etc/hadoop/hdfs-site.xml:

  ```
  <configuration>
   <property>
          <name>dfs.replication</name>
          <value>1</value>
      </property>
          <!-- nn web端访问地址-->
          <property>
          <name>dfs.namenode.http-address</name>
          <value>hadoop102:9870</value>
      </property>
          <!-- 2nn web端访问地址-->
      <property>
          <name>dfs.namenode.secondary.http-address</name>
          <value>hadoop104:9868</value>
      </property>
  </configuration>
  ```

### 启动 hadoop

#### 设置免登陆

```
  $ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
  $ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
  $ chmod 0600 ~/.ssh/authorized_keys
```

#### 格式化

```
  $ bin/hdfs namenode -format
```

#### 启动

```
  $ sbin/start-dfs.sh
  $ sbin/stop-dfs.sh
```

### YARN 单机配置文件

> 通过设置一些参数，并在 YARN 上运行 ResourceManager 守护进程和 NodeManager 守护进程，可以在 YARN 上以伪分布式方式运行 MapReduce 作业。

- 配置 yarn-site.xml

  ```
  <?xml version="1.0" encoding="UTF-8"?>
  <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

  <configuration>
      <!-- 指定MR走shuffle -->
      <property>
          <name>yarn.nodemanager.aux-services</name>
          <value>mapreduce_shuffle</value>
      </property>

      <!-- 指定ResourceManager的地址-->
      <property>
          <name>yarn.resourcemanager.hostname</name>
          <value>hadoop103</value>
      </property>

      <!-- 环境变量的继承 -->
      <property>
          <name>yarn.nodemanager.env-whitelist</name>
          <property>
          <name>yarn.nodemanager.env-whitelist</name>
          <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ,HADOOP_MAPRED_HOME</value>
      </property>
      </property>
  </configuration>
  ```

- （4）MapReduce 配置文件

  ```
  <?xml version="1.0" encoding="UTF-8"?>
  <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

  <configuration>
  	<!-- 指定MapReduce程序运行在Yarn上 -->
      <property>
          <name>mapreduce.framework.name</name>
          <value>yarn</value>
      </property>
       <property>
          <name>mapreduce.application.classpath</name
          <value>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*</value>
      </property>
  </configuration>
  ```

- （5）启动 yarn

  ```
    $ sbin/start-yarn.sh
    $ sbin/stop-yarn.sh
  ```

## 完全分布式

> http://blog.admin4j.com/Hadoop/Build-Hadoop-running-environment

​
