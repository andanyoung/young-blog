---
title: Hive入门 的坑
date: 2023-10-04 12:14:58
permalink: /bigdata/hive_trap/
categories:
  - 大数据
  - hive
tags:
  -
author:
  name: andanyang
  link: https://github.com/andanyoung
---

# 1. beeline 建表建库权限问题导致的报错

## 报错详情：

```
ERROR : FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:Got exception: org.apache.hadoop.security.AccessControlException Permission denied: user=node1, access=WRITE, inode="/user":root:supergroup:drwxr-xr-x
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:399)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:255)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:193)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1852)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1836)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkAncestorAccess(FSDirectory.java:1795)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:59)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3192)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1157)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:714)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:527)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1036)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1015)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:943)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2943)
)
```

很明显是用户权限的问题。

解决方案：

为 user 添加权限，`hadoop fs -chmod 777 /user`

创建数据库是加在有权限的目录下面（修改 hdfs 的权限 `hadoop fs -chown xxx:xxx /user/hive/xxx`）

```
hive (default)> create database db_hive2 location '/db_hive2';
```

## 2. java.sql.SQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask. No such file or directory at org.apache.hive.jdbc.HiveStatement.waitForOperationToComplete(HiveStatement.java:401)

由于一开始 hadoop 和 hive 使用 root 用户启动的，改用 其他用户启动之后，提交任务文件夹没有权限了。

解决方法： 删除 /tmp 下的 hive hadoop 文件 。推荐 hive 和hadoop使用同个用户或者用户组执行



# 3.Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.StatsTask

之前的insert语句虽然报错了，但是已经向表里插入数据了，有可能会造成重复的数据。

设置 `set set hive.stats.column.autogather=false`

可以通过设置 `hive.stats.column.autogather` 参数来控制是否自动收集列的统计信息。如果你想禁用自动收集，可以将此参数设置为 `false`。

hive-site.xml

```
<property>  
    <name>hive.stats.column.autogather</name>  
    <value>false</value>  
</property>
```



>  `StatsTask` 类的主要职责是执行统计任务。它通过分析表的元数据信息和表的分区信息来收集统计信息。然后，它会将统计信息存储在 Hive 的元数据中，以便在执行查询时使用。

